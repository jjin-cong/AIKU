{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"JeXa6KG1pR1s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038580502,"user_tz":-540,"elapsed":27405,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"a14a0a8c-0704-4e56-be8b-35b6cfbef8e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/AIKU/DeepInDeep/ê³¼ì œ_1/D2D/datasets\n","/content/drive/My Drive/AIKU/DeepInDeep/ê³¼ì œ_1/D2D\n"]}],"source":["# Google Driveë¥¼ Colab VMì— Mount í•©ë‹ˆë‹¤.\n","# 'ë¡œê·¸ì¸ í•˜ê² ìŠµë‹ˆê¹Œ?' ë¬»ëŠ” ì°½ì´ ë‚˜ì˜¤ë©´ í—ˆê°€ í•´ ì£¼ì„¸ìš”.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# ê³¼ì œ íŒŒì¼ì„ ë‹¤ìš´ ë°›ì€ ê²½ë¡œë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n","# Google Driveì˜ í´ë” ê²½ë¡œëŠ” /content/drive/My Drive/ ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.\n","# ì¦‰, ë§Œì•½ ë‹¹ì‹ ì´ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ìµœìƒë‹¨ì— ìˆëŠ” 'D2D' í´ë”ì— í•´ë‹¹ íŒŒì¼ì„ ë‹¤ìš´ ë°›ì•˜ë‹¤ê³  í•©ì‹œë‹¤.\n","# ê·¸ëŸ¬ë©´ D2D ì•ˆì—ëŠ” 'Assignment 0' Colab íŒŒì¼ê³¼, datasets í´ë”ê°€ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n","# ê·¸ë ‡ë‹¤ë©´ ë°‘ì˜ ê²½ë¡œì—ëŠ” '/D2D' ë¼ê³  ì ì–´ì£¼ë©´ ë©ë‹ˆë‹¤. ë§ˆì§€ë§‰ì— '/'ê°€ ì—†ìŒì— ìœ ì˜í•´ ì£¼ì„¸ìš”.\n","FOLDERNAME = 'AIKU/DeepInDeep/ê³¼ì œ_1/D2D'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# ì´ì œ Driveë¥¼ ë§ˆìš´íŠ¸ í–ˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\n","# Python interpreterê°€ Colab VMì´ python filesë¥¼ load í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","# ì´ ì½”ë“œëŠ” CIFAR-10 datasetì´ Driveì— ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ì €ì¥í•©ë‹ˆë‹¤.\n","%cd /content/drive/My\\ Drive/$FOLDERNAME/datasets/\n","!bash get_datasets.sh\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"]},{"cell_type":"markdown","metadata":{"id":"vtsHWi7KpR1x"},"source":["# PyTorch ì‹œì‘í•˜ê¸°\n","**AIKU í•™íšŒì› ì—¬ëŸ¬ë¶„!** ë”¥ëŸ¬ë‹ì„ í–¥í•œ ì—¬ì •ì— ë°œ ë“¤ì¸ ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤ğŸ˜„.\n","\n","í•™íšŒì› ì—¬ëŸ¬ë¶„ì´ ì•ìœ¼ë¡œ ë§ˆì£¼í•˜ê²Œ ë  ì—¬ëŸ¬ ì–´ë ¤ì›€ë“¤ì´ ìˆì„í…ë°, Deep Into Deepì˜ ìˆ˜ì—…ê³¼ ê³¼ì œê°€ ê·¸ ê¸¸ì— ì¡°ê¸ˆì€ ë„ì›€ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤.\n","\n","ë³¸ ê³¼ì œëŠ” CS231n, ê³ ë ¤ëŒ€í•™êµ ë”¥ëŸ¬ë‹ ìˆ˜ì—… ë“± ì—¬ëŸ¬ ì¢‹ì€ ê³¼ì œë“¤ì„ í˜¼í•©í•´ ë§Œë“¤ì–´ ì¡ŒìŒì„ ë¯¸ë¦¬ ì•Œë¦½ë‹ˆë‹¤. ê±°ì¸ì˜ ì–´ê¹¨ë¥¼ ë§Œë“¤ì–´ì¤€ ì—¬ëŸ¬ë¶„ ê°ì‚¬í•©ë‹ˆë‹¤!\n","\n","ë‹¤ì‹œ í•œ ë²ˆ ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤! **Happy Hacking!**"]},{"cell_type":"markdown","metadata":{"id":"r7e58EDipR1z"},"source":["## ì™œ Deep Learning frameworksë¥¼ ì¨ì•¼í• ê¹Œìš”?\n","\n","* ìš°ë¦¬ì˜ Codeë¥¼ GPUë¡œ ì‹¤í–‰ ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ì´ë¥¼ í†µí•´ ëª¨ë¸ì„ í›¨ì”¬ ë¹ ë¥´ê²Œ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. PyTorchë‚˜ TensorFlowì™€ ê°™ì€ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ë©´ CUDA ì½”ë“œë¥¼ ì§ì ‘ ì‘ì„±í•  í•„ìš” ì—†ì´(ì´ ê°•ì˜ì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ”) ìì‹ ë§Œì˜ ë§ì¶¤í˜• ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ë¥¼ ìœ„í•´ GPUì˜ ì„±ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","* ì´ ê°•ì˜ì—ì„œëŠ” í”„ë¡œì íŠ¸ì— ì´ëŸ¬í•œ í”„ë ˆì„ì›Œí¬ ì¤‘ í•˜ë‚˜ (PyTorch)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©í•˜ë ¤ëŠ” ëª¨ë“  ê¸°ëŠ¥ì„ ì§ì ‘ ì‘ì„±í•  ë•Œë³´ë‹¤ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•  ê²ƒì…ë‹ˆë‹¤.\n","\n","* ê±°ì¸ë“¤ì˜ ì–´ê¹¨ ìœ„ì— ì„œ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤! TensorFlowì™€ PyTorchëŠ” ëª¨ë‘ ì—¬ëŸ¬ë¶„ì˜ ì‚¶ì„ í›¨ì”¬ í¸í•˜ê²Œ ë§Œë“¤ì–´ì¤„ í›Œë¥­í•œ í”„ë ˆì„ì›Œí¬ì´ë©°, ì´ì œ ê·¸ ê¸°ëŠ¥ì„ ì´í•´í•˜ì…¨ìœ¼ë‹ˆ ììœ ë¡­ê²Œ ì‚¬ìš©í•˜ì…”ë„ ë©ë‹ˆë‹¤ :)\n","\n","* ë§ˆì§€ë§‰ìœ¼ë¡œ, í•™ê³„ë‚˜ ì—…ê³„ì—ì„œ ì ‘í•  ìˆ˜ ìˆëŠ” ë”¥ ëŸ¬ë‹ ì½”ë“œì— ë…¸ì¶œë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤.\n","\n","## PyTorchë€ ë¬´ì—‡ì¼ê¹Œìš”?\n","numpyì˜ ndarrayì™€ ë¹„ìŠ·í•˜ê²Œ ë™ì‘í•˜ëŠ” **Tensor objects**ì— ëŒ€í•´ì„œ ë™ì  computational graphsë¥¼ ì‹¤í–‰í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. PyTorchëŠ” ì‚¬ëŒì´ ì§ì ‘ backpropagationì„ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ì´ ê°•ë ¥í•œ **ìë™ ë¯¸ë¶„** ì—”ì§„ì„ ì œê³µí•©ë‹ˆë‹¤.\n","\n","## ì–´ë–»ê²Œ PyTorchë¥¼ ë°°ìš¸ ìˆ˜ ìˆì„ê¹Œìš”?\n","ì´ ê³¼ì œë§Œìœ¼ë¡œëŠ” PyTorch ì „ë°˜ì„ ì´í•´í•˜ëŠ”ë° ì–´ë ¤ì›€ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì´ ì¶”ì²œë˜ì§€ë§Œ, ë„ì›€ì´ ë  ë§Œí•œ ì‚¬ì´íŠ¸ì™€ í•™ìŠµ ë°©ë²•ì„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n","\n","PyTorch ê³µì‹ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ :\n","https://tutorials.pytorch.kr/beginner/basics/intro.html\n","\n","Stanfordì˜ PyTorch ê°•ì˜ : https://github.com/jcjohnson/pytorch-examples\n"]},{"cell_type":"markdown","metadata":{"id":"Ulz-ISjJpR10"},"source":["# ëª©ì°¨\n","ì´ ê³¼ì œëŠ” 6ê°œì˜ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŒŒì´í† ì¹˜ë¥¼ ë” ì˜ ì´í•´í•˜ê³  ìµœì¢… í”„ë¡œì íŠ¸ë¥¼ ì¤€ë¹„í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” **ì„¸ ê°€ì§€ ì¶”ìƒí™” ìˆ˜ì¤€**ì—ì„œ íŒŒì´í† ì¹˜ë¥¼ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤.\n","\n","ì´ì— ë”í•´, ìˆ˜ì—… ì‹œê°„ì— ë°°ì› ë˜ **AlexNet**ì„ ì¬êµ¬í˜„í•´ ë³´ë©´ì„œ PyTorchì—ì„œ CNN Layerë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆì„ì§€ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤.\n","\n","1. Part I, ì¤€ë¹„: CIFAR-10 ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n","2. Part II, Barebones PyTorch: **ì¶”ìƒí™” ìˆ˜ì¤€ 1**ì˜ ê°€ì¥ ë‚®ì€ ìˆ˜ì¤€ì˜ PyTorch í…ì„œë¡œ ì§ì ‘ ì‘ì—…í•©ë‹ˆë‹¤.\n","3. Part III, PyTorch Module API: **ì¶”ìƒí™” ìˆ˜ì¤€ 2**ì—ì„œëŠ” `nn.Module`ì„ ì‚¬ìš©í•˜ì—¬ ì„ì˜ì˜ ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n","4. Part IV, PyTorch Sequential API: **ì¶”ìƒí™” ìˆ˜ì¤€ 3**ì—ì„œëŠ” `nn.Sequential`ì„ ì‚¬ìš©í•˜ì—¬ Linear Feed-Forward Networkë¥¼ ë§¤ìš° í¸ë¦¬í•˜ê²Œ ì •ì˜í•©ë‹ˆë‹¤. + **AlexNet**ì„ ì¬êµ¬í˜„í•´ ë´…ì‹œë‹¤!\n","5. Part V, CIFAR-10 open-ended challenge: CIFAR-10ì—ì„œ ê°€ëŠ¥í•œ í•œ ë†’ì€ ì •í™•ë„ë¥¼ ì–»ê¸° ìœ„í•´ ìì‹ ë§Œì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í•˜ì„¸ìš”. Layer, Optimizer, hyperparameters ë˜ëŠ” ê¸°íƒ€ ê³ ê¸‰ ê¸°ëŠ¥ìœ¼ë¡œ ì‹¤í—˜í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","6. Additional Part, Pretrained model ë¶ˆëŸ¬ì˜¤ê¸°: torchvisionì—ì„œ ë‹¤ì–‘í•œ pretrained modelì„ ë¶ˆëŸ¬ë³´ê³  finetuning í•´ ë´…ì‹œë‹¤.\n","\n","ë‹¤ìŒì€ ë¹„êµ í‘œì…ë‹ˆë‹¤:\n","\n","| API | ìœ ì—°ì„± | í¸ì˜ì„± |\n","|---------------|-------------|-------------|\n","| Barebones | ë†’ìŒ | ë‚®ìŒ |\n","| `nn.Module` | ë†’ìŒ | ì¤‘ê°„ |\n","| `nn.Sequential` | ë‚®ìŒ | ë†’ìŒ |"]},{"cell_type":"markdown","metadata":{"id":"aZQFg1RRpR11"},"source":["# GPU\n","`ëŸ°íƒ€ì„ -> ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½`ì„ í´ë¦­í•˜ê³  `í•˜ë“œì›¨ì–´ ê°€ì†ê¸°` ì•„ë˜ì—ì„œ `GPU`ë¥¼ ì„ íƒí•˜ë©´ Colabì—ì„œ GPU ì¥ì¹˜ë¡œ ìˆ˜ë™ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ì„ ì „í™˜í•˜ë©´ ì»¤ë„ì´ ë‹¤ì‹œ ì‹œì‘ë˜ë¯€ë¡œ íŒ¨í‚¤ì§€ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ê¸° ì „ì— ì´ ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cKvYIhDDpR12","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038584814,"user_tz":-540,"elapsed":4314,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"f1bd0e9f-5d7a-43a7-83a0-ac6a2737f84e"},"outputs":[{"output_type":"stream","name":"stdout","text":["using device: cuda\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","USE_GPU = True\n","dtype = torch.float32 # We will be using float throughout this tutorial.\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","# Constant to control how frequently we print train loss.\n","print_every = 100\n","print('using device:', device)"]},{"cell_type":"markdown","metadata":{"id":"e4q1RwwngAJz"},"source":["`using device: cuda`ê°€ ë‚˜ì˜¤ë©´ ì„±ê³µì…ë‹ˆë‹¤!"]},{"cell_type":"markdown","metadata":{"id":"swu-jxUigCVr"},"source":["## What is 'CUDA'?\n","\n","\n","> CUDA(\"Compute Unified Device Architecture\", ì¿ ë‹¤)ëŠ” ê·¸ë˜í”½ ì²˜ë¦¬ ì¥ì¹˜(GPU)ì—ì„œ ìˆ˜í–‰í•˜ëŠ” (ë³‘ë ¬ ì²˜ë¦¬) ì•Œê³ ë¦¬ì¦˜ì„ C í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ë¹„ë¡¯í•œ ì‚°ì—… í‘œì¤€ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” GPGPU ê¸°ìˆ ì´ë‹¤. -Wikipedia-\n","\n","GPUëŠ” ì›ë˜ ê·¸ ì´ë¦„ì—ì„œë„ ì•Œ ìˆ˜ ìˆë“¯ì´ Graphic ì—°ì‚°ì„ ìœ„í•œ ì¥ì¹˜ì˜€ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ GPUê°€ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ë§¤ìš° ë¹ ë¥¸ ì†ë„ë¡œ ì²˜ë¦¬í•œë‹¤ëŠ” ì ì— ì£¼ëª©í•˜ì—¬, ì¼ë°˜ì ì¸ matrix ì—°ì‚°ì— ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” GPGPU ê¸°ìˆ ì´ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. NVIDAê°€ ì§€ì›í•˜ëŠ” CUDAë¥¼ í†µí•´ ê°œë°œìë“¤ì´ ì‰½ê²Œ GPU ìƒì—ì„œ ë³‘ë ¬ ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ì„ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.\n","\n","ì§€ê¸ˆ ê³¼ì œëŠ” Colabì—ì„œ ì§„í–‰ë˜ë¯€ë¡œ íŠ¹ë³„íˆ CUDA Versionì„ ì„¤ì •í•´ ì¤„ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ê·¸ë ‡ì§€ë§Œ, ì•ìœ¼ë¡œ Local, ë˜ëŠ” Serverì—ì„œ Deep Learning ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë‹¤ ë³´ë©´ CUDA, PyTorch ë²„ì ¼ê³¼ ê´€ë ¨ëœ ì˜¤ë¥˜ë¥¼ ë§ì´ ë§ˆì£¼í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ´ ë• ë‹¤ìŒê³¼ ê°™ì€ ê¸°ìˆ ì„ ê²€í† í•´ ë³´ì„¸ìš”.\n","* Anaconda\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E9fI9EE0pR12"},"source":["# Part I. ì¤€ë¹„\n","ì´ì œ CIFAR-10 ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¡œë“œí•´ ë³´ê² ìŠµë‹ˆë‹¤. ì²˜ìŒ ëª‡ ë¶„ ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆì§€ë§Œ ê·¸ ì´í›„ì—ëŠ” íŒŒì¼ì´ ìºì‹œëœ ìƒíƒœë¡œ ìœ ì§€ë©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"MDBJu2TJpR13","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038810325,"user_tz":-540,"elapsed":10051,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"bc31ba3f-73a6-4a08-e0c7-7dc118b6b7cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["NUM_TRAIN = 49000\n","\n","# The torchvision.transforms package provides tools for preprocessing data\n","# and for performing data augmentation; here we set up a transform to\n","# preprocess the data by subtracting the mean RGB value and dividing by the\n","# standard deviation of each RGB value; we've hardcoded the mean and std.\n","\n","#ë°ì´í„° ì „ì²˜ë¦¬(Transform), ì…ë ¥ ë°ì´í„°ë¥¼ í…ì„œ ë°”ê¿”ì£¼ê³  Normalize í•´ì¤€ë‹¤\n","transform = T.Compose([\n","                T.ToTensor(),\n","                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","            ])\n","\n","# We set up a Dataset object for each split (train / val / test); Datasets load\n","# training examples one at a time, so we wrap each Dataset in a DataLoader which\n","# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n","# training set into train and val sets by passing a Sampler object to the\n","# DataLoader telling how it should sample from the underlying Dataset.\n","\n","#train data ê°€ì ¸ì˜¤ê¸°\n","cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n","                             transform=transform) #train dataset ë¶ˆëŸ¬ì˜¤ê¸°\n","\n","#dataloaderë¥¼ í†µí•´ train dataë¥¼ batchë¡œ split & save\n","loader_train = DataLoader(cifar10_train, batch_size=64,\n","                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n","\n","##validation data ê°€ì ¸ì˜¤ê¸° (ê·¼ë° ì™œ trainì—ì„œ í•¨ê»˜ ê°€ì ¸ì™”ì„ê¹Œ)\n","cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n","                           transform=transform)\n","\n","#dataloaderë¥¼ í†µí•œ val dataë¥¼ batchë¡œ split&save\n","loader_val = DataLoader(cifar10_val, batch_size=64,\n","                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n","\n","#test data ê°€ì ¸ì˜¤ê¸°\n","cifar10_test = dset.CIFAR10('./datasets', train=False, download=True,\n","                            transform=transform)\n","\n","#dataloaderë¡œ test data split\n","loader_test = DataLoader(cifar10_test, batch_size=64)"]},{"cell_type":"markdown","metadata":{"id":"yTVAtckopR14"},"source":["## Part II. Barebones PyTorch\n","PyTorchëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ í¸ë¦¬í•˜ê²Œ ì •ì˜í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í•˜ì´ë ˆë²¨ APIì™€ í•¨ê»˜ ì œê³µë˜ë©°, ì´ íŠœí† ë¦¬ì–¼ì˜ Part IIì—ì„œëŠ” ì´ë¥¼ ë‹¤ë£° ê²ƒì…ë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” autograd engineì„ ë” ì˜ ì´í•´í•˜ê¸° ìœ„í•´ Barebones PyTorch ìš”ì†Œë¶€í„° ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì´ ì—°ìŠµì„ ë§ˆì¹˜ë©´ í•˜ì´ë ˆë²¨ ëª¨ë¸ APIë¥¼ ë” ì˜ ì´í•´í•˜ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.\n","\n","ë‘ ê°œì˜ ìˆ¨ê²¨ì§„ ë ˆì´ì–´ê°€ ìˆê³  CIFAR ë¶„ë¥˜ë¥¼ ìœ„í•œ biasê°€ ì—†ëŠ” ê°„ë‹¨í•œ Fully-connected ReLU ë„¤íŠ¸ì›Œí¬ë¡œ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì´ êµ¬í˜„ì€ PyTorch í…ì„œì—ì„œ ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ forward passë¥¼ ê³„ì‚°í•˜ê³  PyTorch autogradë¥¼ ì‚¬ìš©í•˜ì—¬ gradientë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ ì˜ˆì œ ì´í›„ì— ë” ì–´ë ¤ìš´ ë²„ì „ì„ ì‘ì„±í•  ê²ƒì´ë¯€ë¡œ ëª¨ë“  ì¤„ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n","\n","`requires_grad = True`ë¡œ PyTorch í…ì„œë¥¼ ìƒì„±í•˜ë©´ í•´ë‹¹ í…ì„œë¥¼ í¬í•¨í•˜ëŠ” ì—°ì‚°ì€ ê°’ë§Œ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì‚° ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•˜ì—¬ ê·¸ë˜í”„ë¥¼ í†µí•´ ì‰½ê²Œ ì—­ì „íŒŒí•˜ì—¬ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì†ì‹¤ì— ëŒ€í•œ ì¼ë¶€ í…ì„œì˜ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ xê°€ `x.requires_grad == True`ì¸ í…ì„œì¸ ê²½ìš°, ì—­ì „íŒŒ í›„ `x.grad`ëŠ” ë§ˆì§€ë§‰ì— scalar lossì— ëŒ€í•œ xì˜ ê¸°ìš¸ê¸°ë¥¼ ë³´ìœ í•˜ëŠ” ë˜ ë‹¤ë¥¸ í…ì„œê°€ ë  ê²ƒì…ë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"KLO6iHpBpR15"},"source":["### PyTorch Tensors: Flatten í•¨ìˆ˜\n","PyTorch TensorsëŠ” ê°œë…ì ìœ¼ë¡œ nì°¨ì› ë°°ì—´ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. nì°¨ì› ìˆ«ì ê·¸ë¦¬ë“œì´ë©°, PyTorchëŠ” nì°¨ì› ë°°ì—´ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ í…ì„œì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆëŠ” ë§ì€ í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê°„ë‹¨í•œ ì˜ˆë¡œ, ì•„ë˜ì—ì„œëŠ” ì™„ì „íˆ ì—°ê²°ëœ ì‹ ê²½ë§ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì¬êµ¬ì„±í•˜ëŠ” `flatten` í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n","\n","ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ N x C x H x W í˜•íƒœì˜ í…ì„œì— ì €ì¥ëœë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ì„¸ìš”:\n","\n","* Nì€ ë°ì´í„° í¬ì¸íŠ¸ì˜ ìˆ˜ì…ë‹ˆë‹¤.\n","* CëŠ” ì±„ë„ ìˆ˜ì…ë‹ˆë‹¤.\n","* HëŠ” ì¤‘ê°„ íŠ¹ì§• ë§µì˜ í”½ì…€ ë‹¨ìœ„ ë†’ì´ì…ë‹ˆë‹¤.\n","* WëŠ” ì¤‘ê°„ í”¼ì²˜ ë§µì˜ ë†’ì´(í”½ì…€)ì…ë‹ˆë‹¤.\n","\n","ì´ëŠ” 2D convolution ê°™ì´ ì¤‘ê°„ íŠ¹ì§•ì´ ì„œë¡œ ìƒëŒ€ì ì¸ ìœ„ì¹˜ì— ëŒ€í•œ ê³µê°„ì  ì´í•´ê°€ í•„ìš”í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œ ë°ì´í„°ë¥¼ í‘œí˜„í•˜ëŠ” ë° ì í•©í•œ ë°©ë²•ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ fully connected affine layersë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ë•ŒëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ë‹¨ì¼ ë²¡í„°ë¡œ í‘œí˜„í•´ì•¼ í•˜ë¯€ë¡œ ë°ì´í„°ì˜ ì—¬ëŸ¬ ì±„ë„, í–‰, ì—´ì„ ë¶„ë¦¬í•˜ëŠ” ê²ƒì€ ë” ì´ìƒ ìœ ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ 'flatten' ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ í‘œí˜„ë‹¹ `C x H x W` ê°’ì„ í•˜ë‚˜ì˜ ê¸´ ë²¡í„°ë¡œ ì¶•ì†Œí•©ë‹ˆë‹¤. ì•„ë˜ì˜ flatten í•¨ìˆ˜ëŠ” ë¨¼ì € ì£¼ì–´ì§„ ë°ì´í„° ë°°ì¹˜ì—ì„œ N, C, H, W ê°’ì„ ì½ì€ ë‹¤ìŒ í•´ë‹¹ ë°ì´í„°ì˜ 'view'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. \"view\"ëŠ” numpyì˜ \"reshape\" ë©”ì„œë“œì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. xì˜ ì°¨ì›ì„ N x ?? ë¡œ ì¬í˜•ì„±í•˜ë©°, ì—¬ê¸°ì„œ ?? ëŠ” ë¬´ì—‡ì´ë“  í—ˆìš©ë©ë‹ˆë‹¤(ì´ ê²½ìš° C x H x Wê°€ ë˜ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤)."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"pUnA0EncpR15","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038810327,"user_tz":-540,"elapsed":12,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"d69c6694-e1bb-4054-fe69-29f95f502393"},"outputs":[{"output_type":"stream","name":"stdout","text":["Before flattening:  tensor([[[[ 0,  1],\n","          [ 2,  3],\n","          [ 4,  5]]],\n","\n","\n","        [[[ 6,  7],\n","          [ 8,  9],\n","          [10, 11]]]])\n","After flattening:  tensor([[ 0,  1,  2,  3,  4,  5],\n","        [ 6,  7,  8,  9, 10, 11]])\n"]}],"source":["def flatten(x):\n","    N = x.shape[0] # read in N, C, H, W\n","    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n","\n","def test_flatten():\n","    x = torch.arange(12).view(2, 1, 3, 2)\n","    print('Before flattening: ', x)\n","    print('After flattening: ', flatten(x))\n","\n","test_flatten()"]},{"cell_type":"markdown","metadata":{"id":"wpnPI6lVpR16"},"source":["### Barebones PyTorch: Two-Layer Network\n","\n","ì—¬ê¸°ì—ì„œëŠ” ì´ë¯¸ì§€ ë°ì´í„° ë°°ì¹˜ì— ëŒ€í•´ ì™„ì „íˆ ì—°ê²°ëœ 2ê³„ì¸µ ReLU ë„¤íŠ¸ì›Œí¬ì˜ í¬ì›Œë“œ íŒ¨ìŠ¤ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ `two_layer_fc`ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. í¬ì›Œë“œ íŒ¨ìŠ¤ë¥¼ ì •ì˜í•œ í›„ì—ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ 0ì„ ì‹¤í–‰í•˜ì—¬ ì¶©ëŒì´ ë°œìƒí•˜ì§€ ì•ŠëŠ”ì§€, ì˜¬ë°”ë¥¸ ëª¨ì–‘ì˜ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n","\n","ì—¬ê¸°ì„œ ì½”ë“œë¥¼ ì‘ì„±í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ êµ¬í˜„ì„ ì½ê³  ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"vg43S8B0pR16","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038817343,"user_tz":-540,"elapsed":2,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"c3576124-d368-4954-f08d-bb46dccc5823"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["import torch.nn.functional as F  # useful stateless functions\n","\n","def two_layer_fc(x, params):\n","    \"\"\"\n","    A fully-connected neural networks; the architecture is:\n","    NN is fully connected -> ReLU -> fully connected layer.\n","    Note that this function only defines the forward pass;\n","    PyTorch will take care of the backward pass for us.\n","\n","    The input to the network will be a minibatch of data, of shape\n","    (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n","    and the output layer will produce scores for C classes.\n","\n","    Inputs:\n","    - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of\n","      input data.\n","    - params: A list [w1, w2] of PyTorch Tensors giving weights for the network;\n","      w1 has shape (D, H) and w2 has shape (H, C).\n","\n","    Returns:\n","    - scores: A PyTorch Tensor of shape (N, C) giving classification scores for\n","      the input data x.\n","    \"\"\"\n","    # first we flatten the image\n","    x = flatten(x)  # shape: [batch_size, C x H x W]\n","\n","    w1, w2 = params\n","\n","    # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n","    # w2 have requires_grad=True, operations involving these Tensors will cause\n","    # PyTorch to build a computational graph, allowing automatic computation of\n","    # gradients. Since we are no longer implementing the backward pass by hand we\n","    # don't need to keep references to intermediate values.\n","    # you can also use `.clamp(min=0)`, equivalent to F.relu()\n","\n","    x = F.relu(x.mm(w1)) #torch.mmì€ í–‰ë ¬ ê³±ì„ ì˜ë¯¸í•œë‹¤.\n","    x = x.mm(w2)\n","    ##ë§ˆì§€ë§‰ ë ˆì´ì–´ì— ëŒ€í•´ì„œëŠ” í™œì„±í™”í•¨ìˆ˜ ì—†ì–´ë„ ê´œì°®ì€ê°€? -> í¬ë¡œìŠ¤ ì•¤íŠ¸ë¡œí”¼ ë¡œìŠ¤ì—ì„œ softmaxê¹Œì§€ ì²˜ë¦¬í•´ì¤€ë‹¤!\n","    return x\n","\n","\n","def two_layer_fc_test():\n","    hidden_layer_size = 42\n","    x = torch.zeros((64, 50), dtype=dtype)  # minibatch size 64, feature dimension 50\n","    w1 = torch.zeros((50, hidden_layer_size), dtype=dtype)\n","    w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype)\n","    scores = two_layer_fc(x, [w1, w2])\n","    print(scores.size())  # you should see [64, 10]\n","\n","two_layer_fc_test()"]},{"cell_type":"markdown","metadata":{"id":"Hpfeu2JJpR17"},"source":["### Barebones PyTorch: Three-Layer ConvNet\n","\n","ì—¬ê¸°ì„œëŠ” 3ê³„ì¸µ Convolution ë„¤íŠ¸ì›Œí¬ì˜ ìˆœë°©í–¥ íŒ¨ìŠ¤ë¥¼ ìˆ˜í–‰í•˜ëŠ” `three_layer_convnet` í•¨ìˆ˜ì˜ êµ¬í˜„ì„ ì™„ë£Œí•©ë‹ˆë‹¤. ìœ„ì™€ ê°™ì´ ë„¤íŠ¸ì›Œí¬ì— 0ì„ ì „ë‹¬í•˜ì—¬ êµ¬í˜„ì„ ì¦‰ì‹œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤:\n","\n","1. `channel_1` í•„í„°ê°€ ìˆëŠ” Convolution ë ˆì´ì–´(bias í¬í•¨), ê°ê° ëª¨ì–‘ì´ `KW1 x KH1`ì´ê³  zero padding ì´ 2ì…ë‹ˆë‹¤.\n","2. ReLU nonlinearity\n","3. `channel_2` í•„í„°ê°€ ìˆëŠ” Convolution ë ˆì´ì–´(bias í¬í•¨), ê° í•„í„°ì˜ ëª¨ì–‘ì´ `KW2 x KH2`ì´ê³  ì œë¡œ íŒ¨ë”©ì´ 1ì…ë‹ˆë‹¤.\n","4. ReLU nonlinearity\n","5. biasê°€ ìˆëŠ” Fully-connected layer, C í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n","\n","Fully-connected layer ì´í›„ì—ëŠ” **ì†Œí”„íŠ¸ë§¥ìŠ¤ í™œì„±í™”ê°€ ì—†ìŒ**ì— ìœ ì˜í•˜ì‹­ì‹œì˜¤: ì´ëŠ” PyTorchì˜ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ì´ ì†Œí”„íŠ¸ë§¥ìŠ¤ í™œì„±í™”ë¥¼ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì´ë©°, ì´ ë‹¨ê³„ë¥¼ ë²ˆë“¤ë¡œ ë¬¶ìœ¼ë©´ ê³„ì‚°ì´ ë” íš¨ìœ¨ì ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n","\n","**íŒíŠ¸**: Convolutionsì— ëŒ€í•´: http://pytorch.org/docs/stable/nn.html#torch.nn.functional.conv2d; convolutional filters ëª¨ì–‘ì— ì£¼ì˜í•´ ì£¼ì„¸ìš”!"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ECDdAX4GpR18","executionInfo":{"status":"ok","timestamp":1690038817343,"user_tz":-540,"elapsed":1,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"outputs":[],"source":["def three_layer_convnet(x, params):\n","    \"\"\"\n","    Performs the forward pass of a three-layer convolutional network with the\n","    architecture defined above.\n","\n","    Inputs:\n","    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images\n","    - params: A list of PyTorch Tensors giving the weights and biases for the\n","      network; should contain the following:\n","      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n","        for the first convolutional layer\n","      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n","        convolutional layer\n","      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n","        weights for the second convolutional layer\n","      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n","        convolutional layer\n","      - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","      - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","\n","    Returns:\n","    - scores: PyTorch Tensor of shape (N, C) giving classification scores for x\n","    \"\"\"\n","    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n","    scores = None\n","    ################################################################################\n","    # TODO: Implement the forward pass for the three-layer ConvNet.                #\n","    ################################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    A_1 = torch.nn.functional.conv2d(x, conv_w1, bias=conv_b1, stride=1, padding=2) #ì—¬ê¸°ì„œ bias = conv_b1ê³¼ ë’¤ì— + conv_b1 í•´ì£¼ëŠ” ê²ƒì— ì°¨ì´ê°€ ìˆì„ê¹Œ?\n","    Z_1 = F.relu(A_1)\n","    A_2 = torch.nn.functional.conv2d(Z_1, conv_w2, bias=conv_b2, stride=1, padding=1)\n","    Z_2 = F.relu(A_2)\n","    flatten_Z_2 = flatten(Z_2)\n","    Z_3 = flatten_Z_2.mm(fc_w) + fc_b\n","\n","    scores = Z_3\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ################################################################################\n","    #                                 END OF YOUR CODE                             #\n","    ################################################################################\n","    return scores"]},{"cell_type":"markdown","metadata":{"id":"g6hBYahWpR18"},"source":["ìœ„ì—ì„œ ConvNetì˜ í¬ì›Œë“œ íŒ¨ìŠ¤ë¥¼ ì •ì˜í•œ í›„ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì—¬ êµ¬í˜„ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n","\n","ì´ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ë©´ ì ìˆ˜ëŠ” (64, 10) ëª¨ì–‘ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"barebones_output_shape","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038817753,"user_tz":-540,"elapsed":2,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"c1b40237-051d-407c-bc3a-60e64137a5c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["def three_layer_convnet_test():\n","    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n","\n","    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n","    conv_b1 = torch.zeros((6,))  # out_channel\n","    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n","    conv_b2 = torch.zeros((9,))  # out_channel\n","\n","    # you must calculate the shape of the tensor after two conv layers, before the fully-connected layer\n","    fc_w = torch.zeros((9 * 32 * 32, 10))\n","    fc_b = torch.zeros(10)\n","\n","    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n","    print(scores.size())  # you should see [64, 10]\n","three_layer_convnet_test()"]},{"cell_type":"markdown","metadata":{"id":"2jxzynJspR19"},"source":["### Barebones PyTorch: Initialization\n","ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì´ˆê¸°í™”í•˜ëŠ” ëª‡ ê°€ì§€ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë¥¼ ì‘ì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n","\n","- `random_weight(shape)`ëŠ” Kaiming normalization ë°©ë²•ìœ¼ë¡œ ê°€ì¤‘ì¹˜ í…ì„œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n","- `zero_weight(shape)`ëŠ” ëª¨ë“  0ìœ¼ë¡œ ê°€ì¤‘ì¹˜ í…ì„œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ë°”ì´ì–´ìŠ¤ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n","\n","`random_weight` í•¨ìˆ˜ëŠ” Kaiming normal initialization ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\n","\n","He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*, ICCV 2015, https://arxiv.org/abs/1502.01852"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"UXkgnTzMpR19","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038819570,"user_tz":-540,"elapsed":2,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"dda5f45e-d14a-4236-8722-cb378492e9cb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.2312, -1.4870,  0.5531, -0.4321,  0.3992],\n","        [ 1.9478, -0.3602,  0.7176, -0.2205,  0.4583],\n","        [ 0.4094, -0.6763,  0.9371,  0.6880,  0.3608]], device='cuda:0',\n","       requires_grad=True)"]},"metadata":{},"execution_count":15}],"source":["def random_weight(shape):\n","    \"\"\"\n","    Create random Tensors for weights; setting requires_grad=True means that we\n","    want to compute gradients for these Tensors during the backward pass.\n","    We use Kaiming normalization: sqrt(2 / fan_in)\n","    \"\"\"\n","\n","    #kaiming he normalziationì€ convolution ì—°ì‚°ì— ë§ì´ ì“°ì´ëŠ” ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ë°©ì‹ìœ¼ë¡œ\n","    #íŠ¹ì„± ì¸µì˜ í™œì„±í™” í•¨ìˆ˜ì— ëŒ€í•œ ë¶„ì‚°ì„ ì¼ì •í•˜ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤.\n","    #ë°‘ì˜ fan_inì€ ê°€ì¤‘ì¹˜ í…ì„œì˜ ì±„ë„(í”¼ì³) ìˆ˜ì´ë‹¤.\n","    if len(shape) == 2:  # FC weight, FC layerì— ëŒ€í•´ì„œëŠ” Flattenëœ ê°’ì´ê¸° ë•Œë¬¸ì—\n","        fan_in = shape[0]\n","\n","    else:\n","        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n","    # randn is standard normal distribution generator.\n","    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in) #XavierëŠ” np.sqrt(1/fan_in)ì´ê³  tanhì— ì‚¬ìš©, HeëŠ” np.sqrt(2/fan_in)ì´ê³  Reluì— ì‚¬ìš©\n","    w.requires_grad = True\n","    return w\n","\n","def zero_weight(shape):\n","    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n","\n","# create a weight of shape [3 x 5]\n","# you should see the type `torch.cuda.FloatTensor` if you use GPU.\n","# Otherwise it should be `torch.FloatTensor`\n","random_weight((3, 5))"]},{"cell_type":"markdown","metadata":{"id":"_Z1t3y6YpR19"},"source":["### Barebones PyTorch: Check Accuracy\n","ëª¨ë¸ì„ í›ˆë ¨í•  ë•Œ ë‹¤ìŒ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë˜ëŠ” ê²€ì¦ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n","\n","ì •í™•ë„ë¥¼ í™•ì¸í•  ë•Œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ë•Œ PyTorchê°€ ê³„ì‚° ê·¸ë˜í”„ë¥¼ ë§Œë“¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ê·¸ë˜í”„ê°€ ìƒì„±ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ `torch.no_grad()` context managerì—ì„œ ê³„ì‚° ë²”ìœ„ë¥¼ ì§€ì •í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"jre5tpX2pR1-","executionInfo":{"status":"ok","timestamp":1690038820068,"user_tz":-540,"elapsed":2,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"outputs":[],"source":["def check_accuracy_part2(loader, model_fn, params):\n","    \"\"\"\n","    Check the accuracy of a classification model.\n","\n","    Inputs:\n","    - loader: A DataLoader for the data split we want to check\n","    - model_fn: A function that performs the forward pass of the model,\n","      with the signature scores = model_fn(x, params)\n","    - params: List of PyTorch Tensors giving parameters of the model\n","\n","    Returns: Nothing, but prints the accuracy of the model\n","    \"\"\"\n","    split = 'val' if loader.dataset.train else 'test'\n","    print('Checking accuracy on the %s set' % split)\n","    num_correct, num_samples = 0, 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.int64)\n","            scores = model_fn(x, params)\n","            _, preds = scores.max(1) #argmaxì™€ ê°™ì€ ì—­í• \n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0) #ì „ì²´ ê°œìˆ˜ë¡œ ë‚˜ëˆ ì£¼ê¸° ìœ„í•¨\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"]},{"cell_type":"markdown","metadata":{"id":"OwNMOvc7pR1-"},"source":["### BareBones PyTorch: Training Loop\n","ì´ì œ ë„¤íŠ¸ì›Œí¬ë¥¼ í›ˆë ¨í•˜ê¸° ìœ„í•œ basic training loopë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. momentum ì—†ì´ Stochastic gradient descentë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•  ê²ƒì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” `torch.functional.cross_entropy`ë¥¼ ì‚¬ìš©í•˜ì—¬ lossë¥¼ ê³„ì‚°í•  ê²ƒì…ë‹ˆë‹¤(http://pytorch.org/docs/stable/nn.html#cross-entropy).\n","\n","training loopëŠ” ì‹ ê²½ë§ í•¨ìˆ˜, ì´ˆê¸°í™”ëœ ë§¤ê°œë³€ìˆ˜ ëª©ë¡(ì˜ˆì œì—ì„œëŠ” `[w1, w2]`), í•™ìŠµ ì†ë„ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Fyt2Boy_pR1-","executionInfo":{"status":"ok","timestamp":1690038820532,"user_tz":-540,"elapsed":2,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"outputs":[],"source":["def train_part2(model_fn, params, learning_rate):\n","    \"\"\"\n","    Train a model on CIFAR-10.\n","\n","    Inputs:\n","    - model_fn: A Python function that performs the forward pass of the model.\n","      It should have the signature scores = model_fn(x, params) where x is a\n","      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n","      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n","      scores for the elements in x.\n","    - params: List of PyTorch Tensors giving weights for the model\n","    - learning_rate: Python scalar giving the learning rate to use for SGD\n","\n","    Returns: Nothing\n","    \"\"\"\n","    for t, (x, y) in enumerate(loader_train):\n","        # Move the data to the proper device (GPU or CPU)\n","        x = x.to(device=device, dtype=dtype)\n","        y = y.to(device=device, dtype=torch.long)\n","\n","        # Forward pass: compute scores and loss\n","        scores = model_fn(x, params)\n","        loss = F.cross_entropy(scores, y)\n","\n","        # Backward pass: PyTorch figures out which Tensors in the computational\n","        # graph has requires_grad=True and uses backpropagation to compute the\n","        # gradient of the loss with respect to these Tensors, and stores the\n","        # gradients in the .grad attribute of each Tensor.\n","        loss.backward()\n","\n","        # Update parameters. We don't want to backpropagate through the\n","        # parameter updates, so we scope the updates under a torch.no_grad()\n","        # context manager to prevent a computational graph from being built.\n","        with torch.no_grad():\n","            for w in params:\n","                w -= learning_rate * w.grad\n","\n","                # Manually zero the gradients after running the backward pass\n","                w.grad.zero_()\n","\n","        if t % print_every == 0:\n","            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","            check_accuracy_part2(loader_val, model_fn, params)\n","            print()"]},{"cell_type":"markdown","metadata":{"id":"KhZfY1PzpR1_"},"source":["### BareBones PyTorch: Train a Two-Layer Network\n","ì´ì œ training loopë¥¼ ì‹¤í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. fully connected weightsì¸ `w1`ê³¼ `w2`ì— ëŒ€í•œ Tensorë¥¼ ëª…ì‹œì ìœ¼ë¡œ í• ë‹¹í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","CIFARì˜ ê° minibatchì—ëŠ” 64ê°œì˜ ì˜ˆê°€ ìˆìœ¼ë¯€ë¡œ í…ì„œ ëª¨ì–‘ì€ `[64, 3, 32, 32]`ì…ë‹ˆë‹¤.\n","\n","flatten í›„ `x` ëª¨ì–‘ì€ `[64, 3 * 32 * 32]`ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ê²ƒì´ `w1`ì˜ ì²« ë²ˆì§¸ ì°¨ì› í¬ê¸°ê°€ ë©ë‹ˆë‹¤.\n","`w1`ì˜ ë‘ ë²ˆì§¸ ì°¨ì›ì€ hidden layer sizeì´ë©°, ì´ëŠ” ë˜í•œ `w2`ì˜ ì²« ë²ˆì§¸ ì°¨ì›ì´ ë©ë‹ˆë‹¤.\n","\n","ë§ˆì§€ë§‰ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ì˜ ì¶œë ¥ì€ 10ê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” 10ì°¨ì› ë²¡í„°ì…ë‹ˆë‹¤.\n","\n","hyperparameterë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ í•œ íšŒê¸° ë™ì•ˆ í›ˆë ¨í•œ í›„ì—ëŠ” 40% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"OVhigckkpR1_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038841728,"user_tz":-540,"elapsed":20766,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"907793e0-9788-4132-cf11-84988569b29e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 3.9069\n","Checking accuracy on the val set\n","Got 165 / 1000 correct (16.50%)\n","\n","Iteration 100, loss = 2.4596\n","Checking accuracy on the val set\n","Got 311 / 1000 correct (31.10%)\n","\n","Iteration 200, loss = 2.0550\n","Checking accuracy on the val set\n","Got 377 / 1000 correct (37.70%)\n","\n","Iteration 300, loss = 1.9371\n","Checking accuracy on the val set\n","Got 360 / 1000 correct (36.00%)\n","\n","Iteration 400, loss = 1.9233\n","Checking accuracy on the val set\n","Got 419 / 1000 correct (41.90%)\n","\n","Iteration 500, loss = 1.7812\n","Checking accuracy on the val set\n","Got 418 / 1000 correct (41.80%)\n","\n","Iteration 600, loss = 1.4448\n","Checking accuracy on the val set\n","Got 410 / 1000 correct (41.00%)\n","\n","Iteration 700, loss = 1.7972\n","Checking accuracy on the val set\n","Got 449 / 1000 correct (44.90%)\n","\n"]}],"source":["hidden_layer_size = 4000\n","learning_rate = 1e-2\n","\n","w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n","w2 = random_weight((hidden_layer_size, 10))\n","\n","train_part2(two_layer_fc, [w1, w2], learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"8qHT93KFpR1_"},"source":["### BareBones PyTorch: Training a ConvNet\n","\n","ì•„ë˜ì—ì„œëŠ” ìœ„ì—ì„œ ì •ì˜í•œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ CIFARì—ì„œ 3ê³„ì¸µ Convolutional networkë¥¼ í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ì˜ ì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:\n","\n","1. 32ê°œì˜ 5x5 í•„í„°ê°€ ìˆëŠ” ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´(ë°”ì´ì–´ìŠ¤ í¬í•¨), ì œë¡œ íŒ¨ë”©ì€ 2ì…ë‹ˆë‹¤.\n","2. ReLU\n","3. 16ê°œì˜ 3x3 í•„í„°ê°€ ìˆëŠ” ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´(ë°”ì´ì–´ìŠ¤ í¬í•¨), ì œë¡œ íŒ¨ë”© 1\n","4. ReLU\n","5. 10ê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ ì™„ì „ ì—°ê²° ë ˆì´ì–´(ë°”ì´ì–´ìŠ¤ í¬í•¨)\n","\n","ìœ„ì—ì„œ ì •ì˜í•œ `random_weight` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì´ˆê¸°í™”í•´ì•¼ í•˜ë©°, ìœ„ì˜ `zero_weight` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°”ì´ì–´ìŠ¤ ë²¡í„°ë¥¼ ì´ˆê¸°í™”í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ ëª¨ë“  ê²ƒì´ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ë©´ í•œ ì—í¬í¬ í›„ì— 42% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"barebones_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038865585,"user_tz":-540,"elapsed":23859,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"82d675f1-9de4-4d25-b257-97946816dc11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 4.0912\n","Checking accuracy on the val set\n","Got 103 / 1000 correct (10.30%)\n","\n","Iteration 100, loss = 1.7508\n","Checking accuracy on the val set\n","Got 334 / 1000 correct (33.40%)\n","\n","Iteration 200, loss = 1.6677\n","Checking accuracy on the val set\n","Got 376 / 1000 correct (37.60%)\n","\n","Iteration 300, loss = 1.9416\n","Checking accuracy on the val set\n","Got 416 / 1000 correct (41.60%)\n","\n","Iteration 400, loss = 1.6902\n","Checking accuracy on the val set\n","Got 413 / 1000 correct (41.30%)\n","\n","Iteration 500, loss = 1.5923\n","Checking accuracy on the val set\n","Got 445 / 1000 correct (44.50%)\n","\n","Iteration 600, loss = 1.6769\n","Checking accuracy on the val set\n","Got 438 / 1000 correct (43.80%)\n","\n","Iteration 700, loss = 1.5980\n","Checking accuracy on the val set\n","Got 457 / 1000 correct (45.70%)\n","\n"]}],"source":["learning_rate = 3e-3\n","\n","channel_1 = 32\n","channel_2 = 16\n","\n","conv_w1 = random_weight((channel_1,3,5,5))\n","conv_b1 = zero_weight((channel_1,))\n","conv_w2 = random_weight((channel_2,channel_1,3,3))\n","conv_b2 = zero_weight((channel_2,))\n","fc_w = random_weight((channel_2 * 32 * 32, 10))\n","fc_b = zero_weight((10,))\n","\n","################################################################################\n","# TODO: Initialize the parameters of a three-layer ConvNet.                    #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","'''\n","    Inputs:\n","    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images\n","    - params: A list of PyTorch Tensors giving the weights and biases for the\n","      network; should contain the following:\n","      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n","        for the first convolutional layer\n","      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n","        convolutional layer\n","      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n","        weights for the second convolutional layer\n","      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n","        convolutional layer\n","      - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","      - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","'''\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n","train_part2(three_layer_convnet, params, learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"KpzU23oApR2A"},"source":["# Part III. PyTorch Module API\n","\n","Barebone PyTorchì—ì„œëŠ” ëª¨ë“  Parameter tensorsë¥¼ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì¶”ì í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ëª‡ ê°œì˜ í…ì„œê°€ ìˆëŠ” ì†Œê·œëª¨ ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” ê´œì°®ì§€ë§Œ, ëŒ€ê·œëª¨ ë„¤íŠ¸ì›Œí¬ì—ì„œ ìˆ˜ì‹­ ë˜ëŠ” ìˆ˜ë°± ê°œì˜ í…ì„œë¥¼ ì¶”ì í•˜ëŠ” ê²ƒì€ ë§¤ìš° ë¶ˆí¸í•˜ê³  ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.\n","\n","PyTorchëŠ” ì„ì˜ì˜ ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ë¥¼ ì •ì˜í•˜ëŠ” ë™ì‹œì— í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì í•  ìˆ˜ ìˆë„ë¡ `nn.Module` APIë¥¼ ì œê³µí•©ë‹ˆë‹¤. Part IIì—ì„œëŠ” SGDë¥¼ ì§ì ‘ êµ¬í˜„í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. PyTorchëŠ” ë˜í•œ RMSProp, Adagrad, Adamê³¼ ê°™ì€ ëª¨ë“  ì¼ë°˜ì ì¸ Optimizerë¥¼ êµ¬í˜„í•˜ëŠ” `torch.optim` íŒ¨í‚¤ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì‹¬ì§€ì–´ L-BFGSì™€ ê°™ì€ ëŒ€ëµì ì¸ 2ì°¨ ë°©ë²•ë„ ì§€ì›í•©ë‹ˆë‹¤! ê° ì˜µí‹°ë§ˆì´ì €ì˜ ì •í™•í•œ ì‚¬ì–‘ì€ [ë¬¸ì„œ](http://pytorch.org/docs/master/optim.html)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n","\n","ëª¨ë“ˆ APIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:\n","\n","1. ì„œë¸Œí´ë˜ìŠ¤ `nn.Module`. ë„¤íŠ¸ì›Œí¬ í´ë˜ìŠ¤ì— `TwoLayerFC`ì™€ ê°™ì€ ì§ê´€ì ì¸ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤.\n","\n","2. ìƒì„±ì `__init__()`ì—ì„œ í•„ìš”í•œ ëª¨ë“  ë ˆì´ì–´ë¥¼ í´ë˜ìŠ¤ ì†ì„±ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤. `nn.Linear` ë° `nn.Conv2d`ì™€ ê°™ì€ ë ˆì´ì–´ ê°ì²´ëŠ” ê·¸ ìì²´ë¡œ `nn.Module` ì„œë¸Œí´ë˜ìŠ¤ì´ë©° í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•˜ë¯€ë¡œ ì›ì‹œ í…ì„œë¥¼ ì§ì ‘ ì¸ìŠ¤í„´ìŠ¤í™”í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. `nn.Module`ì´ ì´ëŸ¬í•œ ë‚´ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. ìˆ˜ì‹­ ê°œì˜ ë‚´ì¥ ë ˆì´ì–´ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ [ë¬¸ì„œ](http://pytorch.org/docs/master/nn.html)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. **ê²½ê³ **: `super().__init__()`ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”!\n","\n","3. `forward()` ë©”ì„œë“œì—ì„œ ë„¤íŠ¸ì›Œí¬ì˜ *ì—°ê²°ì„±*ì„ ì •ì˜í•©ë‹ˆë‹¤. í…ì„œë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³  \"ë³€í™˜ëœ\" í…ì„œë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œë¡œ `__init__`ì— ì •ì˜ëœ ì†ì„±ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. `forward()`ì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ê°€ ìˆëŠ” ìƒˆ ë ˆì´ì–´ë¥¼ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”! ëª¨ë“  ë§¤ê°œë³€ìˆ˜ëŠ” `__init__`ì—ì„œ ë¯¸ë¦¬ ì„ ì–¸í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","ëª¨ë“ˆ ì„œë¸Œí´ë˜ìŠ¤ë¥¼ ì •ì˜í•œ í›„ì—ëŠ” ê°ì²´ë¡œ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ì—¬ Part IIì˜ NN ì „ë‹¬ í•¨ìˆ˜ì²˜ëŸ¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","### Module API: Two-Layer Network\n","ë‹¤ìŒì€ fully connected 2ê³„ì¸µ ë„¤íŠ¸ì›Œí¬ì˜ êµ¬ì²´ì ì¸ ì˜ˆì…ë‹ˆë‹¤:"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"WSrvts7LpR2A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038865586,"user_tz":-540,"elapsed":10,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"679981b1-946b-493b-da30-aae767da7fd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["class TwoLayerFC(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super().__init__()\n","        # assign layer objects to class attributes\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        # nn.init package contains convenient initialization methods\n","        # http://pytorch.org/docs/master/nn.html#torch-nn-init\n","        nn.init.kaiming_normal_(self.fc1.weight)\n","        self.fc2 = nn.Linear(hidden_size, num_classes)\n","        nn.init.kaiming_normal_(self.fc2.weight)\n","\n","    def forward(self, x):\n","        # forward always defines connectivity\n","        x = flatten(x)\n","        scores = self.fc2(F.relu(self.fc1(x)))\n","        return scores\n","\n","def test_TwoLayerFC():\n","    input_size = 50\n","    x = torch.zeros((64, input_size), dtype=dtype)  # minibatch size 64, feature dimension 50\n","    model = TwoLayerFC(input_size, 42, 10)\n","    scores = model(x)\n","    print(scores.size())  # you should see [64, 10]\n","test_TwoLayerFC()"]},{"cell_type":"markdown","metadata":{"id":"oTbHlNclpR2A"},"source":["### Module API: Three-Layer ConvNet\n","ì´ì œ ì™„ì „íˆ ì—°ê²°ëœ ë ˆì´ì–´ì— ì´ì–´ 3ê³„ì¸µ ConvNetì„ êµ¬í˜„í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ëŠ” íŒŒíŠ¸ IIì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤:\n","\n","1. zero-paddingì´ 2ì¸ `channel_1` 5x5 í•„í„°ê°€ ìˆëŠ” ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´\n","2. ReLU\n","3. `channel_2` 3x3 í•„í„°ê°€ ìˆëŠ” Convolution Layer, zero-padding 1\n","4. ReLU\n","5. `num_classes` í´ë˜ìŠ¤ì— ì™„ì „íˆ ì—°ê²°ëœ ë ˆì´ì–´\n","\n","Kaiming normal initialize ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì´ˆê¸°í™”í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","**HINT**: http://pytorch.org/docs/stable/nn.html#conv2d\n","\n","3ê³„ì¸µ ConvNetì„ êµ¬í˜„í•œ í›„ `test_ThreeLayerConvNet` í•¨ìˆ˜ê°€ êµ¬í˜„ì„ ì‹¤í–‰í•˜ë©´ ì¶œë ¥ ì ìˆ˜ì˜ ëª¨ì–‘ì— ëŒ€í•´ `(64, 10)`ì´ ì¶œë ¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"module_output_shape","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038865586,"user_tz":-540,"elapsed":8,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"dea5d698-96d4-43ba-f6c8-7c16e0690d91"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["class ThreeLayerConvNet(nn.Module):\n","    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n","        super().__init__()\n","        ########################################################################\n","        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n","        # architecture defined above.                                          #\n","        ########################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        self.conv1 = nn.Conv2d(in_channel, channel_1, kernel_size = 5, stride=1, padding=2, bias=True, padding_mode='zeros')\n","        nn.init.kaiming_normal_(self.conv1.weight)\n","        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_size = 3, stride=1, padding=1, bias=True, padding_mode='zeros')\n","        nn.init.kaiming_normal_(self.conv2.weight)\n","        self.fc = nn.Linear(channel_2 * 32 * 32,num_classes) ##Linearì˜ input channelì€ í•­ìƒ ê³„ì‚°í•´ì„œ ë„£ì–´ì¤˜ì•¼í•˜ëŠ”ì§€\n","        nn.init.kaiming_normal_(self.fc.weight)\n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ########################################################################\n","        #                          END OF YOUR CODE                            #\n","        ########################################################################\n","\n","    def forward(self, x):\n","        scores = None\n","        ########################################################################\n","        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n","        # should use the layers you defined in __init__ and specify the        #\n","        # connectivity of those layers in forward()                            #\n","        ########################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        A_1 = self.conv1(x)\n","        Z_1 = F.relu(A_1)\n","        A_2 = self.conv2(Z_1)\n","        Z_2 = F.relu(A_2)\n","        flatten_Z_2 = flatten(Z_2)\n","\n","        scores = self.fc(flatten_Z_2)\n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################\n","        return scores\n","\n","\n","def test_ThreeLayerConvNet():\n","    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n","    model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10)\n","    scores = model(x)\n","    print(scores.size())  # you should see [64, 10]\n","test_ThreeLayerConvNet()"]},{"cell_type":"markdown","metadata":{"id":"b3CDip-7pR2B"},"source":["### Module API: Check Accuracy\n","ê²€ì¦ ë˜ëŠ” í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ê°€ ì£¼ì–´ì§€ë©´ ì‹ ê²½ë§ì˜ ë¶„ë¥˜ ì •í™•ë„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ì´ ë²„ì „ì€ Part IIì˜ ë²„ì „ê³¼ ì•½ê°„ ë‹¤ë¦…ë‹ˆë‹¤. ë” ì´ìƒ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì „ë‹¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"7PYAZQ1DpR2B","executionInfo":{"status":"ok","timestamp":1690038865586,"user_tz":-540,"elapsed":5,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"outputs":[],"source":["def check_accuracy_part34(loader, model):\n","    if loader.dataset.train:\n","        print('Checking accuracy on validation set')\n","    else:\n","        print('Checking accuracy on test set')\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()  # set model to evaluation mode\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","            scores = model(x)\n","            _, preds = scores.max(1)\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"]},{"cell_type":"markdown","metadata":{"id":"Pb6341vOpR2B"},"source":["### Module API: Training Loop\n","ë˜í•œ ì•½ê°„ ë‹¤ë¥¸ training loopë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê°€ì¤‘ì¹˜ ê°’ì„ ì§ì ‘ ì—…ë°ì´íŠ¸í•˜ëŠ” ëŒ€ì‹ , Optimization ì•Œê³ ë¦¬ì¦˜ì˜ ê°œë…ì„ ì¶”ìƒí™”í•˜ê³  ì‹ ê²½ë§ ìµœì í™”ì— ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ì„ ì œê³µí•˜ëŠ” `torch.optim` íŒ¨í‚¤ì§€ì˜ Optimizer ê°ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"lY-B6AXbpR2B","executionInfo":{"status":"ok","timestamp":1690038865587,"user_tz":-540,"elapsed":6,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"outputs":[],"source":["def train_part34(model, optimizer, epochs=1):\n","    \"\"\"\n","    Train a model on CIFAR-10 using the PyTorch Module API.\n","\n","    Inputs:\n","    - model: A PyTorch Module giving the model to train.\n","    - optimizer: An Optimizer object we will use to train the model\n","    - epochs: (Optional) A Python integer giving the number of epochs to train for\n","\n","    Returns: Nothing, but prints model accuracies during training.\n","    \"\"\"\n","    model = model.to(device=device)  # move the model parameters to CPU/GPU\n","    for e in range(epochs):\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores = model(x)\n","            loss = F.cross_entropy(scores, y)\n","\n","            # Zero out all of the gradients for the variables which the optimizer\n","            # will update.\n","            optimizer.zero_grad()\n","\n","            # This is the backwards pass: compute the gradient of the loss with\n","            # respect to each  parameter of the model.\n","            loss.backward()\n","\n","            # Actually update the parameters of the model using the gradients\n","            # computed by the backwards pass.\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy_part34(loader_val, model)\n","                print()"]},{"cell_type":"markdown","metadata":{"id":"CMFEsm-OpR2C"},"source":["### Module API: Train a Two-Layer Network\n","ì´ì œ training loopë¥¼ ì‹¤í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. Part IIì™€ ë‹¬ë¦¬ ì´ë²ˆì—ëŠ” Parameter tensorsë¥¼ ë” ì´ìƒ ëª…ì‹œì ìœ¼ë¡œ í• ë‹¹í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n","\n","ì…ë ¥ í¬ê¸°, ìˆ¨ê²¨ì§„ ë ˆì´ì–´ í¬ê¸°, í´ë˜ìŠ¤ ìˆ˜(ì¦‰, ì¶œë ¥ í¬ê¸°)ë¥¼ `TwoLayerFC`ì˜ ìƒì„±ìì— ì „ë‹¬í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.\n","\n","ë˜í•œ `TwoLayerFC` ë‚´ì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì í•˜ëŠ” ì˜µí‹°ë§ˆì´ì €ë¥¼ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, í•œ epoch ë™ì•ˆ í•™ìŠµí•œ í›„ 40% ì´ìƒì˜ ëª¨ë¸ ì •í™•ë„ë¥¼ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"TCwaZfJTpR2C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038883905,"user_tz":-540,"elapsed":18324,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"b1ed1f9c-5ea9-40db-b013-6dbfb50023a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 3.5638\n","Checking accuracy on validation set\n","Got 148 / 1000 correct (14.80)\n","\n","Iteration 100, loss = 2.1056\n","Checking accuracy on validation set\n","Got 337 / 1000 correct (33.70)\n","\n","Iteration 200, loss = 2.0244\n","Checking accuracy on validation set\n","Got 409 / 1000 correct (40.90)\n","\n","Iteration 300, loss = 1.9611\n","Checking accuracy on validation set\n","Got 418 / 1000 correct (41.80)\n","\n","Iteration 400, loss = 1.9021\n","Checking accuracy on validation set\n","Got 390 / 1000 correct (39.00)\n","\n","Iteration 500, loss = 1.6553\n","Checking accuracy on validation set\n","Got 437 / 1000 correct (43.70)\n","\n","Iteration 600, loss = 1.8947\n","Checking accuracy on validation set\n","Got 405 / 1000 correct (40.50)\n","\n","Iteration 700, loss = 1.6947\n","Checking accuracy on validation set\n","Got 433 / 1000 correct (43.30)\n","\n"]}],"source":["hidden_layer_size = 4000\n","learning_rate = 1e-2\n","model = TwoLayerFC(3 * 32 * 32, hidden_layer_size, 10)\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"OvnHTm_MpR2C"},"source":["### Module API: Train a Three-Layer ConvNet\n","ì´ì œ Module APIë¥¼ ì‚¬ìš©í•˜ì—¬ CIFARì—ì„œ 3ê³„ì¸µ ConvNetì„ í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” 2ê³„ì¸µ ë„¤íŠ¸ì›Œí¬ í›ˆë ¨ê³¼ ë§¤ìš° ìœ ì‚¬í•˜ê²Œ ë³´ì¼ ê²ƒì…ë‹ˆë‹¤! í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, í•œ íšŒê¸° ë™ì•ˆ í›ˆë ¨í•œ í›„ 45% ì´ìƒì„ ë‹¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","Momentumì´ ì—†ëŠ” Stochastic gradient descentë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"module_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038918959,"user_tz":-540,"elapsed":35058,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"5060c340-9943-4103-efa5-b5ac3b959847"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.8246\n","Checking accuracy on validation set\n","Got 99 / 1000 correct (9.90)\n","\n","Iteration 100, loss = 1.8629\n","Checking accuracy on validation set\n","Got 347 / 1000 correct (34.70)\n","\n","Iteration 200, loss = 1.8717\n","Checking accuracy on validation set\n","Got 421 / 1000 correct (42.10)\n","\n","Iteration 300, loss = 1.5427\n","Checking accuracy on validation set\n","Got 446 / 1000 correct (44.60)\n","\n","Iteration 400, loss = 1.6517\n","Checking accuracy on validation set\n","Got 461 / 1000 correct (46.10)\n","\n","Iteration 500, loss = 1.3903\n","Checking accuracy on validation set\n","Got 480 / 1000 correct (48.00)\n","\n","Iteration 600, loss = 1.7687\n","Checking accuracy on validation set\n","Got 475 / 1000 correct (47.50)\n","\n","Iteration 700, loss = 1.3211\n","Checking accuracy on validation set\n","Got 493 / 1000 correct (49.30)\n","\n","Iteration 0, loss = 1.3906\n","Checking accuracy on validation set\n","Got 488 / 1000 correct (48.80)\n","\n","Iteration 100, loss = 1.4405\n","Checking accuracy on validation set\n","Got 502 / 1000 correct (50.20)\n","\n","Iteration 200, loss = 1.3856\n","Checking accuracy on validation set\n","Got 490 / 1000 correct (49.00)\n","\n","Iteration 300, loss = 1.2646\n","Checking accuracy on validation set\n","Got 498 / 1000 correct (49.80)\n","\n","Iteration 400, loss = 1.4873\n","Checking accuracy on validation set\n","Got 497 / 1000 correct (49.70)\n","\n","Iteration 500, loss = 1.2333\n","Checking accuracy on validation set\n","Got 505 / 1000 correct (50.50)\n","\n","Iteration 600, loss = 1.3669\n","Checking accuracy on validation set\n","Got 518 / 1000 correct (51.80)\n","\n","Iteration 700, loss = 1.5149\n","Checking accuracy on validation set\n","Got 512 / 1000 correct (51.20)\n","\n"]}],"source":["learning_rate = 3e-3\n","channel_1 = 32\n","channel_2 = 16\n","\n","model = None\n","optimizer = None\n","################################################################################\n","# TODO: Instantiate your ThreeLayerConvNet model and a corresponding optimizer #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","model = ThreeLayerConvNet(in_channel = 3, channel_1 = 32, channel_2 = 16, num_classes = 10)\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","train_part34(model, optimizer)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"lsFqIP43pR2D"},"source":["# Part IV. PyTorch Sequential API\n","\n","Part IIIì—ì„œëŠ” ì„ì˜ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ë ˆì´ì–´ì™€ ê·¸ ì—°ê²°ì„±ì„ ì •ì˜í•  ìˆ˜ ìˆëŠ” PyTorch ëª¨ë“ˆ APIë¥¼ ì†Œê°œí–ˆìŠµë‹ˆë‹¤.\n","\n","Feed forward layersê³¼ ê°™ì€ ê°„ë‹¨í•œ ëª¨ë¸ì˜ ê²½ìš°, `nn.Module` ì„œë¸Œí´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ê³ , `__init__`ì—ì„œ í´ë˜ìŠ¤ ì†ì„±ì— ë ˆì´ì–´ë¥¼ í• ë‹¹í•˜ê³ , `forward()`ì—ì„œ ê° ë ˆì´ì–´ë¥¼ í•˜ë‚˜ì”© í˜¸ì¶œí•˜ëŠ” 3ë‹¨ê³„ë¥¼ ê±°ì³ì•¼ í•©ë‹ˆë‹¤. ë” í¸ë¦¬í•œ ë°©ë²•ì´ ìˆì„ê¹Œìš”?\n","\n","ë‹¤í–‰íˆë„ PyTorchì—ì„œëŠ” ìœ„ì˜ ë‹¨ê³„ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹œ `nn.Sequential`ì´ë¼ëŠ” ì»¨í…Œì´ë„ˆ ëª¨ë“ˆì„ ì œê³µí•©ë‹ˆë‹¤. feed forward stacksë³´ë‹¤ ë” ë³µì¡í•œ topologyë¥¼ ì§€ì •í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— `nn.Module`ë§Œí¼ ìœ ì—°í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ë§ì€ ì‚¬ìš© ì‚¬ë¡€ì— ì¶©ë¶„í•©ë‹ˆë‹¤.\n","\n","### Sequential API: 2ê³„ì¸µ ë„¤íŠ¸ì›Œí¬\n","`nn.Sequential`ì„ ì‚¬ìš©í•˜ì—¬ 2ê³„ì¸µ fully connected ë„¤íŠ¸ì›Œí¬ ì˜ˆì œë¥¼ ë‹¤ì‹œ ì‘ì„±í•˜ê³  ìœ„ì—ì„œ ì •ì˜í•œ training loopë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì´ë‹í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë´…ì‹œë‹¤.\n","\n","ì—¬ê¸°ì„œë„ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, í•œ ë²ˆì˜ í›ˆë ¨ í›„ì—ëŠ” 40% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"hTN-_2OmpR2D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038941198,"user_tz":-540,"elapsed":22254,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"1f1536b4-3413-4ca0-d3b2-45bb62880588"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.3326\n","Checking accuracy on validation set\n","Got 124 / 1000 correct (12.40)\n","\n","Iteration 100, loss = 1.8909\n","Checking accuracy on validation set\n","Got 390 / 1000 correct (39.00)\n","\n","Iteration 200, loss = 1.7270\n","Checking accuracy on validation set\n","Got 394 / 1000 correct (39.40)\n","\n","Iteration 300, loss = 1.6427\n","Checking accuracy on validation set\n","Got 433 / 1000 correct (43.30)\n","\n","Iteration 400, loss = 2.0764\n","Checking accuracy on validation set\n","Got 427 / 1000 correct (42.70)\n","\n","Iteration 500, loss = 1.9092\n","Checking accuracy on validation set\n","Got 426 / 1000 correct (42.60)\n","\n","Iteration 600, loss = 1.7882\n","Checking accuracy on validation set\n","Got 433 / 1000 correct (43.30)\n","\n","Iteration 700, loss = 1.4243\n","Checking accuracy on validation set\n","Got 430 / 1000 correct (43.00)\n","\n"]}],"source":["# We need to wrap `flatten` function in a module in order to stack it\n","# in nn.Sequential\n","class Flatten(nn.Module):\n","    def forward(self, x):\n","        return flatten(x)\n","\n","hidden_layer_size = 4000\n","learning_rate = 1e-2\n","\n","model = nn.Sequential(\n","    Flatten(),\n","    nn.Linear(3 * 32 * 32, hidden_layer_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_layer_size, 10),\n",")\n","\n","# you can use Nesterov momentum in optim.SGD\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n","                     momentum=0.9, nesterov=True)\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"Ppx-dXtZpR2D"},"source":["### Sequential API: Three-Layer ConvNet\n","ì—¬ê¸°ì„œëŠ” `nn.Sequential`ì„ ì‚¬ìš©í•˜ì—¬ Part IIIì—ì„œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•œ ì•„í‚¤í…ì²˜ë¡œ 3ê³„ì¸µ ConvNetì„ ì •ì˜í•˜ê³  í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤:\n","\n","1. 32ê°œì˜ 5x5 í•„í„°ê°€ ìˆëŠ” Convolution ë ˆì´ì–´(ë°”ì´ì–´ìŠ¤ í¬í•¨), zero-paddingì€ 2ì…ë‹ˆë‹¤.\n","2. ReLU\n","3. 16ê°œì˜ 3x3 í•„í„°ê°€ ìˆëŠ” Convolution ë ˆì´ì–´(ë°”ì´ì–´ìŠ¤ í¬í•¨), zero-padding 1\n","4. ReLU\n","5. 10ê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ  fully-connected layer(ë°”ì´ì–´ìŠ¤ í¬í•¨)\n","\n","ê¸°ë³¸ PyTorch ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","Nesterov momentum 0.9ì˜ í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ìµœì í™”í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","ë‹¤ì‹œ ë§í•˜ì§€ë§Œ, í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ í•œ ë²ˆì˜ í›ˆë ¨ í›„ì—ëŠ” 55% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CP6-UsQtzMeI","executionInfo":{"status":"aborted","timestamp":1689914896539,"user_tz":-540,"elapsed":6,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"outputs":[],"source":["channel_1 = 32\n","channel_2 = 16\n","learning_rate = 1e-2\n","\n","model = None\n","optimizer = None\n","\n","################################################################################\n","# TODO: Rewrite the 2-layer ConvNet with bias from Part III with the           #\n","# Sequential API.                                                              #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","model = nn.Sequential(\n","    nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 5, stride=1, padding=2, bias=True, padding_mode='zeros'),\n","    nn.ReLU(),\n","    nn.Conv2d(in_channels = 32, out_channels = 16, kernel_size = 3, stride=1, padding=1, bias=True, padding_mode='zeros'),\n","    nn.ReLU(),\n","    Flatten(),\n","    nn.Linear(16 * 32 * 32, 10)\n",")\n","\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n","                     momentum=0.9, nesterov=True)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"8AhsbVrNoPt7"},"source":["# Let's do this! - Reimplement AlexNet\n","ì´ì œ PyTorchì˜ ê¸°ë³¸ì ì¸ ì‚¬ìš©ë²•ì„ ëª¨ë‘ ë°°ì›Œ ë´¤ìŠµë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ë°°ì› ë˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ Deep Into Deep ìˆ˜ì—… ì¤‘ì— ë‹¤ë£¨ì—ˆë˜ ëª¨ë¸ ì¤‘ í•˜ë‚˜ì¸ [AlexNet](https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)ì„ ì¬êµ¬í˜„í•´ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n"]},{"cell_type":"markdown","metadata":{"id":"DdF9qsXnLi_W"},"source":["## AlexNet Architecture\n","AlexNetì˜ ì „ì²´ì ì¸ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gl7KqYljPjbO","executionInfo":{"status":"aborted","timestamp":1689914896540,"user_tz":-540,"elapsed":7,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","\n","images = './notebook_images/AlexNet_Architecture.png'\n","image = cv2.imread(images)\n","cv2_imshow(image)"]},{"cell_type":"markdown","metadata":{"id":"kESoCsqDQuLX"},"source":["## êµ¬í˜„ ì„¸ë¶€ì‚¬í•­\n","ì´ ê·¸ë¦¼ì„ ë°”íƒ•ìœ¼ë¡œ AlexNetì„ ì¬êµ¬í˜„ í•´ ë´…ì‹œë‹¤. ê·¸ëŸ¬ê¸° ìœ„í•´ì„œ ëª‡ ê°€ì§€ ì•Œê³  ë„˜ì–´ê°€ì•¼í•  ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤.\n","\n","AlexNetì˜ Input DataëŠ” ì›ë˜ 3x224x224ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” ì§€ê¸ˆ 3x32x32ì¸ CIFAR-10 Datasetì— ëŒ€í•´ì„œ ì‹¤í—˜ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— Input Dataì˜ dimensionì„ ë§ì¶°ì£¼ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n","\n","PyTorchì—ëŠ” ì´ë¥¼ ìœ„í•œ Upsample í´ë˜ìŠ¤ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n","\n","```\n","nn.Upsample(size=(224,224))\n","```\n","\n","> **ì£¼ì˜** : ì´ëŠ” ì‹¤í—˜ì˜ í¸ì˜ì„±ì„ ìœ„í•´ ì‚¬ìš©í•œ ë°©ì‹ì…ë‹ˆë‹¤. ì‹¤ì œë¡œ ë…¼ë¬¸ì„ ì¬êµ¬í˜„ í•  ë•Œì—ëŠ” ì‹¤í—˜ì´ ì§„í–‰ëœ Dataì™€ ë™ì¼í•œ dimensionì˜ Dataë¥¼ ì‚¬ìš©í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\n","\n","+ ì¶”ê°€ë¡œ, Deep Learning ë¶„ì•¼ì—ì„œ ë§ì´ í™”ì œê°€ ë˜ì—ˆë˜ ì´ì•¼ê¸° ì¤‘ í•˜ë‚˜ê°€ Input dimensionì´ ë§ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì´ì—ˆìŠµë‹ˆë‹¤. ë…¼ë¬¸ì—ì„œ ì²«ë²ˆì§¸ Convolution Layerì—ì„œ filter sizeê°€ 11ì´ê³ , strideê°€ 4ë¼ëŠ” ê²ƒë§Œ ì–¸ê¸‰ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê·¸ ë•Œ output volumeì„ ê³„ì‚°í•´ ë³´ë©´ ì •ìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤. ë§ì€ ì£¼ì¥ì´ ìˆì—ˆì§€ë§Œ ì €ìê°€ Padding 3ë¥¼ ë¹¼ë¨¹ì—ˆë‹¤ê³  ìƒê°í•´, ë³¸ êµ¬í˜„ì—ì„œë„ Padding 3ì„ ì¤¬ìŠµë‹ˆë‹¤.\n","\n","ë˜í•œ, AlexNetì€ GPU ë‘ ê°œì—ì„œ ëª¨ë¸ì„ ëŒë¦¬ê¸° ìœ„í•´ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. 2012ë…„ AlexNetì´ êµ¬í˜„ë  ë•Œì™€ ë‹¬ë¦¬ ì§€ê¸ˆì€ GPU ì„±ëŠ¥ì´ ë§ì´ ë°œì „í•˜ì—¬, í•˜ë‚˜ì˜ GPUì—ì„œë„ ì¶©ë¶„íˆ ì´ë¥¼ ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ì˜ GPUì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ëª¨ë¸ì„ ìˆ˜ì •í•´ì„œ ì‹¤í—˜í•´ ë´…ì‹œë‹¤.\n","\n","ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ìœ—ìª½ê³¼ ì•„ë˜ìª½ CNN Layerê°€ ìˆìŠµë‹ˆë‹¤. ì´ Layerë“¤ì„ í•˜ë‚˜ë¡œ í•©í•œë‹¤ë©´, feature ìˆ˜ê°€ ëŠ˜ì–´ë‚œë‹¤ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì²« ë²ˆì§¸ CNN LayerëŠ” 48ê°œì˜ filterê°€ ë‘ ê°œ ìˆëŠ”ë°, ì´ë¥¼ 96ê°œì˜ filterê°€ ìˆë‹¤ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤.\n","\n","Fully-Connected Layer ë˜í•œ 2048 + 2048 = 4096ê°œì˜ featureë¥¼ ê°€ì§„ë‹¤ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤.\n","\n","**ì¬êµ¬í˜„ì€ Module APIë¥¼ ì‚¬ìš©í•´ë„ ì¢‹ê³ , Sequential APIë¥¼ ì‚¬ìš©í•´ë„ ì¢‹ìŠµë‹ˆë‹¤. ê¶Œíˆ¬ë¥¼ ë¹•ë‹ˆë‹¤!**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2l01XXCQQP2G"},"source":["## AlexNet Architecture Summary\n","ë‹¤ìŒì€ ë…¼ë¬¸ì— ë‚˜ì˜¨ AlexNetì˜ êµ¬ì¡°ë¥¼ ìš”ì•½í•œ ê²ƒì…ë‹ˆë‹¤. êµ¬í˜„ì— ì°¸ê³ í•´ ì£¼ì„¸ìš”.\n","### features\n","|Layer|# of filters|Filter Size|Stride|Padding|Size of feature map|Activation|\n","|:-----|:-----------|:----|:-----------|:------|:----------|:--|\n","|Input Image|-|-|-|-|3x32x32|-|\n","|Upsample|-|-|-|-|3x224x224|-|\n","|Convolution 1|96|11x11|4|3|55x55x96|ReLU|\n","|Max Pooling 1|-|3x3|2|-|27x27x96|-|\n","|Convolution 2|256|5x5|2|-|27x27x256|ReLU|\n","|Max Pooling 2|-|3x3|2|-|13x13x256|-|\n","|Convolution 3|384|3x3|1|1|13x13x384|ReLU|\n","|Convolution 4|384|3x3|1|1|13x13x384|ReLU|\n","|Convolution 5|256|3x3|1|1|13x13x256|ReLU|\n","|Max Pooling 3|-|3x3|2|-|6x6x256|-|\n","\n","### classifier\n","|Layer|in_feature|out_feature|dropout rate|Activation|\n","|:----|:---------|:----------|:-----------|:---------|\n","|Flatten|-|-|-|-|\n","|Dropout 1|-|-|0.5|-|\n","|Fully-Connected 1|9216|4096|-|ReLU|\n","|Dropout 2|-|-|0.5|-|\n","|Fully-Connected 2|4096|4096|-|ReLU|\n","|Fully-Connected 3|4096|10|-|-|\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sequential_accuracy","executionInfo":{"status":"aborted","timestamp":1689914896540,"user_tz":-540,"elapsed":6,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"outputs":[],"source":["learning_rate = 1e-4\n","\n","model = None\n","optimizer = None\n","\n","################################################################################\n","# TODO: Reimplement AlexNet                                                    #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","class AlexNet(nn.Module):\n","  def __init__(self, num_classes):\n","    super(AlexNet,self).__init__()\n","    self.upsample = nn.Upsample(size = (227,227))\n","    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 96, kernel_size = 11, stride= 4, padding = 0, bias=True, padding_mode='zeros')\n","    self.maxpool1 = nn.MaxPool2d(kernel_size = 3, stride= 2, padding=0)\n","    self.conv2 = nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size = 5, stride= 1, padding = 2, bias=True, padding_mode='zeros')\n","    self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride= 2, padding=0)\n","    self.conv3 = nn.Conv2d(in_channels = 256, out_channels = 384, kernel_size = 3, stride= 1, padding = 1, bias=True, padding_mode='zeros')\n","    self.conv4 = nn.Conv2d(in_channels = 384, out_channels = 384, kernel_size = 3, stride= 1, padding = 1, bias=True, padding_mode='zeros')\n","    self.conv5 = nn.Conv2d(in_channels = 384, out_channels = 256, kernel_size = 3, stride= 1, padding = 1, bias=True, padding_mode='zeros')\n","    self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride= 2, padding=0)\n","\n","    self.dropout1 = nn.Dropout(p=0.5, inplace=False)\n","    self.fc1 = nn.Linear(9216, 4096)\n","    self.dropout2 = nn.Dropout(p=0.5, inplace=False)\n","    self.fc2 = nn.Linear(4096,4096)\n","    self.fc3 = nn.Linear(4096, num_classes)\n","\n","  def forward(self,x):\n","    scores = None\n","\n","    upsampled_x = self.upsample(x)\n","    A_1 = self.conv1(upsampled_x)\n","    Z_1 = F.relu(A_1)\n","    maxpool_Z_1 = self.maxpool1(Z_1)\n","\n","    A_2 = self.conv2(maxpool_Z_1)\n","    Z_2 = F.relu(A_2)\n","    maxpool_Z_2 = self.maxpool2(Z_2)\n","\n","    A_3 = self.conv3(maxpool_Z_2)\n","    Z_3 = F.relu(A_3)\n","    A_4 = self.conv4(Z_3)\n","    Z_4 = F.relu(A_4)\n","    A_5 = self.conv5(Z_4)\n","    Z_5 = F.relu(A_5)\n","    maxpool_Z_5 = self.maxpool3(Z_5)\n","\n","    flatten_feature = flatten(maxpool_Z_5)\n","    dropout1_flatten_feature = self.dropout1(flatten_feature)\n","    A_6 = self.fc1(dropout1_flatten_feature)\n","    Z_6 = F.relu(A_6)\n","    dropout2_Z_6 = self.dropout2(Z_6)\n","    A_7 = self.fc2(dropout2_Z_6)\n","    Z_7 = F.relu(A_7)\n","    A_8 = self.fc3(Z_7)\n","\n","    scores = A_8\n","\n","    return scores\n","\n","model = AlexNet(num_classes = 10)\n","optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n","#optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n","#                    momentum=0.9, nesterov=True)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","train_part34(model, optimizer, epochs=10)"]},{"cell_type":"markdown","metadata":{"id":"yTQNIdymfthW"},"source":["## Describe what you did\n","\n","ì¬êµ¬í˜„ì— ì„±ê³µí–ˆë‚˜ìš”? ì‹¤íŒ¨í–ˆë‹¤ë©´ ì–´ë–¤ ì ì´ ì–´ë ¤ì› ë‚˜ìš”? ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë¹„êµí–ˆì„ ë•Œ ë” ì¢‹ì€ ì„±ëŠ¥ì´ ë‚˜ì™”ë‚˜ìš”? í˜¹ì€ ILSVRC'12ì™€ ë¹„ìŠ·í•œ ì„±ëŠ¥ì¸ê°€ìš”? ë§Œì•½ ê¸°ëŒ€í•˜ë˜ ì„±ëŠ¥ì´ ì•ˆ ë‚˜ì™”ë‹¤ë©´ ì–´ë–¤ ë¬¸ì œê°€ ìˆì—ˆì„ê¹Œìš”? ììœ ë¡­ê²Œ ìƒê°ì„ ì ì–´ì£¼ì„¸ìš”."]},{"cell_type":"markdown","metadata":{"id":"V4ueerblf7FI"},"source":["**Answer:**\n","\n","ì„±ëŠ¥ì´ ì „í˜€ ë‚˜ì˜¤ì§ˆ ì•Šì•˜ëŠ”ë° ì´ëŠ” 32 X 32 X 3 dataë¥¼ ê°•ì œë¡œ upsampling í–ˆê¸° ë•Œë¬¸ì´ë¼ê³  ìƒê°í•œë‹¤.\n","\n","ì¶”ê°€ì ìœ¼ë¡œ AlexNetì˜ êµ¬ì¡°ì—ëŠ” LRN êµ¬ì¡°ë„ ë“¤ì–´ê°€ ìˆëŠ”ë° ë³¸ êµ¬ì¡°ì—ëŠ” LRNì„ ë„£ê¸° ì•Šì€ ê²ƒë„ ì´ìœ ì¼ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ..\n","\n","- ì•„ë‹ˆë‹¤. ë§ˆì§€ë§‰ Layerì— RELUë¥¼ ë„£ì–´ì„œ ì„±ëŠ¥ì´ ì•„ì˜ˆ ì•ˆë‚˜ì˜¨ ê²ƒì´ì—ˆë‹¤. ë˜‘ë°”ë¡œ ë³´ì!!!!"]},{"cell_type":"markdown","metadata":{"id":"Iq-i0xoUpR2E"},"source":["# Part V. CIFAR-10 open-ended challenge\n","\n","ì´ sectionì—ì„œëŠ” CIFAR-10ì—ì„œ ì›í•˜ëŠ” ConvNet ì•„í‚¤í…ì²˜ë¥¼ ì‹¤í—˜í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ì´ì œ ì—¬ëŸ¬ë¶„ì´ í•  ì¼ì€ ì•„í‚¤í…ì²˜, í•˜ì´í¼íŒŒë¼ë¯¸í„°, loss í•¨ìˆ˜, Optimizerë¥¼ ì‹¤í—˜í•˜ì—¬ 10ê°œ epoch ì´ë‚´ì— CIFAR-10 **Validation** ì„¸íŠ¸ì—ì„œ **70% ì´ìƒ** ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ëŠ” ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ìœ„ì—ì„œ í™•ì¸_ì •í™•ë„ ë° í›ˆë ¨ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `nn.Module` ë˜ëŠ” `nn.Sequential` APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ì´ ë…¸íŠ¸ë¶ì˜ ë§ˆì§€ë§‰ì— ì—¬ëŸ¬ë¶„ì´ ìˆ˜í–‰í•œ ì‘ì—…ì„ ì„¤ëª…í•˜ì„¸ìš”.\n","\n","ë‹¤ìŒì€ ê° êµ¬ì„± ìš”ì†Œì— ëŒ€í•œ ê³µì‹ API ë¬¸ì„œì…ë‹ˆë‹¤. í•œ ê°€ì§€ ì°¸ê³  ì‚¬í•­: \"spatial batch norm\" í´ë˜ìŠ¤ì—ì„œ í˜¸ì¶œí•˜ëŠ” ê²ƒì„ PyTorchì—ì„œëŠ” \"BatchNorm2D\"ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n","\n","* Layers in torch.nn package: http://pytorch.org/docs/stable/nn.html\n","* Activations: http://pytorch.org/docs/stable/nn.html#non-linear-activations\n","* Loss functions: http://pytorch.org/docs/stable/nn.html#loss-functions\n","* Optimizers: http://pytorch.org/docs/stable/optim.html\n","\n","\n","### ì‹œë„í•´ ë³¼ë§Œí•œ ì¼:\n","- **Filter size**: ìœ„ì—ì„œëŠ” 5x5ë¥¼ ì‚¬ìš©í–ˆëŠ”ë°, ë” ì‘ì€ í•„í„°ê°€ ë” íš¨ìœ¨ì ì¼ê¹Œìš”?\n","- **Filters ìˆ˜**: ìœ„ì—ì„œëŠ” 32ê°œì˜ í•„í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. í•„í„° ìˆ˜ê°€ ë§ê±°ë‚˜ ì ì„ìˆ˜ë¡ ë” íš¨ìœ¨ì ì¼ê¹Œìš”?\n","- **Pooling vs Strided Convolution**: max poolingì„ ì‚¬ìš©í•˜ë‚˜ìš”, ì•„ë‹ˆë©´ Strided Convolutionë§Œ ì‚¬ìš©í•˜ë‚˜ìš”?\n","- **Batch normalization**: Convolutional Layer ë’¤ì— spatial batch normalizationì„, affine ë ˆì´ì–´ ë’¤ì— vanilla batch normalizationì„ ì¶”ê°€í•´ ë³´ì„¸ìš”. ë„¤íŠ¸ì›Œí¬ê°€ ë” ë¹ ë¥´ê²Œ í›ˆë ¨ë˜ë‚˜ìš”?\n","- **ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜**: ìœ„ì˜ ë„¤íŠ¸ì›Œí¬ì—ëŠ” ë‘ ê°œì˜ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ë ˆì´ì–´ê°€ ìˆìŠµë‹ˆë‹¤. ì‹¬ì¸µ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì˜í•  ìˆ˜ ìˆë‚˜ìš”? ì‹œë„í•´ ë³¼ ë§Œí•œ ì¢‹ì€ ì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n","    - [conv-relu-pool]xN -> [affine]xM -> [softmax ë˜ëŠ” SVM]\n","    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax ë˜ëŠ” SVM]\n","    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax ë˜ëŠ” SVM]\n","- **Global Average Pooling**: í‰í‰í•˜ê²Œ í•œ ë‹¤ìŒ ì—¬ëŸ¬ ê°œì˜ Affine ë ˆì´ì–´ë¥¼ ê°–ëŠ” ëŒ€ì‹  ì´ë¯¸ì§€ê°€ ì‘ì•„ì§ˆ ë•Œê¹Œì§€ Convolutionì„ ìˆ˜í–‰í•œ ë‹¤ìŒ(7x7 ì •ë„) Average Pooling ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì—¬ 1x1 ì´ë¯¸ì§€ ì‚¬ì§„(1, 1 , Filter#)ì„ ì–»ì€ ë‹¤ìŒ (Filter#) ë²¡í„°ë¡œ ì¬í˜•ì„±í•©ë‹ˆë‹¤. ì´ ë°©ì‹ì€ [Google's Inception Network](https://arxiv.org/abs/1512.00567)ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤(ì•„í‚¤í…ì²˜ëŠ” í‘œ 1 ì°¸ì¡°).\n","- **Regularization**: l2 ê°€ì¤‘ì¹˜ regulariztionë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ Dropoutì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","### Tips for training\n","ì‹œë„í•˜ëŠ” ê° ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ì— ëŒ€í•´ í•™ìŠµ ì†ë„ì™€ ê¸°íƒ€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œ ëª…ì‹¬í•´ì•¼ í•  ëª‡ ê°€ì§€ ì¤‘ìš”í•œ ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤:\n","\n","- ë§¤ê°œë³€ìˆ˜ê°€ ì˜ ì‘ë™í•˜ëŠ” ê²½ìš° ìˆ˜ë°± ë²ˆì˜ ë°˜ë³µì„ í†µí•´ ê°œì„  íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n","- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìœ„í•œ ê±°ì¹ ê³  ì„¸ë°€í•œ ì ‘ê·¼ ë°©ì‹ì„ ê¸°ì–µí•˜ì„¸ìš”. ëª‡ ë²ˆì˜ í•™ìŠµ ë°˜ë³µë§Œìœ¼ë¡œ ê´‘ë²”ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í…ŒìŠ¤íŠ¸í•˜ì—¬ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ” íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ì°¾ëŠ” ê²ƒë¶€í„° ì‹œì‘í•˜ì„¸ìš”.\n","- íš¨ê³¼ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ëª‡ ê°€ì§€ íŒŒë¼ë¯¸í„° ì„¸íŠ¸ë¥¼ ì°¾ìœ¼ë©´ í•´ë‹¹ íŒŒë¼ë¯¸í„°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë” ì„¸ë°€í•˜ê²Œ ê²€ìƒ‰í•˜ì„¸ìš”. ë” ë§ì€ epochì— ëŒ€í•´ í›ˆë ¨í•´ì•¼ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n","- í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ì—ëŠ” ìœ íš¨ì„± ê²€ì‚¬ ì§‘í•©ì„ ì‚¬ìš©í•˜ê³ , ìœ íš¨ì„± ê²€ì‚¬ ì§‘í•©ì—ì„œ ì„ íƒí•œ ìµœìƒì˜ íŒŒë¼ë¯¸í„°ë¡œ ì•„í‚¤í…ì²˜ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ í…ŒìŠ¤íŠ¸ ì§‘í•©ì„ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","### Going above and beyond\n","ëª¨í—˜ì‹¬ì´ ê°•í•˜ë‹¤ë©´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ êµ¬í˜„í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ê¸°ëŠ¥ë„ ë§ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ì„ ë°˜ë“œì‹œ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆì§€ë§Œ, ì‹œê°„ì´ ëœë‹¤ë©´ ê·¸ ì¬ë¯¸ë¥¼ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”!\n","\n","- ëŒ€ì²´ optimizers: Adam, Adagrad, RMSprop ë“±ì„ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","- Leaky ReLU, parametric ReLU, ELU ë˜ëŠ” MaxOutê³¼ ê°™ì€ ëŒ€ì²´ Activation í•¨ìˆ˜.\n","- Model ensembles\n","- Data augmentation\n","- ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜\n","  - [ResNets](https://arxiv.org/abs/1512.03385) ì´ì „ ë ˆì´ì–´ì˜ ì…ë ¥ì´ ì¶œë ¥ì— ì¶”ê°€ë©ë‹ˆë‹¤.\n","  - [DenseNets](https://arxiv.org/abs/1608.06993) ì´ì „ ë ˆì´ì–´ì— ëŒ€í•œ ì…ë ¥ì´ ì„œë¡œ ì—°ê²°ë˜ëŠ” ê³³ì…ë‹ˆë‹¤.\n","  - [ì´ ë¸”ë¡œê·¸ì—ì„œ ìì„¸í•œ ê°œìš”ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n","\n","### Have fun and happy training!"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"uWsuRLTjfoRa","executionInfo":{"status":"ok","timestamp":1689916613642,"user_tz":-540,"elapsed":1524,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"outputs":[],"source":["def train_part5(model, optimizer, epochs=1):\n","    \"\"\"\n","    Train a model on CIFAR-10 using the PyTorch Module API.\n","\n","    Inputs:\n","    - model: A PyTorch Module giving the model to train.\n","    - optimizer: An Optimizer object we will use to train the model\n","    - epochs: (Optional) A Python integer giving the number of epochs to train for\n","\n","    Returns: Nothing, but prints model accuracies during training.\n","    \"\"\"\n","    avg_losses = []\n","    model = model.to(device=device)  # move the model parameters to CPU/GPU\n","    for e in range(epochs):\n","        avg_loss = 0.0\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores = model(x)\n","            loss = F.cross_entropy(scores, y)\n","\n","            # Zero out all of the gradients for the variables which the optimizer\n","            # will update.\n","            optimizer.zero_grad()\n","\n","            # This is the backwards pass: compute the gradient of the loss with\n","            # respect to each  parameter of the model.\n","            loss.backward()\n","\n","            # Actually update the parameters of the model using the gradients\n","            # computed by the backwards pass.\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy_part34(loader_val, model)\n","                print()\n","\n","            avg_loss += loss.item()\n","        avg_losses.append(avg_loss / len(loader_train))\n","    return avg_losses"]},{"cell_type":"markdown","source":["auxiliary loss ì‚¬ìš© x"],"metadata":{"id":"UEk22c6r3fpt"}},{"cell_type":"code","execution_count":49,"metadata":{"id":"open_ended_accuracy","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1689918654622,"user_tz":-540,"elapsed":1994753,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"0273b123-962b-4163-e1ca-257c569cbec3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.3620\n","Checking accuracy on validation set\n","Got 105 / 1000 correct (10.50)\n","\n","Iteration 100, loss = 1.8140\n","Checking accuracy on validation set\n","Got 284 / 1000 correct (28.40)\n","\n","Iteration 200, loss = 2.1421\n","Checking accuracy on validation set\n","Got 336 / 1000 correct (33.60)\n","\n","Iteration 300, loss = 1.7402\n","Checking accuracy on validation set\n","Got 368 / 1000 correct (36.80)\n","\n","Iteration 400, loss = 1.8479\n","Checking accuracy on validation set\n","Got 430 / 1000 correct (43.00)\n","\n","Iteration 500, loss = 1.3086\n","Checking accuracy on validation set\n","Got 457 / 1000 correct (45.70)\n","\n","Iteration 600, loss = 1.4314\n","Checking accuracy on validation set\n","Got 520 / 1000 correct (52.00)\n","\n","Iteration 700, loss = 1.4886\n","Checking accuracy on validation set\n","Got 468 / 1000 correct (46.80)\n","\n","Iteration 0, loss = 1.2705\n","Checking accuracy on validation set\n","Got 540 / 1000 correct (54.00)\n","\n","Iteration 100, loss = 1.0071\n","Checking accuracy on validation set\n","Got 494 / 1000 correct (49.40)\n","\n","Iteration 200, loss = 1.3555\n","Checking accuracy on validation set\n","Got 583 / 1000 correct (58.30)\n","\n","Iteration 300, loss = 1.1130\n","Checking accuracy on validation set\n","Got 597 / 1000 correct (59.70)\n","\n","Iteration 400, loss = 1.2252\n","Checking accuracy on validation set\n","Got 587 / 1000 correct (58.70)\n","\n","Iteration 500, loss = 1.0151\n","Checking accuracy on validation set\n","Got 564 / 1000 correct (56.40)\n","\n","Iteration 600, loss = 1.0697\n","Checking accuracy on validation set\n","Got 623 / 1000 correct (62.30)\n","\n","Iteration 700, loss = 1.0004\n","Checking accuracy on validation set\n","Got 609 / 1000 correct (60.90)\n","\n","Iteration 0, loss = 0.8641\n","Checking accuracy on validation set\n","Got 669 / 1000 correct (66.90)\n","\n","Iteration 100, loss = 0.8398\n","Checking accuracy on validation set\n","Got 611 / 1000 correct (61.10)\n","\n","Iteration 200, loss = 0.9429\n","Checking accuracy on validation set\n","Got 613 / 1000 correct (61.30)\n","\n","Iteration 300, loss = 0.7814\n","Checking accuracy on validation set\n","Got 678 / 1000 correct (67.80)\n","\n","Iteration 400, loss = 0.7884\n","Checking accuracy on validation set\n","Got 655 / 1000 correct (65.50)\n","\n","Iteration 500, loss = 1.0652\n","Checking accuracy on validation set\n","Got 688 / 1000 correct (68.80)\n","\n","Iteration 600, loss = 0.8295\n","Checking accuracy on validation set\n","Got 714 / 1000 correct (71.40)\n","\n","Iteration 700, loss = 0.5542\n","Checking accuracy on validation set\n","Got 685 / 1000 correct (68.50)\n","\n","Iteration 0, loss = 1.0469\n","Checking accuracy on validation set\n","Got 670 / 1000 correct (67.00)\n","\n","Iteration 100, loss = 0.6959\n","Checking accuracy on validation set\n","Got 690 / 1000 correct (69.00)\n","\n","Iteration 200, loss = 0.6102\n","Checking accuracy on validation set\n","Got 693 / 1000 correct (69.30)\n","\n","Iteration 300, loss = 0.6960\n","Checking accuracy on validation set\n","Got 738 / 1000 correct (73.80)\n","\n","Iteration 400, loss = 0.8257\n","Checking accuracy on validation set\n","Got 737 / 1000 correct (73.70)\n","\n","Iteration 500, loss = 0.7858\n","Checking accuracy on validation set\n","Got 738 / 1000 correct (73.80)\n","\n","Iteration 600, loss = 0.5755\n","Checking accuracy on validation set\n","Got 744 / 1000 correct (74.40)\n","\n","Iteration 700, loss = 0.6899\n","Checking accuracy on validation set\n","Got 719 / 1000 correct (71.90)\n","\n","Iteration 0, loss = 0.5731\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 100, loss = 0.5756\n","Checking accuracy on validation set\n","Got 764 / 1000 correct (76.40)\n","\n","Iteration 200, loss = 0.7609\n","Checking accuracy on validation set\n","Got 704 / 1000 correct (70.40)\n","\n","Iteration 300, loss = 0.5654\n","Checking accuracy on validation set\n","Got 750 / 1000 correct (75.00)\n","\n","Iteration 400, loss = 0.6332\n","Checking accuracy on validation set\n","Got 759 / 1000 correct (75.90)\n","\n","Iteration 500, loss = 0.4052\n","Checking accuracy on validation set\n","Got 761 / 1000 correct (76.10)\n","\n","Iteration 600, loss = 0.9023\n","Checking accuracy on validation set\n","Got 757 / 1000 correct (75.70)\n","\n","Iteration 700, loss = 0.8680\n","Checking accuracy on validation set\n","Got 802 / 1000 correct (80.20)\n","\n","Iteration 0, loss = 0.6351\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 100, loss = 0.4850\n","Checking accuracy on validation set\n","Got 753 / 1000 correct (75.30)\n","\n","Iteration 200, loss = 0.3492\n","Checking accuracy on validation set\n","Got 779 / 1000 correct (77.90)\n","\n","Iteration 300, loss = 0.5605\n","Checking accuracy on validation set\n","Got 803 / 1000 correct (80.30)\n","\n","Iteration 400, loss = 0.5103\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Iteration 500, loss = 0.3832\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 600, loss = 0.4836\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 700, loss = 0.7519\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 0, loss = 0.4158\n","Checking accuracy on validation set\n","Got 809 / 1000 correct (80.90)\n","\n","Iteration 100, loss = 0.3713\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 200, loss = 0.5052\n","Checking accuracy on validation set\n","Got 822 / 1000 correct (82.20)\n","\n","Iteration 300, loss = 0.6827\n","Checking accuracy on validation set\n","Got 808 / 1000 correct (80.80)\n","\n","Iteration 400, loss = 0.4426\n","Checking accuracy on validation set\n","Got 817 / 1000 correct (81.70)\n","\n","Iteration 500, loss = 0.8007\n","Checking accuracy on validation set\n","Got 828 / 1000 correct (82.80)\n","\n","Iteration 600, loss = 0.4695\n","Checking accuracy on validation set\n","Got 804 / 1000 correct (80.40)\n","\n","Iteration 700, loss = 0.3731\n","Checking accuracy on validation set\n","Got 818 / 1000 correct (81.80)\n","\n","Iteration 0, loss = 0.4148\n","Checking accuracy on validation set\n","Got 823 / 1000 correct (82.30)\n","\n","Iteration 100, loss = 0.3909\n","Checking accuracy on validation set\n","Got 813 / 1000 correct (81.30)\n","\n","Iteration 200, loss = 0.4122\n","Checking accuracy on validation set\n","Got 826 / 1000 correct (82.60)\n","\n","Iteration 300, loss = 0.5040\n","Checking accuracy on validation set\n","Got 824 / 1000 correct (82.40)\n","\n","Iteration 400, loss = 0.5492\n","Checking accuracy on validation set\n","Got 826 / 1000 correct (82.60)\n","\n","Iteration 500, loss = 0.4504\n","Checking accuracy on validation set\n","Got 842 / 1000 correct (84.20)\n","\n","Iteration 600, loss = 0.2906\n","Checking accuracy on validation set\n","Got 821 / 1000 correct (82.10)\n","\n","Iteration 700, loss = 0.4841\n","Checking accuracy on validation set\n","Got 830 / 1000 correct (83.00)\n","\n","Iteration 0, loss = 0.2100\n","Checking accuracy on validation set\n","Got 829 / 1000 correct (82.90)\n","\n","Iteration 100, loss = 0.6203\n","Checking accuracy on validation set\n","Got 847 / 1000 correct (84.70)\n","\n","Iteration 200, loss = 0.2806\n","Checking accuracy on validation set\n","Got 782 / 1000 correct (78.20)\n","\n","Iteration 300, loss = 0.5731\n","Checking accuracy on validation set\n","Got 824 / 1000 correct (82.40)\n","\n","Iteration 400, loss = 0.4860\n","Checking accuracy on validation set\n","Got 806 / 1000 correct (80.60)\n","\n","Iteration 500, loss = 0.2865\n","Checking accuracy on validation set\n","Got 843 / 1000 correct (84.30)\n","\n","Iteration 600, loss = 0.4438\n","Checking accuracy on validation set\n","Got 820 / 1000 correct (82.00)\n","\n","Iteration 700, loss = 0.3516\n","Checking accuracy on validation set\n","Got 807 / 1000 correct (80.70)\n","\n","Iteration 0, loss = 0.3051\n","Checking accuracy on validation set\n","Got 844 / 1000 correct (84.40)\n","\n","Iteration 100, loss = 0.3601\n","Checking accuracy on validation set\n","Got 837 / 1000 correct (83.70)\n","\n","Iteration 200, loss = 0.3269\n","Checking accuracy on validation set\n","Got 820 / 1000 correct (82.00)\n","\n","Iteration 300, loss = 0.3205\n","Checking accuracy on validation set\n","Got 840 / 1000 correct (84.00)\n","\n","Iteration 400, loss = 0.3029\n","Checking accuracy on validation set\n","Got 828 / 1000 correct (82.80)\n","\n","Iteration 500, loss = 0.2629\n","Checking accuracy on validation set\n","Got 856 / 1000 correct (85.60)\n","\n","Iteration 600, loss = 0.3548\n","Checking accuracy on validation set\n","Got 840 / 1000 correct (84.00)\n","\n","Iteration 700, loss = 0.5695\n","Checking accuracy on validation set\n","Got 823 / 1000 correct (82.30)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["################################################################################\n","# TODO:                                                                        #\n","# Experiment with any architectures, optimizers, and hyperparameters.          #\n","# Achieve AT LEAST 70% accuracy on the *validation set* within 10 epochs.      #\n","#                                                                              #\n","# Note that you can use the check_accuracy function to evaluate on either      #\n","# the test set or the validation set, by passing either loader_test or         #\n","# loader_val as the second argument to check_accuracy. You should not touch    #\n","# the test set until you have finished your architecture and  hyperparameter   #\n","# tuning, and only run the test set once at the end to report a final value.   #\n","################################################################################\n","model = None\n","optimizer = None\n","experiment_name = \"googlenet_without_aux_adam_lr0.0001\"  # e.g., \"model1_sgd_lr0.1\", \"model2_adam_lr0.001\"\n","# Change the above experiment_name to store the avg_losses while perserving\n","# the previous avg_losses. Using the same value for experiment_name results in\n","# overwriting the previous one.\n","\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","class inceptionv1(nn.Module):\n","  def __init__(self,auxiliary = True, init_weight = True):\n","    super(inceptionv1,self).__init__()\n","\n","    assert auxiliary == True or auxiliary == False\n","    self.auxiliary = True\n","\n","    self.upsample = nn.Upsample(size = (224,224))\n","\n","    self.conv1 = ConvBlock(3, 64, kernel_size=7, stride=2, padding=3)\n","    self.maxpool1 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.conv2 = ConvBlock(64, 192, kernel_size=3, stride=1, padding=1)\n","    self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.inception3a = InceptionBlock(192,64,96,128,16,32,32)\n","    self.inception3b = InceptionBlock(256,128,128,192,32,96,64)\n","    self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.inception4a = InceptionBlock(480,192,96,208,16,48,64)\n","    self.inception4b = InceptionBlock(512,160,112,224,24,64,64)\n","    self.inception4c = InceptionBlock(512,128,128,256,24,64,64)\n","    self.inception4d = InceptionBlock(512,112,114,288,32,64,64)\n","    self.inception4e = InceptionBlock(528,256,160,320,32,128,128)\n","    self.maxpool4 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","    self.inception5a = InceptionBlock(832,256,160,320,32,128,128)\n","    self.inception5b = InceptionBlock(832,384,192,384,48,128,128)\n","    self.avgpool5 = nn.AvgPool2d(kernel_size = 7, stride=1)\n","    self.drop = nn.Dropout(p=0.4, inplace=False)\n","    self.fc = nn.Linear(1024,10)\n","\n","    if self.auxiliary:\n","      self.aux1 = Auxiliaray_classifier(512,10)\n","      self.aux2 = Auxiliaray_classifier(528,10)\n","    else:\n","      self.aux1 = None\n","      self.aux2 = None\n","\n","    if init_weight:\n","      self._initialize_weights()\n","\n","  def forward(self, x):\n","    x = self.upsample(x)\n","\n","    x = self.conv1(x)\n","    x = self.maxpool1(x)\n","    x = self.conv2(x)\n","    x = self.maxpool2(x)\n","    x = self.inception3a(x)\n","    x = self.inception3b(x)\n","    x = self.maxpool3(x)\n","\n","    x = self.inception4a(x)\n","\n","    if self.auxiliary and self.training:\n","      aux1 = self.aux1(x)\n","\n","    x = self.inception4b(x)\n","    x = self.inception4c(x)\n","    x = self.inception4d(x)\n","\n","    if self.auxiliary and self.training:\n","      aux2 = self.aux2(x)\n","\n","    x = self.inception4e(x)\n","    x = self.maxpool4(x)\n","    x = self.inception5a(x)\n","    x = self.inception5b(x)\n","    x = self.avgpool5(x)\n","\n","    x = x.view(x.shape[0], -1)\n","\n","    x = self.drop(x)\n","    x = self.fc(x)\n","\n","    if self.auxiliary and self.training:\n","      #return x, aux1, aux2\n","      return x\n","    else:\n","      return x\n","\n","  def _initialize_weights(self):\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","        if m.bias is not None:\n","          nn.init.constant_(m.bias, 0)\n","      elif isinstance(m, nn.BatchNorm2d):\n","        nn.init.constant_(m.weight,1)\n","        nn.init.constant_(m.bias,0)\n","      elif isinstance(m, nn.Linear):\n","        nn.init.normal_(m.weight,0,0.01)\n","        nn.init.constant_(m.bias,0)\n","\n","\n","class ConvBlock(nn.Module):\n","  def __init__(self,in_channels, out_channels, **kwarg):\n","    super(ConvBlock,self).__init__()\n","\n","    self.convlayer = nn.Sequential(\n","        nn.Conv2d(in_channels,out_channels, **kwarg),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","    )\n","\n","  def forward(self,x):\n","    return self.convlayer(x)\n","\n","\n","class InceptionBlock(nn.Module):\n","  def __init__(self,in_channels,out_channels_1x1,reduce_channels_3x3,out_channels_3x3,reduce_channels_5x5,out_channels_5x5,poolproj_channels):\n","    super(InceptionBlock,self).__init__()\n","\n","    self.branch1 = ConvBlock(in_channels,out_channels_1x1,kernel_size = 1)\n","    self.branch2 = nn.Sequential(\n","        ConvBlock(in_channels,reduce_channels_3x3,kernel_size = 1),\n","        ConvBlock(reduce_channels_3x3,out_channels_3x3,kernel_size = 3,padding = 1)\n","    )\n","    self.branch3 = nn.Sequential(\n","        ConvBlock(in_channels,reduce_channels_5x5,kernel_size = 1),\n","        ConvBlock(reduce_channels_5x5,out_channels_5x5,kernel_size = 5, padding = 2)\n","    )\n","    self.branch4 = nn.Sequential(\n","        nn.MaxPool2d(kernel_size = 3, stride=1, padding=1),\n","        ConvBlock(in_channels,poolproj_channels,kernel_size = 1)\n","    )\n","\n","  def forward(self,x):\n","    x = torch.cat([self.branch1(x),self.branch2(x),self.branch3(x),self.branch4(x)],1)\n","    return x\n","\n","class Auxiliaray_classifier(nn.Module):\n","  def __init__(self,in_channels,num_classes):\n","    super(Auxiliaray_classifier,self).__init__()\n","\n","    self.avgpool = nn.AvgPool2d(kernel_size = 5, stride=3, padding=0)\n","    self.conv = ConvBlock(in_channels,128,kernel_size = 1)\n","    self.fc = nn.Sequential(\n","        nn.Linear(2048,1024),\n","        nn.ReLU(),\n","        nn.Dropout(),\n","        nn.Linear(1024,num_classes)\n","    )\n","\n","  def forward(self,x):\n","    x = self.avgpool(x)\n","    x = self.conv(x)\n","    x = x.view(x.shape[0],-1)\n","    x = self.fc(x)\n","\n","    return x\n","\n","\n","model = inceptionv1(auxiliary = False, init_weight = True)\n","optimizer = optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","\n","# You should get at least 70% accuracy\n","avg_losses = train_part5(model, optimizer, epochs=10)\n","avg_losses = np.array(avg_losses)\n","np.save(\"%s.npy\" % experiment_name, avg_losses)\n","\n","plt.plot(avg_losses)\n","plt.title(\"Training Loss (%s)\" % experiment_name)\n","plt.show()"]},{"cell_type":"markdown","source":["auxiliary loss ì‚¬ìš©í•´ì„œ ëª¨ë¸ë§"],"metadata":{"id":"eT2NnTAr3a5z"}},{"cell_type":"code","source":["def train_part5(model, optimizer, epochs=1):\n","    \"\"\"\n","    Train a model on CIFAR-10 using the PyTorch Module API.\n","\n","    Inputs:\n","    - model: A PyTorch Module giving the model to train.\n","    - optimizer: An Optimizer object we will use to train the model\n","    - epochs: (Optional) A Python integer giving the number of epochs to train for\n","\n","    Returns: Nothing, but prints model accuracies during training.\n","    \"\"\"\n","    avg_losses = []\n","    model = model.to(device=device)  # move the model parameters to CPU/GPU\n","    for e in range(epochs):\n","        avg_loss = 0.0\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores_out,scores_aux1,scores_aux2 = model(x)\n","            output_loss = F.cross_entropy(scores_out, y)\n","            aux_1_loss = F.cross_entropy(scores_aux1, y)\n","            aux_2_loss = F.cross_entropy(scores_aux2, y)\n","\n","            loss = output_loss + 0.3 * (aux_1_loss + aux_2_loss)\n","            # Zero out all of the gradients for the variables which the optimizer\n","            # will update.\n","            optimizer.zero_grad()\n","\n","            # This is the backwards pass: compute the gradient of the loss with\n","            # respect to each  parameter of the model.\n","            loss.backward()\n","\n","            # Actually update the parameters of the model using the gradients\n","            # computed by the backwards pass.\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy_part34(loader_val, model)\n","                print()\n","\n","            avg_loss += loss.item()\n","        avg_losses.append(avg_loss / len(loader_train))\n","\n","    torch.save(model,'googlenet_with_aux_adam_lr0.0001.pth')\n","    return avg_losses"],"metadata":{"id":"5xVOh0dF3in9","executionInfo":{"status":"ok","timestamp":1690039230516,"user_tz":-540,"elapsed":382,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["################################################################################\n","# TODO:                                                                        #\n","# Experiment with any architectures, optimizers, and hyperparameters.          #\n","# Achieve AT LEAST 70% accuracy on the *validation set* within 10 epochs.      #\n","#                                                                              #\n","# Note that you can use the check_accuracy function to evaluate on either      #\n","# the test set or the validation set, by passing either loader_test or         #\n","# loader_val as the second argument to check_accuracy. You should not touch    #\n","# the test set until you have finished your architecture and  hyperparameter   #\n","# tuning, and only run the test set once at the end to report a final value.   #\n","################################################################################\n","model = None\n","optimizer = None\n","experiment_name = \"googlenet_with_aux_adam_lr0.0001\"  # e.g., \"model1_sgd_lr0.1\", \"model2_adam_lr0.001\"\n","# Change the above experiment_name to store the avg_losses while perserving\n","# the previous avg_losses. Using the same value for experiment_name results in\n","# overwriting the previous one.\n","\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","class inceptionv1(nn.Module):\n","  def __init__(self,auxiliary = True, init_weight = True):\n","    super(inceptionv1,self).__init__()\n","\n","    assert auxiliary == True or auxiliary == False\n","    self.auxiliary = True\n","\n","    self.upsample = nn.Upsample(size = (224,224))\n","\n","    self.conv1 = ConvBlock(3, 64, kernel_size=7, stride=2, padding=3)\n","    self.maxpool1 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.conv2 = ConvBlock(64, 192, kernel_size=3, stride=1, padding=1)\n","    self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.inception3a = InceptionBlock(192,64,96,128,16,32,32)\n","    self.inception3b = InceptionBlock(256,128,128,192,32,96,64)\n","    self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.inception4a = InceptionBlock(480,192,96,208,16,48,64)\n","    self.inception4b = InceptionBlock(512,160,112,224,24,64,64)\n","    self.inception4c = InceptionBlock(512,128,128,256,24,64,64)\n","    self.inception4d = InceptionBlock(512,112,114,288,32,64,64)\n","    self.inception4e = InceptionBlock(528,256,160,320,32,128,128)\n","    self.maxpool4 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","    self.inception5a = InceptionBlock(832,256,160,320,32,128,128)\n","    self.inception5b = InceptionBlock(832,384,192,384,48,128,128)\n","    self.avgpool5 = nn.AvgPool2d(kernel_size = 7, stride=1)\n","    self.drop = nn.Dropout(p=0.4, inplace=False)\n","    self.fc = nn.Linear(1024,10)\n","\n","    if self.auxiliary:\n","      self.aux1 = Auxiliaray_classifier(512,10)\n","      self.aux2 = Auxiliaray_classifier(528,10)\n","    else:\n","      self.aux1 = None\n","      self.aux2 = None\n","\n","    if init_weight:\n","      self._initialize_weights()\n","\n","  def forward(self, x):\n","    x = self.upsample(x)\n","\n","    x = self.conv1(x)\n","    x = self.maxpool1(x)\n","    x = self.conv2(x)\n","    x = self.maxpool2(x)\n","    x = self.inception3a(x)\n","    x = self.inception3b(x)\n","    x = self.maxpool3(x)\n","\n","    x = self.inception4a(x)\n","\n","    if self.auxiliary and self.training:\n","      aux1 = self.aux1(x)\n","\n","    x = self.inception4b(x)\n","    x = self.inception4c(x)\n","    x = self.inception4d(x)\n","\n","    if self.auxiliary and self.training:\n","      aux2 = self.aux2(x)\n","\n","    x = self.inception4e(x)\n","    x = self.maxpool4(x)\n","    x = self.inception5a(x)\n","    x = self.inception5b(x)\n","    x = self.avgpool5(x)\n","\n","    x = x.view(x.shape[0], -1)\n","\n","    x = self.drop(x)\n","    x = self.fc(x)\n","\n","    if self.auxiliary and self.training:\n","      return x, aux1, aux2\n","    else:\n","      return x\n","\n","  def _initialize_weights(self):\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","        if m.bias is not None:\n","          nn.init.constant_(m.bias, 0)\n","      elif isinstance(m, nn.BatchNorm2d):\n","        nn.init.constant_(m.weight,1)\n","        nn.init.constant_(m.bias,0)\n","      elif isinstance(m, nn.Linear):\n","        nn.init.normal_(m.weight,0,0.01)\n","        nn.init.constant_(m.bias,0)\n","\n","\n","class ConvBlock(nn.Module):\n","  def __init__(self,in_channels, out_channels, **kwarg):\n","    super(ConvBlock,self).__init__()\n","\n","    self.convlayer = nn.Sequential(\n","        nn.Conv2d(in_channels,out_channels, **kwarg),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","    )\n","\n","  def forward(self,x):\n","    return self.convlayer(x)\n","\n","\n","class InceptionBlock(nn.Module):\n","  def __init__(self,in_channels,out_channels_1x1,reduce_channels_3x3,out_channels_3x3,reduce_channels_5x5,out_channels_5x5,poolproj_channels):\n","    super(InceptionBlock,self).__init__()\n","\n","    self.branch1 = ConvBlock(in_channels,out_channels_1x1,kernel_size = 1)\n","    self.branch2 = nn.Sequential(\n","        ConvBlock(in_channels,reduce_channels_3x3,kernel_size = 1),\n","        ConvBlock(reduce_channels_3x3,out_channels_3x3,kernel_size = 3,padding = 1)\n","    )\n","    self.branch3 = nn.Sequential(\n","        ConvBlock(in_channels,reduce_channels_5x5,kernel_size = 1),\n","        ConvBlock(reduce_channels_5x5,out_channels_5x5,kernel_size = 5, padding = 2)\n","    )\n","    self.branch4 = nn.Sequential(\n","        nn.MaxPool2d(kernel_size = 3, stride=1, padding=1),\n","        ConvBlock(in_channels,poolproj_channels,kernel_size = 1)\n","    )\n","\n","  def forward(self,x):\n","    x = torch.cat([self.branch1(x),self.branch2(x),self.branch3(x),self.branch4(x)],1)\n","    return x\n","\n","class Auxiliaray_classifier(nn.Module):\n","  def __init__(self,in_channels,num_classes):\n","    super(Auxiliaray_classifier,self).__init__()\n","\n","    self.avgpool = nn.AvgPool2d(kernel_size = 5, stride=3, padding=0)\n","    self.conv = ConvBlock(in_channels,128,kernel_size = 1)\n","    self.fc = nn.Sequential(\n","        nn.Linear(2048,1024),\n","        nn.ReLU(),\n","        nn.Dropout(),\n","        nn.Linear(1024,num_classes)\n","    )\n","\n","  def forward(self,x):\n","    x = self.avgpool(x)\n","    x = self.conv(x)\n","    x = x.view(x.shape[0],-1)\n","    x = self.fc(x)\n","\n","    return x\n","\n","learning_rate = 0.0001\n","model = inceptionv1(auxiliary = True, init_weight = True)\n","optimizer = optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","\n","# You should get at least 70% accuracy\n","avg_losses = train_part5(model, optimizer, epochs=10)\n","avg_losses = np.array(avg_losses)\n","np.save(\"%s.npy\" % experiment_name, avg_losses)\n","\n","plt.plot(avg_losses)\n","plt.title(\"Training Loss (%s)\" % experiment_name)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tpMsEjGO3Z5s","executionInfo":{"status":"ok","timestamp":1690041234066,"user_tz":-540,"elapsed":2003168,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"cfe356c5-5485-4e71-b5d6-8971fca70dcd"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 3.6781\n","Checking accuracy on validation set\n","Got 88 / 1000 correct (8.80)\n","\n","Iteration 100, loss = 2.7357\n","Checking accuracy on validation set\n","Got 384 / 1000 correct (38.40)\n","\n","Iteration 200, loss = 2.3034\n","Checking accuracy on validation set\n","Got 440 / 1000 correct (44.00)\n","\n","Iteration 300, loss = 1.8122\n","Checking accuracy on validation set\n","Got 512 / 1000 correct (51.20)\n","\n","Iteration 400, loss = 2.0486\n","Checking accuracy on validation set\n","Got 499 / 1000 correct (49.90)\n","\n","Iteration 500, loss = 1.9209\n","Checking accuracy on validation set\n","Got 583 / 1000 correct (58.30)\n","\n","Iteration 600, loss = 1.8618\n","Checking accuracy on validation set\n","Got 585 / 1000 correct (58.50)\n","\n","Iteration 700, loss = 1.6195\n","Checking accuracy on validation set\n","Got 627 / 1000 correct (62.70)\n","\n","Iteration 0, loss = 1.3374\n","Checking accuracy on validation set\n","Got 611 / 1000 correct (61.10)\n","\n","Iteration 100, loss = 1.7645\n","Checking accuracy on validation set\n","Got 581 / 1000 correct (58.10)\n","\n","Iteration 200, loss = 1.3540\n","Checking accuracy on validation set\n","Got 637 / 1000 correct (63.70)\n","\n","Iteration 300, loss = 1.2494\n","Checking accuracy on validation set\n","Got 649 / 1000 correct (64.90)\n","\n","Iteration 400, loss = 1.3251\n","Checking accuracy on validation set\n","Got 674 / 1000 correct (67.40)\n","\n","Iteration 500, loss = 1.3828\n","Checking accuracy on validation set\n","Got 680 / 1000 correct (68.00)\n","\n","Iteration 600, loss = 1.4756\n","Checking accuracy on validation set\n","Got 688 / 1000 correct (68.80)\n","\n","Iteration 700, loss = 1.3428\n","Checking accuracy on validation set\n","Got 740 / 1000 correct (74.00)\n","\n","Iteration 0, loss = 1.4516\n","Checking accuracy on validation set\n","Got 715 / 1000 correct (71.50)\n","\n","Iteration 100, loss = 1.4546\n","Checking accuracy on validation set\n","Got 747 / 1000 correct (74.70)\n","\n","Iteration 200, loss = 1.2314\n","Checking accuracy on validation set\n","Got 722 / 1000 correct (72.20)\n","\n","Iteration 300, loss = 1.1164\n","Checking accuracy on validation set\n","Got 744 / 1000 correct (74.40)\n","\n","Iteration 400, loss = 0.9620\n","Checking accuracy on validation set\n","Got 691 / 1000 correct (69.10)\n","\n","Iteration 500, loss = 0.9995\n","Checking accuracy on validation set\n","Got 770 / 1000 correct (77.00)\n","\n","Iteration 600, loss = 0.9131\n","Checking accuracy on validation set\n","Got 734 / 1000 correct (73.40)\n","\n","Iteration 700, loss = 1.2456\n","Checking accuracy on validation set\n","Got 730 / 1000 correct (73.00)\n","\n","Iteration 0, loss = 0.9791\n","Checking accuracy on validation set\n","Got 759 / 1000 correct (75.90)\n","\n","Iteration 100, loss = 0.8265\n","Checking accuracy on validation set\n","Got 778 / 1000 correct (77.80)\n","\n","Iteration 200, loss = 0.8619\n","Checking accuracy on validation set\n","Got 741 / 1000 correct (74.10)\n","\n","Iteration 300, loss = 0.9809\n","Checking accuracy on validation set\n","Got 764 / 1000 correct (76.40)\n","\n","Iteration 400, loss = 0.7284\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 500, loss = 0.9295\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Iteration 600, loss = 0.7301\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 700, loss = 0.5359\n","Checking accuracy on validation set\n","Got 790 / 1000 correct (79.00)\n","\n","Iteration 0, loss = 0.6430\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 100, loss = 0.5242\n","Checking accuracy on validation set\n","Got 809 / 1000 correct (80.90)\n","\n","Iteration 200, loss = 0.7327\n","Checking accuracy on validation set\n","Got 816 / 1000 correct (81.60)\n","\n","Iteration 300, loss = 0.9247\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 400, loss = 0.6324\n","Checking accuracy on validation set\n","Got 796 / 1000 correct (79.60)\n","\n","Iteration 500, loss = 0.8848\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 600, loss = 0.6821\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Iteration 700, loss = 0.4903\n","Checking accuracy on validation set\n","Got 808 / 1000 correct (80.80)\n","\n","Iteration 0, loss = 0.7126\n","Checking accuracy on validation set\n","Got 813 / 1000 correct (81.30)\n","\n","Iteration 100, loss = 0.5873\n","Checking accuracy on validation set\n","Got 812 / 1000 correct (81.20)\n","\n","Iteration 200, loss = 0.6664\n","Checking accuracy on validation set\n","Got 827 / 1000 correct (82.70)\n","\n","Iteration 300, loss = 0.4336\n","Checking accuracy on validation set\n","Got 806 / 1000 correct (80.60)\n","\n","Iteration 400, loss = 0.3868\n","Checking accuracy on validation set\n","Got 815 / 1000 correct (81.50)\n","\n","Iteration 500, loss = 0.6424\n","Checking accuracy on validation set\n","Got 825 / 1000 correct (82.50)\n","\n","Iteration 600, loss = 0.5601\n","Checking accuracy on validation set\n","Got 798 / 1000 correct (79.80)\n","\n","Iteration 700, loss = 0.7070\n","Checking accuracy on validation set\n","Got 820 / 1000 correct (82.00)\n","\n","Iteration 0, loss = 0.5315\n","Checking accuracy on validation set\n","Got 833 / 1000 correct (83.30)\n","\n","Iteration 100, loss = 0.2619\n","Checking accuracy on validation set\n","Got 830 / 1000 correct (83.00)\n","\n","Iteration 200, loss = 0.3571\n","Checking accuracy on validation set\n","Got 825 / 1000 correct (82.50)\n","\n","Iteration 300, loss = 0.2919\n","Checking accuracy on validation set\n","Got 801 / 1000 correct (80.10)\n","\n","Iteration 400, loss = 0.6144\n","Checking accuracy on validation set\n","Got 819 / 1000 correct (81.90)\n","\n","Iteration 500, loss = 0.5190\n","Checking accuracy on validation set\n","Got 816 / 1000 correct (81.60)\n","\n","Iteration 600, loss = 0.4516\n","Checking accuracy on validation set\n","Got 802 / 1000 correct (80.20)\n","\n","Iteration 700, loss = 0.7036\n","Checking accuracy on validation set\n","Got 798 / 1000 correct (79.80)\n","\n","Iteration 0, loss = 0.3780\n","Checking accuracy on validation set\n","Got 815 / 1000 correct (81.50)\n","\n","Iteration 100, loss = 0.2927\n","Checking accuracy on validation set\n","Got 840 / 1000 correct (84.00)\n","\n","Iteration 200, loss = 0.2309\n","Checking accuracy on validation set\n","Got 810 / 1000 correct (81.00)\n","\n","Iteration 300, loss = 0.1963\n","Checking accuracy on validation set\n","Got 815 / 1000 correct (81.50)\n","\n","Iteration 400, loss = 0.4155\n","Checking accuracy on validation set\n","Got 803 / 1000 correct (80.30)\n","\n","Iteration 500, loss = 0.3241\n","Checking accuracy on validation set\n","Got 808 / 1000 correct (80.80)\n","\n","Iteration 600, loss = 0.3870\n","Checking accuracy on validation set\n","Got 808 / 1000 correct (80.80)\n","\n","Iteration 700, loss = 0.5970\n","Checking accuracy on validation set\n","Got 842 / 1000 correct (84.20)\n","\n","Iteration 0, loss = 0.2407\n","Checking accuracy on validation set\n","Got 842 / 1000 correct (84.20)\n","\n","Iteration 100, loss = 0.2003\n","Checking accuracy on validation set\n","Got 825 / 1000 correct (82.50)\n","\n","Iteration 200, loss = 0.1507\n","Checking accuracy on validation set\n","Got 837 / 1000 correct (83.70)\n","\n","Iteration 300, loss = 0.2092\n","Checking accuracy on validation set\n","Got 841 / 1000 correct (84.10)\n","\n","Iteration 400, loss = 0.3711\n","Checking accuracy on validation set\n","Got 837 / 1000 correct (83.70)\n","\n","Iteration 500, loss = 0.5353\n","Checking accuracy on validation set\n","Got 823 / 1000 correct (82.30)\n","\n","Iteration 600, loss = 0.2610\n","Checking accuracy on validation set\n","Got 824 / 1000 correct (82.40)\n","\n","Iteration 700, loss = 0.5331\n","Checking accuracy on validation set\n","Got 816 / 1000 correct (81.60)\n","\n","Iteration 0, loss = 0.1982\n","Checking accuracy on validation set\n","Got 800 / 1000 correct (80.00)\n","\n","Iteration 100, loss = 0.2014\n","Checking accuracy on validation set\n","Got 840 / 1000 correct (84.00)\n","\n","Iteration 200, loss = 0.2630\n","Checking accuracy on validation set\n","Got 830 / 1000 correct (83.00)\n","\n","Iteration 300, loss = 0.1625\n","Checking accuracy on validation set\n","Got 826 / 1000 correct (82.60)\n","\n","Iteration 400, loss = 0.2584\n","Checking accuracy on validation set\n","Got 813 / 1000 correct (81.30)\n","\n","Iteration 500, loss = 0.2388\n","Checking accuracy on validation set\n","Got 809 / 1000 correct (80.90)\n","\n","Iteration 600, loss = 0.4845\n","Checking accuracy on validation set\n","Got 830 / 1000 correct (83.00)\n","\n","Iteration 700, loss = 0.1758\n","Checking accuracy on validation set\n","Got 816 / 1000 correct (81.60)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"5samHtMggn_8"},"source":["ì´ì „ì— ì‹¤í–‰í•œ `experiment_name` ì—¬ëŸ¬ ê°œë¥¼ ë¦¬ìŠ¤íŠ¸ ë‚´ì— ë‚˜ì—´í•´ ë³´ì„¸ìš”. ê° ì‹¤í—˜ì˜ ì†ì‹¤ í•¨ìˆ˜ ì¶”ì´ë¥¼ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bdyq9pfCgqaz","colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"status":"ok","timestamp":1690038755805,"user_tz":-540,"elapsed":1130,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"23a17c7b-c5bd-4630-fa13-e96d684fb699"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["experiment_names = [\"googlenet_with_aux_adam_lr0.0001\", \"googlenet_without_aux_adam_lr0.0001\"]\n","\n","for experiment_name in experiment_names:\n","    avg_losses = np.load(\"%s.npy\" % experiment_name)\n","    plt.plot(avg_losses, label=experiment_name)\n","plt.title(\"Training Loss Comparison\")\n","plt.legend(loc=\"upper right\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Wn0hm7nvpR2E"},"source":["## Describe what you did\n","\n","ì•„ë˜ ì¹¸ì— ìì‹ ì´ ìˆ˜í–‰í•œ ì‘ì—…, êµ¬í˜„í•œ ì¶”ê°€ ê¸°ëŠ¥ ë°/ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ í›ˆë ¨í•˜ê³  í‰ê°€í•˜ëŠ” ê³¼ì •ì—ì„œ ë§Œë“  ê·¸ë˜í”„ì— ëŒ€í•œ ì„¤ëª…ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"85-8eL1mpR2E"},"source":["**Answer:**\n","\n","ë…¼ë¬¸ ë¦¬ë·°ë¥¼ í–ˆì—ˆë˜ googlenetì— ëŒ€í•œ ì½”ë“œ êµ¬í˜„ì„ í•´ë´¤ë‹¤.\n","\n","CNNì—ì„œ ë‹¤ì–‘í•œ ì‚¬ì´ì¦ˆì˜ Kernelì„ concatí•œ inception moduleì„ ì‚¬ìš©í–ˆê³  ì¤‘ê°„ ì¤‘ê°„ auxiliary classifierë¥¼ ì´ìš©í•´ vanish gradientë¥¼ ë°©ì§€í–ˆë‹¤.\n","\n","auxiliaryê°€ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° ëª¨ë‘ lossê°€ ì˜ í•˜ë½í•˜ê³  ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©° ì²˜ìŒ initializeê°€ ëœë¤í•˜ê²Œ ì§„í–‰ë˜ì–´ lossì˜ ì°¨ì´ê°€ ë‚˜ì˜¬ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤. (í˜¹ì€ auxiliary classifierê°€ ì˜ë¯¸ê°€ ì—†ëŠ” ê²ƒì¼ ìˆ˜ë„ ..)"]},{"cell_type":"markdown","metadata":{"id":"RM-B3G5ypR2F"},"source":["## Test set -- run this only once\n","\n","ì´ì œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ì–»ì—ˆìœ¼ë¯€ë¡œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ìµœì¢… ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤(best_modelì— ì €ì¥í•´ì•¼ í•¨). ì´ê²ƒì´ ìœ íš¨ì„± ê²€ì‚¬ ì„¸íŠ¸ ì •í™•ë„ì™€ ì–´ë–»ê²Œ ë¹„êµë˜ëŠ”ì§€ ìƒê°í•´ ë³´ì„¸ìš”."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"7KGIAvAZpR2F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690041475014,"user_tz":-540,"elapsed":11857,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"ee77a5ef-6716-4fd1-8411-6e666932f50d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Checking accuracy on test set\n","Got 8205 / 10000 correct (82.05)\n"]}],"source":["best_model = torch.load('googlenet_with_aux_adam_lr0.0001.pth')\n","check_accuracy_part34(loader_test, best_model)"]},{"cell_type":"markdown","metadata":{"id":"48ZsEUyiocf-"},"source":["# Additional Part. Pretrained model ë¶ˆëŸ¬ì˜¤ê¸°\n","\n","Part Vì—ì„œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ì–»ìœ¼ì…¨ë‚˜ìš”? PyTorchì˜ Modelì„ ì •ì˜í•˜ëŠ” ëŠ¥ë ¥ì€ ë§¤ìš° ê°•ë ¥í•˜ì§€ë§Œ, ë•Œë¡œëŠ” ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ë§Œë“¤ì–´ ë‘” Modelì„ í†µí•´ ë¹ ë¥´ê²Œ ì‹¤í—˜ì„ í•˜ê³  ì‹¶ì„ ë•Œë„ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ´ ë•Œë¥¼ ìœ„í•´ torchvisionë¥¼ í†µí•´ pre-trainedëœ Modelì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","ë‹¤ìŒì„ ì°¸ê³ í•˜ì„¸ìš”: [torchvision document](https://pytorch.org/vision/stable/models.html#classification)\n","\n","Modelì˜ êµ¬ì¡°ê°€ ê¶ê¸ˆí•œ ê²½ìš° print()ë¥¼ í†µí•´ ì‰½ê²Œ í™•ì¸í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"aLXA4juyol1y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690041715538,"user_tz":-540,"elapsed":2849,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"ebff8c2a-c5b2-4d48-d9ba-bee44a041e5f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 236MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",")\n"]}],"source":["from torchvision import models\n","\n","# Download resnet50 pretrained\n","resnet_pretrained = models.resnet50(pretrained=True)\n","print(resnet_pretrained)"]},{"cell_type":"markdown","metadata":{"id":"HyK1w2VotW_C"},"source":["## Pretrained model ìˆ˜ì •í•˜ê¸°\n","print()ë¥¼ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆë“¯ì´, ë‹¤ìš´ ë°›ì€ ResNet Modelì˜ ë§ˆì§€ë§‰ LayerëŠ” out_features=1000ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ìš°ë¦¬ì˜ taskì—ì„œëŠ” Outputì´ 10ê°œ ì„ìœ¼ë¡œ, model êµ¬ì¡°ë¥¼ ì¡°ê¸ˆ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"B726VCVjpcwK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690041791942,"user_tz":-540,"elapsed":390,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"01c38b51-b2be-4949-936a-bfbe08df549b"},"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",")\n"]}],"source":["num_ftrs = resnet_pretrained.fc.in_features\n","num_classes = 10\n","\n","# Modelì´ ê°€ì§„ 'fc'ë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ Layerì— ì§ì ‘ ì ‘ê·¼í•´ ìˆ˜ì •í•´ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","resnet_pretrained.fc = nn.Linear(num_ftrs, num_classes)\n","print(resnet_pretrained)"]},{"cell_type":"markdown","metadata":{"id":"-oUEPMcPsiBJ"},"source":["## Fine tuning model ì„±ëŠ¥ í‰ê°€ í•˜ê¸°\n","ì´ì œ Fine tuning í•œ Modelì˜ ì„±ëŠ¥ì„ í‰ê°€í•´ ë´…ì‹œë‹¤."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"wUaV2rF7LAX5","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1690043001489,"user_tz":-540,"elapsed":1188745,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"616769b6-82d0-4b10-ae05-0f3edbf3d1ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.3938\n","Checking accuracy on validation set\n","Got 113 / 1000 correct (11.30)\n","\n","Iteration 100, loss = 2.5607\n","Checking accuracy on validation set\n","Got 306 / 1000 correct (30.60)\n","\n","Iteration 200, loss = 2.3100\n","Checking accuracy on validation set\n","Got 225 / 1000 correct (22.50)\n","\n","Iteration 300, loss = 2.0018\n","Checking accuracy on validation set\n","Got 310 / 1000 correct (31.00)\n","\n","Iteration 400, loss = 2.0368\n","Checking accuracy on validation set\n","Got 229 / 1000 correct (22.90)\n","\n","Iteration 500, loss = 1.6766\n","Checking accuracy on validation set\n","Got 322 / 1000 correct (32.20)\n","\n","Iteration 600, loss = 1.6393\n","Checking accuracy on validation set\n","Got 358 / 1000 correct (35.80)\n","\n","Iteration 700, loss = 1.4873\n","Checking accuracy on validation set\n","Got 404 / 1000 correct (40.40)\n","\n","Iteration 0, loss = 1.4721\n","Checking accuracy on validation set\n","Got 450 / 1000 correct (45.00)\n","\n","Iteration 100, loss = 1.4698\n","Checking accuracy on validation set\n","Got 469 / 1000 correct (46.90)\n","\n","Iteration 200, loss = 1.7465\n","Checking accuracy on validation set\n","Got 383 / 1000 correct (38.30)\n","\n","Iteration 300, loss = 1.3743\n","Checking accuracy on validation set\n","Got 463 / 1000 correct (46.30)\n","\n","Iteration 400, loss = 1.6631\n","Checking accuracy on validation set\n","Got 494 / 1000 correct (49.40)\n","\n","Iteration 500, loss = 1.3592\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n","Iteration 600, loss = 1.4866\n","Checking accuracy on validation set\n","Got 522 / 1000 correct (52.20)\n","\n","Iteration 700, loss = 1.3589\n","Checking accuracy on validation set\n","Got 469 / 1000 correct (46.90)\n","\n","Iteration 0, loss = 1.2942\n","Checking accuracy on validation set\n","Got 518 / 1000 correct (51.80)\n","\n","Iteration 100, loss = 1.4343\n","Checking accuracy on validation set\n","Got 518 / 1000 correct (51.80)\n","\n","Iteration 200, loss = 1.2912\n","Checking accuracy on validation set\n","Got 558 / 1000 correct (55.80)\n","\n","Iteration 300, loss = 1.2661\n","Checking accuracy on validation set\n","Got 549 / 1000 correct (54.90)\n","\n","Iteration 400, loss = 1.2987\n","Checking accuracy on validation set\n","Got 557 / 1000 correct (55.70)\n","\n","Iteration 500, loss = 1.1017\n","Checking accuracy on validation set\n","Got 569 / 1000 correct (56.90)\n","\n","Iteration 600, loss = 1.1369\n","Checking accuracy on validation set\n","Got 559 / 1000 correct (55.90)\n","\n","Iteration 700, loss = 1.1943\n","Checking accuracy on validation set\n","Got 553 / 1000 correct (55.30)\n","\n","Iteration 0, loss = 1.1544\n","Checking accuracy on validation set\n","Got 587 / 1000 correct (58.70)\n","\n","Iteration 100, loss = 1.1558\n","Checking accuracy on validation set\n","Got 559 / 1000 correct (55.90)\n","\n","Iteration 200, loss = 1.1397\n","Checking accuracy on validation set\n","Got 586 / 1000 correct (58.60)\n","\n","Iteration 300, loss = 1.1315\n","Checking accuracy on validation set\n","Got 606 / 1000 correct (60.60)\n","\n","Iteration 400, loss = 0.9025\n","Checking accuracy on validation set\n","Got 586 / 1000 correct (58.60)\n","\n","Iteration 500, loss = 1.2181\n","Checking accuracy on validation set\n","Got 583 / 1000 correct (58.30)\n","\n","Iteration 600, loss = 0.9976\n","Checking accuracy on validation set\n","Got 620 / 1000 correct (62.00)\n","\n","Iteration 700, loss = 1.0050\n","Checking accuracy on validation set\n","Got 640 / 1000 correct (64.00)\n","\n","Iteration 0, loss = 0.8207\n","Checking accuracy on validation set\n","Got 646 / 1000 correct (64.60)\n","\n","Iteration 100, loss = 0.8183\n","Checking accuracy on validation set\n","Got 589 / 1000 correct (58.90)\n","\n","Iteration 200, loss = 0.8118\n","Checking accuracy on validation set\n","Got 641 / 1000 correct (64.10)\n","\n","Iteration 300, loss = 0.9840\n","Checking accuracy on validation set\n","Got 641 / 1000 correct (64.10)\n","\n","Iteration 400, loss = 0.7990\n","Checking accuracy on validation set\n","Got 651 / 1000 correct (65.10)\n","\n","Iteration 500, loss = 0.8434\n","Checking accuracy on validation set\n","Got 650 / 1000 correct (65.00)\n","\n","Iteration 600, loss = 0.7820\n","Checking accuracy on validation set\n","Got 659 / 1000 correct (65.90)\n","\n","Iteration 700, loss = 1.0531\n","Checking accuracy on validation set\n","Got 682 / 1000 correct (68.20)\n","\n","Iteration 0, loss = 0.9970\n","Checking accuracy on validation set\n","Got 634 / 1000 correct (63.40)\n","\n","Iteration 100, loss = 0.9365\n","Checking accuracy on validation set\n","Got 634 / 1000 correct (63.40)\n","\n","Iteration 200, loss = 1.0408\n","Checking accuracy on validation set\n","Got 647 / 1000 correct (64.70)\n","\n","Iteration 300, loss = 0.9205\n","Checking accuracy on validation set\n","Got 681 / 1000 correct (68.10)\n","\n","Iteration 400, loss = 0.8107\n","Checking accuracy on validation set\n","Got 688 / 1000 correct (68.80)\n","\n","Iteration 500, loss = 0.8399\n","Checking accuracy on validation set\n","Got 675 / 1000 correct (67.50)\n","\n","Iteration 600, loss = 0.8556\n","Checking accuracy on validation set\n","Got 673 / 1000 correct (67.30)\n","\n","Iteration 700, loss = 0.9142\n","Checking accuracy on validation set\n","Got 623 / 1000 correct (62.30)\n","\n","Iteration 0, loss = 0.7364\n","Checking accuracy on validation set\n","Got 663 / 1000 correct (66.30)\n","\n","Iteration 100, loss = 0.7778\n","Checking accuracy on validation set\n","Got 670 / 1000 correct (67.00)\n","\n","Iteration 200, loss = 0.7090\n","Checking accuracy on validation set\n","Got 687 / 1000 correct (68.70)\n","\n","Iteration 300, loss = 0.7107\n","Checking accuracy on validation set\n","Got 664 / 1000 correct (66.40)\n","\n","Iteration 400, loss = 0.8918\n","Checking accuracy on validation set\n","Got 685 / 1000 correct (68.50)\n","\n","Iteration 500, loss = 0.9349\n","Checking accuracy on validation set\n","Got 716 / 1000 correct (71.60)\n","\n","Iteration 600, loss = 0.8852\n","Checking accuracy on validation set\n","Got 693 / 1000 correct (69.30)\n","\n","Iteration 700, loss = 0.7479\n","Checking accuracy on validation set\n","Got 662 / 1000 correct (66.20)\n","\n","Iteration 0, loss = 0.5168\n","Checking accuracy on validation set\n","Got 699 / 1000 correct (69.90)\n","\n","Iteration 100, loss = 0.5956\n","Checking accuracy on validation set\n","Got 712 / 1000 correct (71.20)\n","\n","Iteration 200, loss = 0.6997\n","Checking accuracy on validation set\n","Got 668 / 1000 correct (66.80)\n","\n","Iteration 300, loss = 0.6663\n","Checking accuracy on validation set\n","Got 711 / 1000 correct (71.10)\n","\n","Iteration 400, loss = 0.9659\n","Checking accuracy on validation set\n","Got 673 / 1000 correct (67.30)\n","\n","Iteration 500, loss = 0.8356\n","Checking accuracy on validation set\n","Got 707 / 1000 correct (70.70)\n","\n","Iteration 600, loss = 0.9447\n","Checking accuracy on validation set\n","Got 710 / 1000 correct (71.00)\n","\n","Iteration 700, loss = 0.7911\n","Checking accuracy on validation set\n","Got 709 / 1000 correct (70.90)\n","\n","Iteration 0, loss = 0.7039\n","Checking accuracy on validation set\n","Got 703 / 1000 correct (70.30)\n","\n","Iteration 100, loss = 0.7813\n","Checking accuracy on validation set\n","Got 673 / 1000 correct (67.30)\n","\n","Iteration 200, loss = 0.7570\n","Checking accuracy on validation set\n","Got 682 / 1000 correct (68.20)\n","\n","Iteration 300, loss = 0.7553\n","Checking accuracy on validation set\n","Got 724 / 1000 correct (72.40)\n","\n","Iteration 400, loss = 0.7364\n","Checking accuracy on validation set\n","Got 708 / 1000 correct (70.80)\n","\n","Iteration 500, loss = 0.8598\n","Checking accuracy on validation set\n","Got 733 / 1000 correct (73.30)\n","\n","Iteration 600, loss = 0.7339\n","Checking accuracy on validation set\n","Got 748 / 1000 correct (74.80)\n","\n","Iteration 700, loss = 0.5838\n","Checking accuracy on validation set\n","Got 705 / 1000 correct (70.50)\n","\n","Iteration 0, loss = 0.5214\n","Checking accuracy on validation set\n","Got 725 / 1000 correct (72.50)\n","\n","Iteration 100, loss = 0.6007\n","Checking accuracy on validation set\n","Got 736 / 1000 correct (73.60)\n","\n","Iteration 200, loss = 0.4618\n","Checking accuracy on validation set\n","Got 719 / 1000 correct (71.90)\n","\n","Iteration 300, loss = 0.6588\n","Checking accuracy on validation set\n","Got 704 / 1000 correct (70.40)\n","\n","Iteration 400, loss = 0.6582\n","Checking accuracy on validation set\n","Got 728 / 1000 correct (72.80)\n","\n","Iteration 500, loss = 0.5928\n","Checking accuracy on validation set\n","Got 742 / 1000 correct (74.20)\n","\n","Iteration 600, loss = 0.5964\n","Checking accuracy on validation set\n","Got 731 / 1000 correct (73.10)\n","\n","Iteration 700, loss = 0.5809\n","Checking accuracy on validation set\n","Got 738 / 1000 correct (73.80)\n","\n","Iteration 0, loss = 0.5534\n","Checking accuracy on validation set\n","Got 710 / 1000 correct (71.00)\n","\n","Iteration 100, loss = 0.4518\n","Checking accuracy on validation set\n","Got 706 / 1000 correct (70.60)\n","\n","Iteration 200, loss = 0.5539\n","Checking accuracy on validation set\n","Got 730 / 1000 correct (73.00)\n","\n","Iteration 300, loss = 0.7499\n","Checking accuracy on validation set\n","Got 745 / 1000 correct (74.50)\n","\n","Iteration 400, loss = 0.4672\n","Checking accuracy on validation set\n","Got 740 / 1000 correct (74.00)\n","\n","Iteration 500, loss = 0.6456\n","Checking accuracy on validation set\n","Got 738 / 1000 correct (73.80)\n","\n","Iteration 600, loss = 0.4007\n","Checking accuracy on validation set\n","Got 736 / 1000 correct (73.60)\n","\n","Iteration 700, loss = 0.5362\n","Checking accuracy on validation set\n","Got 757 / 1000 correct (75.70)\n","\n","Iteration 0, loss = 0.4643\n","Checking accuracy on validation set\n","Got 740 / 1000 correct (74.00)\n","\n","Iteration 100, loss = 0.5383\n","Checking accuracy on validation set\n","Got 752 / 1000 correct (75.20)\n","\n","Iteration 200, loss = 0.7117\n","Checking accuracy on validation set\n","Got 717 / 1000 correct (71.70)\n","\n","Iteration 300, loss = 0.7984\n","Checking accuracy on validation set\n","Got 733 / 1000 correct (73.30)\n","\n","Iteration 400, loss = 0.5858\n","Checking accuracy on validation set\n","Got 742 / 1000 correct (74.20)\n","\n","Iteration 500, loss = 0.6086\n","Checking accuracy on validation set\n","Got 742 / 1000 correct (74.20)\n","\n","Iteration 600, loss = 0.3926\n","Checking accuracy on validation set\n","Got 783 / 1000 correct (78.30)\n","\n","Iteration 700, loss = 0.4146\n","Checking accuracy on validation set\n","Got 748 / 1000 correct (74.80)\n","\n","Iteration 0, loss = 0.6490\n","Checking accuracy on validation set\n","Got 748 / 1000 correct (74.80)\n","\n","Iteration 100, loss = 0.6859\n","Checking accuracy on validation set\n","Got 747 / 1000 correct (74.70)\n","\n","Iteration 200, loss = 0.2467\n","Checking accuracy on validation set\n","Got 735 / 1000 correct (73.50)\n","\n","Iteration 300, loss = 0.4952\n","Checking accuracy on validation set\n","Got 755 / 1000 correct (75.50)\n","\n","Iteration 400, loss = 0.5649\n","Checking accuracy on validation set\n","Got 734 / 1000 correct (73.40)\n","\n","Iteration 500, loss = 0.3932\n","Checking accuracy on validation set\n","Got 762 / 1000 correct (76.20)\n","\n","Iteration 600, loss = 0.5893\n","Checking accuracy on validation set\n","Got 627 / 1000 correct (62.70)\n","\n","Iteration 700, loss = 0.6825\n","Checking accuracy on validation set\n","Got 750 / 1000 correct (75.00)\n","\n","Iteration 0, loss = 0.4569\n","Checking accuracy on validation set\n","Got 744 / 1000 correct (74.40)\n","\n","Iteration 100, loss = 0.3845\n","Checking accuracy on validation set\n","Got 758 / 1000 correct (75.80)\n","\n","Iteration 200, loss = 0.7488\n","Checking accuracy on validation set\n","Got 761 / 1000 correct (76.10)\n","\n","Iteration 300, loss = 0.5961\n","Checking accuracy on validation set\n","Got 769 / 1000 correct (76.90)\n","\n","Iteration 400, loss = 0.3508\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 500, loss = 0.5410\n","Checking accuracy on validation set\n","Got 764 / 1000 correct (76.40)\n","\n","Iteration 600, loss = 0.4211\n","Checking accuracy on validation set\n","Got 778 / 1000 correct (77.80)\n","\n","Iteration 700, loss = 0.5404\n","Checking accuracy on validation set\n","Got 758 / 1000 correct (75.80)\n","\n","Iteration 0, loss = 0.4601\n","Checking accuracy on validation set\n","Got 774 / 1000 correct (77.40)\n","\n","Iteration 100, loss = 0.2360\n","Checking accuracy on validation set\n","Got 786 / 1000 correct (78.60)\n","\n","Iteration 200, loss = 0.4654\n","Checking accuracy on validation set\n","Got 769 / 1000 correct (76.90)\n","\n","Iteration 300, loss = 0.5221\n","Checking accuracy on validation set\n","Got 749 / 1000 correct (74.90)\n","\n","Iteration 400, loss = 0.4198\n","Checking accuracy on validation set\n","Got 769 / 1000 correct (76.90)\n","\n","Iteration 500, loss = 0.5667\n","Checking accuracy on validation set\n","Got 761 / 1000 correct (76.10)\n","\n","Iteration 600, loss = 0.5560\n","Checking accuracy on validation set\n","Got 758 / 1000 correct (75.80)\n","\n","Iteration 700, loss = 0.3805\n","Checking accuracy on validation set\n","Got 763 / 1000 correct (76.30)\n","\n","Iteration 0, loss = 0.3856\n","Checking accuracy on validation set\n","Got 756 / 1000 correct (75.60)\n","\n","Iteration 100, loss = 0.4761\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 200, loss = 0.4640\n","Checking accuracy on validation set\n","Got 785 / 1000 correct (78.50)\n","\n","Iteration 300, loss = 0.1868\n","Checking accuracy on validation set\n","Got 766 / 1000 correct (76.60)\n","\n","Iteration 400, loss = 0.3234\n","Checking accuracy on validation set\n","Got 771 / 1000 correct (77.10)\n","\n","Iteration 500, loss = 0.6242\n","Checking accuracy on validation set\n","Got 766 / 1000 correct (76.60)\n","\n","Iteration 600, loss = 0.4993\n","Checking accuracy on validation set\n","Got 765 / 1000 correct (76.50)\n","\n","Iteration 700, loss = 0.5530\n","Checking accuracy on validation set\n","Got 772 / 1000 correct (77.20)\n","\n","Iteration 0, loss = 0.2097\n","Checking accuracy on validation set\n","Got 785 / 1000 correct (78.50)\n","\n","Iteration 100, loss = 0.3339\n","Checking accuracy on validation set\n","Got 758 / 1000 correct (75.80)\n","\n","Iteration 200, loss = 0.4037\n","Checking accuracy on validation set\n","Got 777 / 1000 correct (77.70)\n","\n","Iteration 300, loss = 0.2840\n","Checking accuracy on validation set\n","Got 749 / 1000 correct (74.90)\n","\n","Iteration 400, loss = 0.3411\n","Checking accuracy on validation set\n","Got 756 / 1000 correct (75.60)\n","\n","Iteration 500, loss = 0.1638\n","Checking accuracy on validation set\n","Got 759 / 1000 correct (75.90)\n","\n","Iteration 600, loss = 0.2947\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 700, loss = 0.3819\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 0, loss = 0.2651\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 100, loss = 0.1925\n","Checking accuracy on validation set\n","Got 763 / 1000 correct (76.30)\n","\n","Iteration 200, loss = 0.1701\n","Checking accuracy on validation set\n","Got 765 / 1000 correct (76.50)\n","\n","Iteration 300, loss = 0.3185\n","Checking accuracy on validation set\n","Got 763 / 1000 correct (76.30)\n","\n","Iteration 400, loss = 0.2945\n","Checking accuracy on validation set\n","Got 782 / 1000 correct (78.20)\n","\n","Iteration 500, loss = 0.3252\n","Checking accuracy on validation set\n","Got 793 / 1000 correct (79.30)\n","\n","Iteration 600, loss = 0.4535\n","Checking accuracy on validation set\n","Got 762 / 1000 correct (76.20)\n","\n","Iteration 700, loss = 0.3498\n","Checking accuracy on validation set\n","Got 781 / 1000 correct (78.10)\n","\n","Iteration 0, loss = 0.1903\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 100, loss = 0.4296\n","Checking accuracy on validation set\n","Got 693 / 1000 correct (69.30)\n","\n","Iteration 200, loss = 0.2885\n","Checking accuracy on validation set\n","Got 745 / 1000 correct (74.50)\n","\n","Iteration 300, loss = 0.3542\n","Checking accuracy on validation set\n","Got 757 / 1000 correct (75.70)\n","\n","Iteration 400, loss = 0.4230\n","Checking accuracy on validation set\n","Got 778 / 1000 correct (77.80)\n","\n","Iteration 500, loss = 0.2851\n","Checking accuracy on validation set\n","Got 786 / 1000 correct (78.60)\n","\n","Iteration 600, loss = 0.4190\n","Checking accuracy on validation set\n","Got 770 / 1000 correct (77.00)\n","\n","Iteration 700, loss = 0.2536\n","Checking accuracy on validation set\n","Iteration 0, loss = 0.3691\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 100, loss = 0.2027\n","Checking accuracy on validation set\n","Got 777 / 1000 correct (77.70)\n","\n","Iteration 200, loss = 0.1192\n","Checking accuracy on validation set\n","Got 792 / 1000 correct (79.20)\n","\n","Iteration 300, loss = 0.2856\n","Checking accuracy on validation set\n","Got 796 / 1000 correct (79.60)\n","\n","Iteration 400, loss = 0.4514\n","Checking accuracy on validation set\n","Got 751 / 1000 correct (75.10)\n","\n","Iteration 500, loss = 0.3002\n","Checking accuracy on validation set\n","Got 761 / 1000 correct (76.10)\n","\n","Iteration 600, loss = 0.2610\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 700, loss = 0.1836\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 0, loss = 0.2374\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 100, loss = 0.2316\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Iteration 200, loss = 0.2020\n","Checking accuracy on validation set\n","Got 774 / 1000 correct (77.40)\n","\n","Iteration 300, loss = 0.4165\n","Checking accuracy on validation set\n","Got 768 / 1000 correct (76.80)\n","\n","Iteration 400, loss = 0.1104\n","Checking accuracy on validation set\n","Got 761 / 1000 correct (76.10)\n","\n","Iteration 500, loss = 0.2114\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 600, loss = 0.2763\n","Checking accuracy on validation set\n","Got 771 / 1000 correct (77.10)\n","\n","Iteration 700, loss = 0.1388\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Iteration 0, loss = 0.1384\n","Checking accuracy on validation set\n","Got 762 / 1000 correct (76.20)\n","\n","Iteration 100, loss = 0.3289\n","Checking accuracy on validation set\n","Got 769 / 1000 correct (76.90)\n","\n","Iteration 200, loss = 0.2976\n","Checking accuracy on validation set\n","Got 764 / 1000 correct (76.40)\n","\n","Iteration 300, loss = 0.2765\n","Checking accuracy on validation set\n","Got 737 / 1000 correct (73.70)\n","\n","Iteration 400, loss = 0.1715\n","Checking accuracy on validation set\n","Got 764 / 1000 correct (76.40)\n","\n","Iteration 500, loss = 0.2583\n","Checking accuracy on validation set\n","Got 792 / 1000 correct (79.20)\n","\n","Iteration 600, loss = 0.2268\n","Checking accuracy on validation set\n","Got 759 / 1000 correct (75.90)\n","\n","Iteration 700, loss = 0.2624\n","Checking accuracy on validation set\n","Got 785 / 1000 correct (78.50)\n","\n","Iteration 0, loss = 0.0651\n","Checking accuracy on validation set\n","Got 793 / 1000 correct (79.30)\n","\n","Iteration 100, loss = 0.1979\n","Checking accuracy on validation set\n","Got 768 / 1000 correct (76.80)\n","\n","Iteration 200, loss = 0.1318\n","Checking accuracy on validation set\n","Got 774 / 1000 correct (77.40)\n","\n","Iteration 300, loss = 0.0432\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 400, loss = 0.1387\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 500, loss = 0.1784\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Iteration 600, loss = 0.2836\n","Checking accuracy on validation set\n","Got 779 / 1000 correct (77.90)\n","\n","Iteration 700, loss = 0.1791\n","Checking accuracy on validation set\n","Got 783 / 1000 correct (78.30)\n","\n","Iteration 0, loss = 0.2053\n","Checking accuracy on validation set\n","Got 794 / 1000 correct (79.40)\n","\n","Iteration 100, loss = 0.4386\n","Checking accuracy on validation set\n","Got 801 / 1000 correct (80.10)\n","\n","Iteration 200, loss = 0.1054\n","Checking accuracy on validation set\n","Got 778 / 1000 correct (77.80)\n","\n","Iteration 300, loss = 0.1573\n","Checking accuracy on validation set\n","Got 768 / 1000 correct (76.80)\n","\n","Iteration 400, loss = 0.0954\n","Checking accuracy on validation set\n","Got 765 / 1000 correct (76.50)\n","\n","Iteration 500, loss = 0.1508\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 600, loss = 0.2464\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 700, loss = 0.3199\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Iteration 0, loss = 0.2102\n","Checking accuracy on validation set\n","Got 794 / 1000 correct (79.40)\n","\n","Iteration 100, loss = 0.2326\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Iteration 200, loss = 0.1697\n","Checking accuracy on validation set\n","Got 782 / 1000 correct (78.20)\n","\n","Iteration 300, loss = 0.2386\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 400, loss = 0.2108\n","Checking accuracy on validation set\n","Got 769 / 1000 correct (76.90)\n","\n","Iteration 500, loss = 0.1098\n","Checking accuracy on validation set\n","Got 781 / 1000 correct (78.10)\n","\n","Iteration 600, loss = 0.1909\n","Checking accuracy on validation set\n","Got 774 / 1000 correct (77.40)\n","\n","Iteration 700, loss = 0.2852\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 0, loss = 0.1160\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 100, loss = 0.1840\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 200, loss = 0.3629\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 300, loss = 0.0684\n","Checking accuracy on validation set\n","Got 796 / 1000 correct (79.60)\n","\n","Iteration 400, loss = 0.1411\n","Checking accuracy on validation set\n","Got 803 / 1000 correct (80.30)\n","\n","Iteration 500, loss = 0.1530\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 600, loss = 0.3064\n","Checking accuracy on validation set\n","Got 752 / 1000 correct (75.20)\n","\n","Iteration 700, loss = 0.5814\n","Checking accuracy on validation set\n","Got 630 / 1000 correct (63.00)\n","\n","Iteration 0, loss = 0.1292\n","Checking accuracy on validation set\n","Got 748 / 1000 correct (74.80)\n","\n","Iteration 100, loss = 0.1121\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 200, loss = 0.1393\n","Checking accuracy on validation set\n","Got 779 / 1000 correct (77.90)\n","\n","Iteration 300, loss = 0.1978\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 400, loss = 0.1851\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Iteration 500, loss = 0.2315\n","Checking accuracy on validation set\n","Got 777 / 1000 correct (77.70)\n","\n","Iteration 600, loss = 0.1845\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 700, loss = 0.2151\n","Checking accuracy on validation set\n","Got 779 / 1000 correct (77.90)\n","\n","Iteration 0, loss = 0.0752\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 100, loss = 0.1516\n","Checking accuracy on validation set\n","Got 770 / 1000 correct (77.00)\n","\n","Iteration 200, loss = 0.0597\n","Checking accuracy on validation set\n","Got 793 / 1000 correct (79.30)\n","\n","Iteration 300, loss = 0.1851\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 400, loss = 0.2546\n","Checking accuracy on validation set\n","Got 794 / 1000 correct (79.40)\n","\n","Iteration 500, loss = 0.2163\n","Checking accuracy on validation set\n","Got 809 / 1000 correct (80.90)\n","\n","Iteration 600, loss = 0.1195\n","Checking accuracy on validation set\n","Got 786 / 1000 correct (78.60)\n","\n","Iteration 700, loss = 0.1795\n","Checking accuracy on validation set\n","Got 781 / 1000 correct (78.10)\n","\n","Iteration 0, loss = 0.0209\n","Checking accuracy on validation set\n","Got 783 / 1000 correct (78.30)\n","\n","Iteration 100, loss = 0.2938\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 200, loss = 0.0530\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 300, loss = 0.1635\n","Checking accuracy on validation set\n","Got 786 / 1000 correct (78.60)\n","\n","Iteration 400, loss = 0.2413\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 500, loss = 0.1380\n","Checking accuracy on validation set\n","Got 772 / 1000 correct (77.20)\n","\n","Iteration 600, loss = 0.0941\n","Checking accuracy on validation set\n","Got 785 / 1000 correct (78.50)\n","\n","Iteration 700, loss = 0.1403\n","Checking accuracy on validation set\n","Got 796 / 1000 correct (79.60)\n","\n","Iteration 0, loss = 0.0412\n","Checking accuracy on validation set\n","Got 765 / 1000 correct (76.50)\n","\n","Iteration 100, loss = 0.0411\n","Checking accuracy on validation set\n","Got 781 / 1000 correct (78.10)\n","\n","Iteration 200, loss = 0.1287\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 300, loss = 0.0730\n","Checking accuracy on validation set\n","Got 772 / 1000 correct (77.20)\n","\n","Iteration 400, loss = 0.1225\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 500, loss = 0.0295\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 600, loss = 0.0911\n","Checking accuracy on validation set\n","Got 792 / 1000 correct (79.20)\n","\n","Iteration 700, loss = 0.0723\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 0, loss = 0.0722\n","Checking accuracy on validation set\n","Got 783 / 1000 correct (78.30)\n","\n","Iteration 100, loss = 0.1365\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 200, loss = 0.1278\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 300, loss = 0.0839\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 400, loss = 0.1414\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 500, loss = 0.1473\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Iteration 600, loss = 0.1601\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 700, loss = 0.2109\n","Checking accuracy on validation set\n","Got 797 / 1000 correct (79.70)\n","\n","Iteration 0, loss = 0.0358\n","Checking accuracy on validation set\n","Got 813 / 1000 correct (81.30)\n","\n","Iteration 100, loss = 0.0441\n","Checking accuracy on validation set\n","Got 782 / 1000 correct (78.20)\n","\n","Iteration 200, loss = 0.0882\n","Checking accuracy on validation set\n","Got 778 / 1000 correct (77.80)\n","\n","Iteration 300, loss = 0.1313\n","Checking accuracy on validation set\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-8db71db0dcac>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_pretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_pretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-efe653b99eac>\u001b[0m in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration %d, loss = %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mcheck_accuracy_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-6bb93280a1d6>\u001b[0m in \u001b[0;36mcheck_accuracy_part34\u001b[0;34m(loader, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["optimizer = optim.Adam(resnet_pretrained.parameters(), lr = 0.01)\n","train_part34(resnet_pretrained, optimizer, epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_l7diPcCqO_4","executionInfo":{"status":"aborted","timestamp":1690043001490,"user_tz":-540,"elapsed":10,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}}},"outputs":[],"source":["check_accuracy_part34(loader_test, resnet_pretrained)"]},{"cell_type":"markdown","metadata":{"id":"wvtjmX24uhMg"},"source":["ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ì–»ìœ¼ì…¨ë‚˜ìš”?\n","\n","ì§ì ‘ ë§Œë“  Modelê³¼ ë¹„êµí•´ ë´¤ì„ ë•Œ ì–´ë–¤ modelì´ ë” ì„±ëŠ¥ì´ ì¢‹ì•˜ê³  ì™œ ê·¸ëŸ° ê²°ê³¼ê°€ ë‚˜ì™”ì„ê¹Œìš”?\n","\n","ë§Œì•½ í•™ìŠµì´ ì˜ ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆì„ê¹Œìš”?\n","\n","> [torchvision document](https://pytorch.org/vision/stable/index.html)ì— ìˆëŠ” ë‹¤ì–‘í•œ Modelë“¤ì„ ì‹œë„í•´ ë³´ë©´ì„œ ë¹„êµí•´ ë³´ë„ë¡ í•©ì‹œë‹¤."]},{"cell_type":"code","source":["efficientnet_b0_pretrained = models.efficientnet_b0(pretrained=True)\n","print(efficientnet_b0_pretrained)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bR25XtT8WKLk","executionInfo":{"status":"ok","timestamp":1690043006767,"user_tz":-540,"elapsed":941,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"3d8d87a7-8436-4e5d-9959-9f21d0f8c22f"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-3dd342df.pth\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20.5M/20.5M [00:00<00:00, 61.3MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["EfficientNet(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (2): Conv2dNormActivation(\n","            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n","      )\n","    )\n","    (2): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n","      )\n","    )\n","    (3): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n","      )\n","    )\n","    (4): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n","      )\n","    )\n","    (8): Conv2dNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=1)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=True)\n","    (1): Linear(in_features=1280, out_features=1000, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","execution_count":42,"metadata":{"id":"pOnK6v92vIwR","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1690043253576,"user_tz":-540,"elapsed":125146,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"3848bbe2-e291-4631-b811-1cda3238b160"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.2862\n","Checking accuracy on validation set\n","Got 151 / 1000 correct (15.10)\n","\n","Iteration 100, loss = 2.7052\n","Checking accuracy on validation set\n","Got 99 / 1000 correct (9.90)\n","\n","Iteration 200, loss = 3.0521\n","Checking accuracy on validation set\n","Got 75 / 1000 correct (7.50)\n","\n","Iteration 300, loss = 2.3734\n","Checking accuracy on validation set\n","Got 137 / 1000 correct (13.70)\n","\n","Iteration 400, loss = 2.4278\n","Checking accuracy on validation set\n","Got 88 / 1000 correct (8.80)\n","\n","Iteration 500, loss = 2.3963\n","Checking accuracy on validation set\n","Got 143 / 1000 correct (14.30)\n","\n","Iteration 600, loss = 2.2738\n","Checking accuracy on validation set\n","Got 130 / 1000 correct (13.00)\n","\n","Iteration 700, loss = 2.3661\n","Checking accuracy on validation set\n","Got 138 / 1000 correct (13.80)\n","\n","Iteration 0, loss = 2.3521\n","Checking accuracy on validation set\n","Got 114 / 1000 correct (11.40)\n","\n","Iteration 100, loss = 2.3535\n","Checking accuracy on validation set\n","Got 129 / 1000 correct (12.90)\n","\n","Iteration 200, loss = 2.3652\n","Checking accuracy on validation set\n","Got 131 / 1000 correct (13.10)\n","\n","Iteration 300, loss = 2.3694\n","Checking accuracy on validation set\n","Got 111 / 1000 correct (11.10)\n","\n","Iteration 400, loss = 2.3235\n","Checking accuracy on validation set\n","Got 113 / 1000 correct (11.30)\n","\n","Iteration 500, loss = 2.6111\n","Checking accuracy on validation set\n","Got 132 / 1000 correct (13.20)\n","\n","Iteration 600, loss = 2.2735\n","Checking accuracy on validation set\n","Got 127 / 1000 correct (12.70)\n","\n","Iteration 700, loss = 2.3837\n","Checking accuracy on validation set\n","Got 164 / 1000 correct (16.40)\n","\n","Iteration 0, loss = 2.2023\n","Checking accuracy on validation set\n","Got 146 / 1000 correct (14.60)\n","\n","Iteration 100, loss = 2.1828\n","Checking accuracy on validation set\n","Got 129 / 1000 correct (12.90)\n","\n","Iteration 200, loss = 2.2122\n","Checking accuracy on validation set\n","Got 149 / 1000 correct (14.90)\n","\n","Iteration 300, loss = 2.4081\n","Checking accuracy on validation set\n","Got 134 / 1000 correct (13.40)\n","\n","Iteration 400, loss = 2.3240\n","Checking accuracy on validation set\n","Got 131 / 1000 correct (13.10)\n","\n","Iteration 500, loss = 2.4406\n","Checking accuracy on validation set\n","Got 148 / 1000 correct (14.80)\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-dc78d43ce801>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefficientnet_b0_pretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-efe653b99eac>\u001b[0m in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move the model parameters to CPU/GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# put model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["################################################################################\n","# TODO:                                                                        #\n","# Download any pretrained model from torchvision, then finetuning them         #\n","################################################################################\n","model = None\n","optimizer = None\n","\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","num_ftrs = efficientnet_b0_pretrained.classifier[1].in_features\n","num_classes = 10\n","\n","efficientnet_b0_pretrained.classifier[1] = nn.Linear(num_ftrs, num_classes)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","model = efficientnet_b0_pretrained\n","optimizer = optim.Adam(efficientnet_b0_pretrained.parameters(), lr = 0.01)\n","\n","train_part34(model, optimizer, epochs=3)"]},{"cell_type":"code","source":["efficientnet_b0_pretrained"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jz8iv7bfbKlB","executionInfo":{"status":"ok","timestamp":1690043256614,"user_tz":-540,"elapsed":393,"user":{"displayName":"ì´ì§„ê·œ","userId":"14200365865951724458"}},"outputId":"d1b9a3f0-1cb4-44ef-c539-076567c9f5ba"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EfficientNet(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (2): Conv2dNormActivation(\n","            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n","      )\n","    )\n","    (2): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n","      )\n","    )\n","    (3): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n","      )\n","    )\n","    (4): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n","      )\n","    )\n","    (8): Conv2dNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=1)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=True)\n","    (1): Linear(in_features=1280, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"7qtKTBHduRa5"},"source":["**Answer:**\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}