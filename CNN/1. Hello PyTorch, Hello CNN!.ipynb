{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"JeXa6KG1pR1s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038580502,"user_tz":-540,"elapsed":27405,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"a14a0a8c-0704-4e56-be8b-35b6cfbef8e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/AIKU/DeepInDeep/과제_1/D2D/datasets\n","/content/drive/My Drive/AIKU/DeepInDeep/과제_1/D2D\n"]}],"source":["# Google Drive를 Colab VM에 Mount 합니다.\n","# '로그인 하겠습니까?' 묻는 창이 나오면 허가 해 주세요.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 과제 파일을 다운 받은 경로를 입력해야 합니다.\n","# Google Drive의 폴더 경로는 /content/drive/My Drive/ 부터 시작합니다.\n","# 즉, 만약 당신이 구글 드라이브 최상단에 있는 'D2D' 폴더에 해당 파일을 다운 받았다고 합시다.\n","# 그러면 D2D 안에는 'Assignment 0' Colab 파일과, datasets 폴더가 있을 것입니다.\n","# 그렇다면 밑의 경로에는 '/D2D' 라고 적어주면 됩니다. 마지막에 '/'가 없음에 유의해 주세요.\n","FOLDERNAME = 'AIKU/DeepInDeep/과제_1/D2D'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# 이제 Drive를 마운트 했음을 확인했습니다.\n","# Python interpreter가 Colab VM이 python files를 load 할 수 있는지 확인합니다.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","# 이 코드는 CIFAR-10 dataset이 Drive에 있는지 확인하고, 없으면 저장합니다.\n","%cd /content/drive/My\\ Drive/$FOLDERNAME/datasets/\n","!bash get_datasets.sh\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"]},{"cell_type":"markdown","metadata":{"id":"vtsHWi7KpR1x"},"source":["# PyTorch 시작하기\n","**AIKU 학회원 여러분!** 딥러닝을 향한 여정에 발 들인 것을 환영합니다😄.\n","\n","학회원 여러분이 앞으로 마주하게 될 여러 어려움들이 있을텐데, Deep Into Deep의 수업과 과제가 그 길에 조금은 도움이 되길 바랍니다.\n","\n","본 과제는 CS231n, 고려대학교 딥러닝 수업 등 여러 좋은 과제들을 혼합해 만들어 졌음을 미리 알립니다. 거인의 어깨를 만들어준 여러분 감사합니다!\n","\n","다시 한 번 만나서 반갑습니다! **Happy Hacking!**"]},{"cell_type":"markdown","metadata":{"id":"r7e58EDipR1z"},"source":["## 왜 Deep Learning frameworks를 써야할까요?\n","\n","* 우리의 Code를 GPU로 실행 시킬 수 있습니다! 이를 통해 모델을 훨씬 빠르게 훈련할 수 있습니다. PyTorch나 TensorFlow와 같은 프레임워크를 사용하면 CUDA 코드를 직접 작성할 필요 없이(이 강의의 범위를 벗어나는) 자신만의 맞춤형 신경망 아키텍처를 위해 GPU의 성능을 활용할 수 있습니다.\n","\n","* 이 강의에서는 프로젝트에 이러한 프레임워크 중 하나 (PyTorch)를 사용하여 사용하려는 모든 기능을 직접 작성할 때보다 더 효율적으로 실험할 수 있도록 준비할 것입니다.\n","\n","* 거인들의 어깨 위에 서 보시기 바랍니다! TensorFlow와 PyTorch는 모두 여러분의 삶을 훨씬 편하게 만들어줄 훌륭한 프레임워크이며, 이제 그 기능을 이해하셨으니 자유롭게 사용하셔도 됩니다 :)\n","\n","* 마지막으로, 학계나 업계에서 접할 수 있는 딥 러닝 코드에 노출되기를 바랍니다.\n","\n","## PyTorch란 무엇일까요?\n","numpy의 ndarray와 비슷하게 동작하는 **Tensor objects**에 대해서 동적 computational graphs를 실행하는 시스템입니다. PyTorch는 사람이 직접 backpropagation을 계산할 필요가 없이 강력한 **자동 미분** 엔진을 제공합니다.\n","\n","## 어떻게 PyTorch를 배울 수 있을까요?\n","이 과제만으로는 PyTorch 전반을 이해하는데 어려움이 있을 수 있습니다.\n","\n","여러 가지 방법이 추천되지만, 도움이 될 만한 사이트와 학습 방법을 알려드리겠습니다.\n","\n","PyTorch 공식 한국어 튜토리얼 :\n","https://tutorials.pytorch.kr/beginner/basics/intro.html\n","\n","Stanford의 PyTorch 강의 : https://github.com/jcjohnson/pytorch-examples\n"]},{"cell_type":"markdown","metadata":{"id":"Ulz-ISjJpR10"},"source":["# 목차\n","이 과제는 6개의 파트로 구성되어 있습니다. 파이토치를 더 잘 이해하고 최종 프로젝트를 준비하는 데 도움이 되는 **세 가지 추상화 수준**에서 파이토치를 배우게 됩니다.\n","\n","이에 더해, 수업 시간에 배웠던 **AlexNet**을 재구현해 보면서 PyTorch에서 CNN Layer를 어떻게 사용할 수 있을지 배우게 됩니다.\n","\n","1. Part I, 준비: CIFAR-10 데이터 세트를 사용합니다.\n","2. Part II, Barebones PyTorch: **추상화 수준 1**의 가장 낮은 수준의 PyTorch 텐서로 직접 작업합니다.\n","3. Part III, PyTorch Module API: **추상화 수준 2**에서는 `nn.Module`을 사용하여 임의의 신경망 아키텍처를 정의합니다.\n","4. Part IV, PyTorch Sequential API: **추상화 수준 3**에서는 `nn.Sequential`을 사용하여 Linear Feed-Forward Network를 매우 편리하게 정의합니다. + **AlexNet**을 재구현해 봅시다!\n","5. Part V, CIFAR-10 open-ended challenge: CIFAR-10에서 가능한 한 높은 정확도를 얻기 위해 자신만의 네트워크를 구현하세요. Layer, Optimizer, hyperparameters 또는 기타 고급 기능으로 실험해 볼 수 있습니다.\n","6. Additional Part, Pretrained model 불러오기: torchvision에서 다양한 pretrained model을 불러보고 finetuning 해 봅시다.\n","\n","다음은 비교 표입니다:\n","\n","| API | 유연성 | 편의성 |\n","|---------------|-------------|-------------|\n","| Barebones | 높음 | 낮음 |\n","| `nn.Module` | 높음 | 중간 |\n","| `nn.Sequential` | 낮음 | 높음 |"]},{"cell_type":"markdown","metadata":{"id":"aZQFg1RRpR11"},"source":["# GPU\n","`런타임 -> 런타임 유형 변경`을 클릭하고 `하드웨어 가속기` 아래에서 `GPU`를 선택하면 Colab에서 GPU 장치로 수동 전환할 수 있습니다. 런타임을 전환하면 커널이 다시 시작되므로 패키지를 가져오기 위해 다음 셀을 실행하기 전에 이 작업을 수행해야 합니다."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cKvYIhDDpR12","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038584814,"user_tz":-540,"elapsed":4314,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"f1bd0e9f-5d7a-43a7-83a0-ac6a2737f84e"},"outputs":[{"output_type":"stream","name":"stdout","text":["using device: cuda\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","USE_GPU = True\n","dtype = torch.float32 # We will be using float throughout this tutorial.\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","# Constant to control how frequently we print train loss.\n","print_every = 100\n","print('using device:', device)"]},{"cell_type":"markdown","metadata":{"id":"e4q1RwwngAJz"},"source":["`using device: cuda`가 나오면 성공입니다!"]},{"cell_type":"markdown","metadata":{"id":"swu-jxUigCVr"},"source":["## What is 'CUDA'?\n","\n","\n","> CUDA(\"Compute Unified Device Architecture\", 쿠다)는 그래픽 처리 장치(GPU)에서 수행하는 (병렬 처리) 알고리즘을 C 프로그래밍 언어를 비롯한 산업 표준 언어를 사용하여 작성할 수 있도록 하는 GPGPU 기술이다. -Wikipedia-\n","\n","GPU는 원래 그 이름에서도 알 수 있듯이 Graphic 연산을 위한 장치였습니다. 하지만 GPU가 병렬 처리를 매우 빠른 속도로 처리한다는 점에 주목하여, 일반적인 matrix 연산에 사용될 수 있는 GPGPU 기술이 제시되었습니다. NVIDA가 지원하는 CUDA를 통해 개발자들이 쉽게 GPU 상에서 병렬 처리 알고리즘을 실행할 수 있게 도와줍니다.\n","\n","지금 과제는 Colab에서 진행되므로 특별히 CUDA Version을 설정해 줄 필요가 없습니다. 그렇지만, 앞으로 Local, 또는 Server에서 Deep Learning 코드를 실행하다 보면 CUDA, PyTorch 버젼과 관련된 오류를 많이 마주할 것입니다. 그럴 땐 다음과 같은 기술을 검토해 보세요.\n","* Anaconda\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E9fI9EE0pR12"},"source":["# Part I. 준비\n","이제 CIFAR-10 데이터 세트를 로드해 보겠습니다. 처음 몇 분 정도 걸릴 수 있지만 그 이후에는 파일이 캐시된 상태로 유지됩니다."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"MDBJu2TJpR13","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038810325,"user_tz":-540,"elapsed":10051,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"bc31ba3f-73a6-4a08-e0c7-7dc118b6b7cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["NUM_TRAIN = 49000\n","\n","# The torchvision.transforms package provides tools for preprocessing data\n","# and for performing data augmentation; here we set up a transform to\n","# preprocess the data by subtracting the mean RGB value and dividing by the\n","# standard deviation of each RGB value; we've hardcoded the mean and std.\n","\n","#데이터 전처리(Transform), 입력 데이터를 텐서 바꿔주고 Normalize 해준다\n","transform = T.Compose([\n","                T.ToTensor(),\n","                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","            ])\n","\n","# We set up a Dataset object for each split (train / val / test); Datasets load\n","# training examples one at a time, so we wrap each Dataset in a DataLoader which\n","# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n","# training set into train and val sets by passing a Sampler object to the\n","# DataLoader telling how it should sample from the underlying Dataset.\n","\n","#train data 가져오기\n","cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n","                             transform=transform) #train dataset 불러오기\n","\n","#dataloader를 통해 train data를 batch로 split & save\n","loader_train = DataLoader(cifar10_train, batch_size=64,\n","                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n","\n","##validation data 가져오기 (근데 왜 train에서 함께 가져왔을까)\n","cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n","                           transform=transform)\n","\n","#dataloader를 통한 val data를 batch로 split&save\n","loader_val = DataLoader(cifar10_val, batch_size=64,\n","                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n","\n","#test data 가져오기\n","cifar10_test = dset.CIFAR10('./datasets', train=False, download=True,\n","                            transform=transform)\n","\n","#dataloader로 test data split\n","loader_test = DataLoader(cifar10_test, batch_size=64)"]},{"cell_type":"markdown","metadata":{"id":"yTVAtckopR14"},"source":["## Part II. Barebones PyTorch\n","PyTorch는 모델 아키텍처를 편리하게 정의하는 데 도움이 되는 하이레벨 API와 함께 제공되며, 이 튜토리얼의 Part II에서는 이를 다룰 것입니다. 이 섹션에서는 autograd engine을 더 잘 이해하기 위해 Barebones PyTorch 요소부터 시작하겠습니다. 이 연습을 마치면 하이레벨 모델 API를 더 잘 이해하게 될 것입니다.\n","\n","두 개의 숨겨진 레이어가 있고 CIFAR 분류를 위한 bias가 없는 간단한 Fully-connected ReLU 네트워크로 시작하겠습니다. 이 구현은 PyTorch 텐서에서 연산을 사용하여 forward pass를 계산하고 PyTorch autograd를 사용하여 gradient를 계산합니다. 이 예제 이후에 더 어려운 버전을 작성할 것이므로 모든 줄을 이해하는 것이 중요합니다.\n","\n","`requires_grad = True`로 PyTorch 텐서를 생성하면 해당 텐서를 포함하는 연산은 값만 계산하는 것이 아니라 백그라운드에서 계산 그래프를 구축하여 그래프를 통해 쉽게 역전파하여 다운스트림 손실에 대한 일부 텐서의 기울기를 계산할 수 있게 해줍니다. 구체적으로 x가 `x.requires_grad == True`인 텐서인 경우, 역전파 후 `x.grad`는 마지막에 scalar loss에 대한 x의 기울기를 보유하는 또 다른 텐서가 될 것입니다."]},{"cell_type":"markdown","metadata":{"id":"KLO6iHpBpR15"},"source":["### PyTorch Tensors: Flatten 함수\n","PyTorch Tensors는 개념적으로 n차원 배열과 유사합니다. n차원 숫자 그리드이며, PyTorch는 n차원 배열과 마찬가지로 텐서에서 효율적으로 작동할 수 있는 많은 함수를 제공합니다. 간단한 예로, 아래에서는 완전히 연결된 신경망에서 사용할 수 있도록 이미지 데이터를 재구성하는 `flatten` 함수를 제공합니다.\n","\n","이미지 데이터는 일반적으로 N x C x H x W 형태의 텐서에 저장된다는 점을 기억하세요:\n","\n","* N은 데이터 포인트의 수입니다.\n","* C는 채널 수입니다.\n","* H는 중간 특징 맵의 픽셀 단위 높이입니다.\n","* W는 중간 피처 맵의 높이(픽셀)입니다.\n","\n","이는 2D convolution 같이 중간 특징이 서로 상대적인 위치에 대한 공간적 이해가 필요한 작업을 수행할 때 데이터를 표현하는 데 적합한 방법입니다. 그러나 fully connected affine layers를 사용하여 이미지를 처리할 때는 각 데이터 포인트를 단일 벡터로 표현해야 하므로 데이터의 여러 채널, 행, 열을 분리하는 것은 더 이상 유용하지 않습니다. 따라서 'flatten' 연산을 사용하여 표현당 `C x H x W` 값을 하나의 긴 벡터로 축소합니다. 아래의 flatten 함수는 먼저 주어진 데이터 배치에서 N, C, H, W 값을 읽은 다음 해당 데이터의 'view'를 반환합니다. \"view\"는 numpy의 \"reshape\" 메서드와 유사합니다. x의 차원을 N x ?? 로 재형성하며, 여기서 ?? 는 무엇이든 허용됩니다(이 경우 C x H x W가 되지만 명시적으로 지정할 필요는 없습니다)."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"pUnA0EncpR15","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038810327,"user_tz":-540,"elapsed":12,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"d69c6694-e1bb-4054-fe69-29f95f502393"},"outputs":[{"output_type":"stream","name":"stdout","text":["Before flattening:  tensor([[[[ 0,  1],\n","          [ 2,  3],\n","          [ 4,  5]]],\n","\n","\n","        [[[ 6,  7],\n","          [ 8,  9],\n","          [10, 11]]]])\n","After flattening:  tensor([[ 0,  1,  2,  3,  4,  5],\n","        [ 6,  7,  8,  9, 10, 11]])\n"]}],"source":["def flatten(x):\n","    N = x.shape[0] # read in N, C, H, W\n","    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n","\n","def test_flatten():\n","    x = torch.arange(12).view(2, 1, 3, 2)\n","    print('Before flattening: ', x)\n","    print('After flattening: ', flatten(x))\n","\n","test_flatten()"]},{"cell_type":"markdown","metadata":{"id":"wpnPI6lVpR16"},"source":["### Barebones PyTorch: Two-Layer Network\n","\n","여기에서는 이미지 데이터 배치에 대해 완전히 연결된 2계층 ReLU 네트워크의 포워드 패스를 수행하는 함수 `two_layer_fc`를 정의합니다. 포워드 패스를 정의한 후에는 네트워크를 통해 0을 실행하여 충돌이 발생하지 않는지, 올바른 모양의 출력을 생성하는지 확인합니다.\n","\n","여기서 코드를 작성할 필요는 없지만 구현을 읽고 이해하는 것이 중요합니다."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"vg43S8B0pR16","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038817343,"user_tz":-540,"elapsed":2,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"c3576124-d368-4954-f08d-bb46dccc5823"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["import torch.nn.functional as F  # useful stateless functions\n","\n","def two_layer_fc(x, params):\n","    \"\"\"\n","    A fully-connected neural networks; the architecture is:\n","    NN is fully connected -> ReLU -> fully connected layer.\n","    Note that this function only defines the forward pass;\n","    PyTorch will take care of the backward pass for us.\n","\n","    The input to the network will be a minibatch of data, of shape\n","    (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n","    and the output layer will produce scores for C classes.\n","\n","    Inputs:\n","    - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of\n","      input data.\n","    - params: A list [w1, w2] of PyTorch Tensors giving weights for the network;\n","      w1 has shape (D, H) and w2 has shape (H, C).\n","\n","    Returns:\n","    - scores: A PyTorch Tensor of shape (N, C) giving classification scores for\n","      the input data x.\n","    \"\"\"\n","    # first we flatten the image\n","    x = flatten(x)  # shape: [batch_size, C x H x W]\n","\n","    w1, w2 = params\n","\n","    # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n","    # w2 have requires_grad=True, operations involving these Tensors will cause\n","    # PyTorch to build a computational graph, allowing automatic computation of\n","    # gradients. Since we are no longer implementing the backward pass by hand we\n","    # don't need to keep references to intermediate values.\n","    # you can also use `.clamp(min=0)`, equivalent to F.relu()\n","\n","    x = F.relu(x.mm(w1)) #torch.mm은 행렬 곱을 의미한다.\n","    x = x.mm(w2)\n","    ##마지막 레이어에 대해서는 활성화함수 없어도 괜찮은가? -> 크로스 앤트로피 로스에서 softmax까지 처리해준다!\n","    return x\n","\n","\n","def two_layer_fc_test():\n","    hidden_layer_size = 42\n","    x = torch.zeros((64, 50), dtype=dtype)  # minibatch size 64, feature dimension 50\n","    w1 = torch.zeros((50, hidden_layer_size), dtype=dtype)\n","    w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype)\n","    scores = two_layer_fc(x, [w1, w2])\n","    print(scores.size())  # you should see [64, 10]\n","\n","two_layer_fc_test()"]},{"cell_type":"markdown","metadata":{"id":"Hpfeu2JJpR17"},"source":["### Barebones PyTorch: Three-Layer ConvNet\n","\n","여기서는 3계층 Convolution 네트워크의 순방향 패스를 수행하는 `three_layer_convnet` 함수의 구현을 완료합니다. 위와 같이 네트워크에 0을 전달하여 구현을 즉시 테스트할 수 있습니다. 네트워크는 다음과 같은 구조를 가져야 합니다:\n","\n","1. `channel_1` 필터가 있는 Convolution 레이어(bias 포함), 각각 모양이 `KW1 x KH1`이고 zero padding 이 2입니다.\n","2. ReLU nonlinearity\n","3. `channel_2` 필터가 있는 Convolution 레이어(bias 포함), 각 필터의 모양이 `KW2 x KH2`이고 제로 패딩이 1입니다.\n","4. ReLU nonlinearity\n","5. bias가 있는 Fully-connected layer, C 클래스에 대한 점수를 생성합니다.\n","\n","Fully-connected layer 이후에는 **소프트맥스 활성화가 없음**에 유의하십시오: 이는 PyTorch의 교차 엔트로피 손실이 소프트맥스 활성화를 수행하기 때문이며, 이 단계를 번들로 묶으면 계산이 더 효율적이기 때문입니다.\n","\n","**힌트**: Convolutions에 대해: http://pytorch.org/docs/stable/nn.html#torch.nn.functional.conv2d; convolutional filters 모양에 주의해 주세요!"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ECDdAX4GpR18","executionInfo":{"status":"ok","timestamp":1690038817343,"user_tz":-540,"elapsed":1,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"outputs":[],"source":["def three_layer_convnet(x, params):\n","    \"\"\"\n","    Performs the forward pass of a three-layer convolutional network with the\n","    architecture defined above.\n","\n","    Inputs:\n","    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images\n","    - params: A list of PyTorch Tensors giving the weights and biases for the\n","      network; should contain the following:\n","      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n","        for the first convolutional layer\n","      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n","        convolutional layer\n","      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n","        weights for the second convolutional layer\n","      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n","        convolutional layer\n","      - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","      - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","\n","    Returns:\n","    - scores: PyTorch Tensor of shape (N, C) giving classification scores for x\n","    \"\"\"\n","    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n","    scores = None\n","    ################################################################################\n","    # TODO: Implement the forward pass for the three-layer ConvNet.                #\n","    ################################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    A_1 = torch.nn.functional.conv2d(x, conv_w1, bias=conv_b1, stride=1, padding=2) #여기서 bias = conv_b1과 뒤에 + conv_b1 해주는 것에 차이가 있을까?\n","    Z_1 = F.relu(A_1)\n","    A_2 = torch.nn.functional.conv2d(Z_1, conv_w2, bias=conv_b2, stride=1, padding=1)\n","    Z_2 = F.relu(A_2)\n","    flatten_Z_2 = flatten(Z_2)\n","    Z_3 = flatten_Z_2.mm(fc_w) + fc_b\n","\n","    scores = Z_3\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ################################################################################\n","    #                                 END OF YOUR CODE                             #\n","    ################################################################################\n","    return scores"]},{"cell_type":"markdown","metadata":{"id":"g6hBYahWpR18"},"source":["위에서 ConvNet의 포워드 패스를 정의한 후 다음 셀을 실행하여 구현을 테스트합니다.\n","\n","이 함수를 실행하면 점수는 (64, 10) 모양을 가져야 합니다."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"barebones_output_shape","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038817753,"user_tz":-540,"elapsed":2,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"c1b40237-051d-407c-bc3a-60e64137a5c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["def three_layer_convnet_test():\n","    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n","\n","    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n","    conv_b1 = torch.zeros((6,))  # out_channel\n","    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n","    conv_b2 = torch.zeros((9,))  # out_channel\n","\n","    # you must calculate the shape of the tensor after two conv layers, before the fully-connected layer\n","    fc_w = torch.zeros((9 * 32 * 32, 10))\n","    fc_b = torch.zeros(10)\n","\n","    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n","    print(scores.size())  # you should see [64, 10]\n","three_layer_convnet_test()"]},{"cell_type":"markdown","metadata":{"id":"2jxzynJspR19"},"source":["### Barebones PyTorch: Initialization\n","모델의 가중치 행렬을 초기화하는 몇 가지 유틸리티 메서드를 작성해 보겠습니다.\n","\n","- `random_weight(shape)`는 Kaiming normalization 방법으로 가중치 텐서를 초기화합니다.\n","- `zero_weight(shape)`는 모든 0으로 가중치 텐서를 초기화합니다. 바이어스 매개변수를 인스턴스화할 때 유용합니다.\n","\n","`random_weight` 함수는 Kaiming normal initialization 방법을 사용합니다:\n","\n","He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*, ICCV 2015, https://arxiv.org/abs/1502.01852"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"UXkgnTzMpR19","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038819570,"user_tz":-540,"elapsed":2,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"dda5f45e-d14a-4236-8722-cb378492e9cb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.2312, -1.4870,  0.5531, -0.4321,  0.3992],\n","        [ 1.9478, -0.3602,  0.7176, -0.2205,  0.4583],\n","        [ 0.4094, -0.6763,  0.9371,  0.6880,  0.3608]], device='cuda:0',\n","       requires_grad=True)"]},"metadata":{},"execution_count":15}],"source":["def random_weight(shape):\n","    \"\"\"\n","    Create random Tensors for weights; setting requires_grad=True means that we\n","    want to compute gradients for these Tensors during the backward pass.\n","    We use Kaiming normalization: sqrt(2 / fan_in)\n","    \"\"\"\n","\n","    #kaiming he normalziation은 convolution 연산에 많이 쓰이는 가중치 초기화 방식으로\n","    #특성 층의 활성화 함수에 대한 분산을 일정하게 유지하기 위해 사용된다.\n","    #밑의 fan_in은 가중치 텐서의 채널(피쳐) 수이다.\n","    if len(shape) == 2:  # FC weight, FC layer에 대해서는 Flatten된 값이기 때문에\n","        fan_in = shape[0]\n","\n","    else:\n","        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n","    # randn is standard normal distribution generator.\n","    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in) #Xavier는 np.sqrt(1/fan_in)이고 tanh에 사용, He는 np.sqrt(2/fan_in)이고 Relu에 사용\n","    w.requires_grad = True\n","    return w\n","\n","def zero_weight(shape):\n","    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n","\n","# create a weight of shape [3 x 5]\n","# you should see the type `torch.cuda.FloatTensor` if you use GPU.\n","# Otherwise it should be `torch.FloatTensor`\n","random_weight((3, 5))"]},{"cell_type":"markdown","metadata":{"id":"_Z1t3y6YpR19"},"source":["### Barebones PyTorch: Check Accuracy\n","모델을 훈련할 때 다음 함수를 사용하여 훈련 또는 검증 세트에서 모델의 정확도를 확인합니다.\n","\n","정확도를 확인할 때 기울기를 계산할 필요가 없으므로 점수를 계산할 때 PyTorch가 계산 그래프를 만들 필요가 없습니다. 그래프가 생성되는 것을 방지하기 위해 `torch.no_grad()` context manager에서 계산 범위를 지정합니다."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"jre5tpX2pR1-","executionInfo":{"status":"ok","timestamp":1690038820068,"user_tz":-540,"elapsed":2,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"outputs":[],"source":["def check_accuracy_part2(loader, model_fn, params):\n","    \"\"\"\n","    Check the accuracy of a classification model.\n","\n","    Inputs:\n","    - loader: A DataLoader for the data split we want to check\n","    - model_fn: A function that performs the forward pass of the model,\n","      with the signature scores = model_fn(x, params)\n","    - params: List of PyTorch Tensors giving parameters of the model\n","\n","    Returns: Nothing, but prints the accuracy of the model\n","    \"\"\"\n","    split = 'val' if loader.dataset.train else 'test'\n","    print('Checking accuracy on the %s set' % split)\n","    num_correct, num_samples = 0, 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.int64)\n","            scores = model_fn(x, params)\n","            _, preds = scores.max(1) #argmax와 같은 역할\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0) #전체 개수로 나눠주기 위함\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"]},{"cell_type":"markdown","metadata":{"id":"OwNMOvc7pR1-"},"source":["### BareBones PyTorch: Training Loop\n","이제 네트워크를 훈련하기 위한 basic training loop를 설정할 수 있습니다. momentum 없이 Stochastic gradient descent를 사용하여 모델을 훈련할 것입니다. 여기서는 `torch.functional.cross_entropy`를 사용하여 loss를 계산할 것입니다(http://pytorch.org/docs/stable/nn.html#cross-entropy).\n","\n","training loop는 신경망 함수, 초기화된 매개변수 목록(예제에서는 `[w1, w2]`), 학습 속도를 입력으로 받습니다."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Fyt2Boy_pR1-","executionInfo":{"status":"ok","timestamp":1690038820532,"user_tz":-540,"elapsed":2,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"outputs":[],"source":["def train_part2(model_fn, params, learning_rate):\n","    \"\"\"\n","    Train a model on CIFAR-10.\n","\n","    Inputs:\n","    - model_fn: A Python function that performs the forward pass of the model.\n","      It should have the signature scores = model_fn(x, params) where x is a\n","      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n","      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n","      scores for the elements in x.\n","    - params: List of PyTorch Tensors giving weights for the model\n","    - learning_rate: Python scalar giving the learning rate to use for SGD\n","\n","    Returns: Nothing\n","    \"\"\"\n","    for t, (x, y) in enumerate(loader_train):\n","        # Move the data to the proper device (GPU or CPU)\n","        x = x.to(device=device, dtype=dtype)\n","        y = y.to(device=device, dtype=torch.long)\n","\n","        # Forward pass: compute scores and loss\n","        scores = model_fn(x, params)\n","        loss = F.cross_entropy(scores, y)\n","\n","        # Backward pass: PyTorch figures out which Tensors in the computational\n","        # graph has requires_grad=True and uses backpropagation to compute the\n","        # gradient of the loss with respect to these Tensors, and stores the\n","        # gradients in the .grad attribute of each Tensor.\n","        loss.backward()\n","\n","        # Update parameters. We don't want to backpropagate through the\n","        # parameter updates, so we scope the updates under a torch.no_grad()\n","        # context manager to prevent a computational graph from being built.\n","        with torch.no_grad():\n","            for w in params:\n","                w -= learning_rate * w.grad\n","\n","                # Manually zero the gradients after running the backward pass\n","                w.grad.zero_()\n","\n","        if t % print_every == 0:\n","            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","            check_accuracy_part2(loader_val, model_fn, params)\n","            print()"]},{"cell_type":"markdown","metadata":{"id":"KhZfY1PzpR1_"},"source":["### BareBones PyTorch: Train a Two-Layer Network\n","이제 training loop를 실행할 준비가 되었습니다. fully connected weights인 `w1`과 `w2`에 대한 Tensor를 명시적으로 할당해야 합니다.\n","\n","CIFAR의 각 minibatch에는 64개의 예가 있으므로 텐서 모양은 `[64, 3, 32, 32]`입니다.\n","\n","flatten 후 `x` 모양은 `[64, 3 * 32 * 32]`가 되어야 합니다. 이것이 `w1`의 첫 번째 차원 크기가 됩니다.\n","`w1`의 두 번째 차원은 hidden layer size이며, 이는 또한 `w2`의 첫 번째 차원이 됩니다.\n","\n","마지막으로 네트워크의 출력은 10개의 클래스에 대한 확률 분포를 나타내는 10차원 벡터입니다.\n","\n","hyperparameter를 조정할 필요는 없지만 한 회기 동안 훈련한 후에는 40% 이상의 정확도를 볼 수 있습니다."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"OVhigckkpR1_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038841728,"user_tz":-540,"elapsed":20766,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"907793e0-9788-4132-cf11-84988569b29e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 3.9069\n","Checking accuracy on the val set\n","Got 165 / 1000 correct (16.50%)\n","\n","Iteration 100, loss = 2.4596\n","Checking accuracy on the val set\n","Got 311 / 1000 correct (31.10%)\n","\n","Iteration 200, loss = 2.0550\n","Checking accuracy on the val set\n","Got 377 / 1000 correct (37.70%)\n","\n","Iteration 300, loss = 1.9371\n","Checking accuracy on the val set\n","Got 360 / 1000 correct (36.00%)\n","\n","Iteration 400, loss = 1.9233\n","Checking accuracy on the val set\n","Got 419 / 1000 correct (41.90%)\n","\n","Iteration 500, loss = 1.7812\n","Checking accuracy on the val set\n","Got 418 / 1000 correct (41.80%)\n","\n","Iteration 600, loss = 1.4448\n","Checking accuracy on the val set\n","Got 410 / 1000 correct (41.00%)\n","\n","Iteration 700, loss = 1.7972\n","Checking accuracy on the val set\n","Got 449 / 1000 correct (44.90%)\n","\n"]}],"source":["hidden_layer_size = 4000\n","learning_rate = 1e-2\n","\n","w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n","w2 = random_weight((hidden_layer_size, 10))\n","\n","train_part2(two_layer_fc, [w1, w2], learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"8qHT93KFpR1_"},"source":["### BareBones PyTorch: Training a ConvNet\n","\n","아래에서는 위에서 정의한 함수를 사용하여 CIFAR에서 3계층 Convolutional network를 훈련해야 합니다. 네트워크의 아키텍처는 다음과 같아야 합니다:\n","\n","1. 32개의 5x5 필터가 있는 컨볼루션 레이어(바이어스 포함), 제로 패딩은 2입니다.\n","2. ReLU\n","3. 16개의 3x3 필터가 있는 컨볼루션 레이어(바이어스 포함), 제로 패딩 1\n","4. ReLU\n","5. 10개의 클래스에 대한 점수를 계산하기 위한 완전 연결 레이어(바이어스 포함)\n","\n","위에서 정의한 `random_weight` 함수를 사용하여 가중치 행렬을 초기화해야 하며, 위의 `zero_weight` 함수를 사용하여 바이어스 벡터를 초기화해야 합니다.\n","\n","하이퍼파라미터를 조정할 필요는 없지만 모든 것이 올바르게 작동하면 한 에포크 후에 42% 이상의 정확도를 달성해야 합니다."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"barebones_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038865585,"user_tz":-540,"elapsed":23859,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"82d675f1-9de4-4d25-b257-97946816dc11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 4.0912\n","Checking accuracy on the val set\n","Got 103 / 1000 correct (10.30%)\n","\n","Iteration 100, loss = 1.7508\n","Checking accuracy on the val set\n","Got 334 / 1000 correct (33.40%)\n","\n","Iteration 200, loss = 1.6677\n","Checking accuracy on the val set\n","Got 376 / 1000 correct (37.60%)\n","\n","Iteration 300, loss = 1.9416\n","Checking accuracy on the val set\n","Got 416 / 1000 correct (41.60%)\n","\n","Iteration 400, loss = 1.6902\n","Checking accuracy on the val set\n","Got 413 / 1000 correct (41.30%)\n","\n","Iteration 500, loss = 1.5923\n","Checking accuracy on the val set\n","Got 445 / 1000 correct (44.50%)\n","\n","Iteration 600, loss = 1.6769\n","Checking accuracy on the val set\n","Got 438 / 1000 correct (43.80%)\n","\n","Iteration 700, loss = 1.5980\n","Checking accuracy on the val set\n","Got 457 / 1000 correct (45.70%)\n","\n"]}],"source":["learning_rate = 3e-3\n","\n","channel_1 = 32\n","channel_2 = 16\n","\n","conv_w1 = random_weight((channel_1,3,5,5))\n","conv_b1 = zero_weight((channel_1,))\n","conv_w2 = random_weight((channel_2,channel_1,3,3))\n","conv_b2 = zero_weight((channel_2,))\n","fc_w = random_weight((channel_2 * 32 * 32, 10))\n","fc_b = zero_weight((10,))\n","\n","################################################################################\n","# TODO: Initialize the parameters of a three-layer ConvNet.                    #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","'''\n","    Inputs:\n","    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images\n","    - params: A list of PyTorch Tensors giving the weights and biases for the\n","      network; should contain the following:\n","      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n","        for the first convolutional layer\n","      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n","        convolutional layer\n","      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n","        weights for the second convolutional layer\n","      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n","        convolutional layer\n","      - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","      - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","'''\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n","train_part2(three_layer_convnet, params, learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"KpzU23oApR2A"},"source":["# Part III. PyTorch Module API\n","\n","Barebone PyTorch에서는 모든 Parameter tensors를 수작업으로 추적해야 합니다. 이는 몇 개의 텐서가 있는 소규모 네트워크에서는 괜찮지만, 대규모 네트워크에서 수십 또는 수백 개의 텐서를 추적하는 것은 매우 불편하고 오류가 발생하기 쉽습니다.\n","\n","PyTorch는 임의의 네트워크 아키텍처를 정의하는 동시에 학습 가능한 모든 파라미터를 추적할 수 있도록 `nn.Module` API를 제공합니다. Part II에서는 SGD를 직접 구현해 보았습니다. PyTorch는 또한 RMSProp, Adagrad, Adam과 같은 모든 일반적인 Optimizer를 구현하는 `torch.optim` 패키지를 제공합니다. 심지어 L-BFGS와 같은 대략적인 2차 방법도 지원합니다! 각 옵티마이저의 정확한 사양은 [문서](http://pytorch.org/docs/master/optim.html)를 참고하세요.\n","\n","모듈 API를 사용하려면 아래 단계를 따르세요:\n","\n","1. 서브클래스 `nn.Module`. 네트워크 클래스에 `TwoLayerFC`와 같은 직관적인 이름을 지정합니다.\n","\n","2. 생성자 `__init__()`에서 필요한 모든 레이어를 클래스 속성으로 정의합니다. `nn.Linear` 및 `nn.Conv2d`와 같은 레이어 객체는 그 자체로 `nn.Module` 서브클래스이며 학습 가능한 파라미터를 포함하므로 원시 텐서를 직접 인스턴스화할 필요가 없습니다. `nn.Module`이 이러한 내부 파라미터를 추적합니다. 수십 개의 내장 레이어에 대해 자세히 알아보려면 [문서](http://pytorch.org/docs/master/nn.html)를 참조하세요. **경고**: `super().__init__()`를 먼저 호출하는 것을 잊지 마세요!\n","\n","3. `forward()` 메서드에서 네트워크의 *연결성*을 정의합니다. 텐서를 입력으로 받고 \"변환된\" 텐서를 출력하는 함수 호출로 `__init__`에 정의된 속성을 사용해야 합니다. `forward()`에서 학습 가능한 매개변수가 있는 새 레이어를 생성하지 마세요! 모든 매개변수는 `__init__`에서 미리 선언해야 합니다.\n","\n","모듈 서브클래스를 정의한 후에는 객체로 인스턴스화하여 Part II의 NN 전달 함수처럼 호출할 수 있습니다.\n","\n","### Module API: Two-Layer Network\n","다음은 fully connected 2계층 네트워크의 구체적인 예입니다:"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"WSrvts7LpR2A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038865586,"user_tz":-540,"elapsed":10,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"679981b1-946b-493b-da30-aae767da7fd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["class TwoLayerFC(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super().__init__()\n","        # assign layer objects to class attributes\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        # nn.init package contains convenient initialization methods\n","        # http://pytorch.org/docs/master/nn.html#torch-nn-init\n","        nn.init.kaiming_normal_(self.fc1.weight)\n","        self.fc2 = nn.Linear(hidden_size, num_classes)\n","        nn.init.kaiming_normal_(self.fc2.weight)\n","\n","    def forward(self, x):\n","        # forward always defines connectivity\n","        x = flatten(x)\n","        scores = self.fc2(F.relu(self.fc1(x)))\n","        return scores\n","\n","def test_TwoLayerFC():\n","    input_size = 50\n","    x = torch.zeros((64, input_size), dtype=dtype)  # minibatch size 64, feature dimension 50\n","    model = TwoLayerFC(input_size, 42, 10)\n","    scores = model(x)\n","    print(scores.size())  # you should see [64, 10]\n","test_TwoLayerFC()"]},{"cell_type":"markdown","metadata":{"id":"oTbHlNclpR2A"},"source":["### Module API: Three-Layer ConvNet\n","이제 완전히 연결된 레이어에 이어 3계층 ConvNet을 구현할 차례입니다. 네트워크 아키텍처는 파트 II와 동일해야 합니다:\n","\n","1. zero-padding이 2인 `channel_1` 5x5 필터가 있는 컨볼루션 레이어\n","2. ReLU\n","3. `channel_2` 3x3 필터가 있는 Convolution Layer, zero-padding 1\n","4. ReLU\n","5. `num_classes` 클래스에 완전히 연결된 레이어\n","\n","Kaiming normal initialize 방법을 사용하여 모델의 가중치 행렬을 초기화해야 합니다.\n","\n","**HINT**: http://pytorch.org/docs/stable/nn.html#conv2d\n","\n","3계층 ConvNet을 구현한 후 `test_ThreeLayerConvNet` 함수가 구현을 실행하면 출력 점수의 모양에 대해 `(64, 10)`이 출력되어야 합니다."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"module_output_shape","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038865586,"user_tz":-540,"elapsed":8,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"dea5d698-96d4-43ba-f6c8-7c16e0690d91"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["class ThreeLayerConvNet(nn.Module):\n","    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n","        super().__init__()\n","        ########################################################################\n","        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n","        # architecture defined above.                                          #\n","        ########################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        self.conv1 = nn.Conv2d(in_channel, channel_1, kernel_size = 5, stride=1, padding=2, bias=True, padding_mode='zeros')\n","        nn.init.kaiming_normal_(self.conv1.weight)\n","        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_size = 3, stride=1, padding=1, bias=True, padding_mode='zeros')\n","        nn.init.kaiming_normal_(self.conv2.weight)\n","        self.fc = nn.Linear(channel_2 * 32 * 32,num_classes) ##Linear의 input channel은 항상 계산해서 넣어줘야하는지\n","        nn.init.kaiming_normal_(self.fc.weight)\n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ########################################################################\n","        #                          END OF YOUR CODE                            #\n","        ########################################################################\n","\n","    def forward(self, x):\n","        scores = None\n","        ########################################################################\n","        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n","        # should use the layers you defined in __init__ and specify the        #\n","        # connectivity of those layers in forward()                            #\n","        ########################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        A_1 = self.conv1(x)\n","        Z_1 = F.relu(A_1)\n","        A_2 = self.conv2(Z_1)\n","        Z_2 = F.relu(A_2)\n","        flatten_Z_2 = flatten(Z_2)\n","\n","        scores = self.fc(flatten_Z_2)\n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################\n","        return scores\n","\n","\n","def test_ThreeLayerConvNet():\n","    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n","    model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10)\n","    scores = model(x)\n","    print(scores.size())  # you should see [64, 10]\n","test_ThreeLayerConvNet()"]},{"cell_type":"markdown","metadata":{"id":"b3CDip-7pR2B"},"source":["### Module API: Check Accuracy\n","검증 또는 테스트 세트가 주어지면 신경망의 분류 정확도를 확인할 수 있습니다.\n","\n","이 버전은 Part II의 버전과 약간 다릅니다. 더 이상 매개 변수를 수동으로 전달하지 않습니다."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"7PYAZQ1DpR2B","executionInfo":{"status":"ok","timestamp":1690038865586,"user_tz":-540,"elapsed":5,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"outputs":[],"source":["def check_accuracy_part34(loader, model):\n","    if loader.dataset.train:\n","        print('Checking accuracy on validation set')\n","    else:\n","        print('Checking accuracy on test set')\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()  # set model to evaluation mode\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","            scores = model(x)\n","            _, preds = scores.max(1)\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"]},{"cell_type":"markdown","metadata":{"id":"Pb6341vOpR2B"},"source":["### Module API: Training Loop\n","또한 약간 다른 training loop를 사용합니다. 가중치 값을 직접 업데이트하는 대신, Optimization 알고리즘의 개념을 추상화하고 신경망 최적화에 일반적으로 사용되는 대부분의 알고리즘 구현을 제공하는 `torch.optim` 패키지의 Optimizer 객체를 사용합니다."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"lY-B6AXbpR2B","executionInfo":{"status":"ok","timestamp":1690038865587,"user_tz":-540,"elapsed":6,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"outputs":[],"source":["def train_part34(model, optimizer, epochs=1):\n","    \"\"\"\n","    Train a model on CIFAR-10 using the PyTorch Module API.\n","\n","    Inputs:\n","    - model: A PyTorch Module giving the model to train.\n","    - optimizer: An Optimizer object we will use to train the model\n","    - epochs: (Optional) A Python integer giving the number of epochs to train for\n","\n","    Returns: Nothing, but prints model accuracies during training.\n","    \"\"\"\n","    model = model.to(device=device)  # move the model parameters to CPU/GPU\n","    for e in range(epochs):\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores = model(x)\n","            loss = F.cross_entropy(scores, y)\n","\n","            # Zero out all of the gradients for the variables which the optimizer\n","            # will update.\n","            optimizer.zero_grad()\n","\n","            # This is the backwards pass: compute the gradient of the loss with\n","            # respect to each  parameter of the model.\n","            loss.backward()\n","\n","            # Actually update the parameters of the model using the gradients\n","            # computed by the backwards pass.\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy_part34(loader_val, model)\n","                print()"]},{"cell_type":"markdown","metadata":{"id":"CMFEsm-OpR2C"},"source":["### Module API: Train a Two-Layer Network\n","이제 training loop를 실행할 준비가 되었습니다. Part II와 달리 이번에는 Parameter tensors를 더 이상 명시적으로 할당하지 않습니다.\n","\n","입력 크기, 숨겨진 레이어 크기, 클래스 수(즉, 출력 크기)를 `TwoLayerFC`의 생성자에 전달하기만 하면 됩니다.\n","\n","또한 `TwoLayerFC` 내에서 학습 가능한 모든 파라미터를 추적하는 옵티마이저를 정의해야 합니다.\n","\n","하이퍼파라미터를 조정할 필요는 없지만, 한 epoch 동안 학습한 후 40% 이상의 모델 정확도를 볼 수 있어야 합니다."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"TCwaZfJTpR2C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038883905,"user_tz":-540,"elapsed":18324,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"b1ed1f9c-5ea9-40db-b013-6dbfb50023a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 3.5638\n","Checking accuracy on validation set\n","Got 148 / 1000 correct (14.80)\n","\n","Iteration 100, loss = 2.1056\n","Checking accuracy on validation set\n","Got 337 / 1000 correct (33.70)\n","\n","Iteration 200, loss = 2.0244\n","Checking accuracy on validation set\n","Got 409 / 1000 correct (40.90)\n","\n","Iteration 300, loss = 1.9611\n","Checking accuracy on validation set\n","Got 418 / 1000 correct (41.80)\n","\n","Iteration 400, loss = 1.9021\n","Checking accuracy on validation set\n","Got 390 / 1000 correct (39.00)\n","\n","Iteration 500, loss = 1.6553\n","Checking accuracy on validation set\n","Got 437 / 1000 correct (43.70)\n","\n","Iteration 600, loss = 1.8947\n","Checking accuracy on validation set\n","Got 405 / 1000 correct (40.50)\n","\n","Iteration 700, loss = 1.6947\n","Checking accuracy on validation set\n","Got 433 / 1000 correct (43.30)\n","\n"]}],"source":["hidden_layer_size = 4000\n","learning_rate = 1e-2\n","model = TwoLayerFC(3 * 32 * 32, hidden_layer_size, 10)\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"OvnHTm_MpR2C"},"source":["### Module API: Train a Three-Layer ConvNet\n","이제 Module API를 사용하여 CIFAR에서 3계층 ConvNet을 훈련해야 합니다. 이는 2계층 네트워크 훈련과 매우 유사하게 보일 것입니다! 하이퍼파라미터를 조정할 필요는 없지만, 한 회기 동안 훈련한 후 45% 이상을 달성해야 합니다.\n","\n","Momentum이 없는 Stochastic gradient descent를 사용하여 모델을 훈련해야 합니다."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"module_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038918959,"user_tz":-540,"elapsed":35058,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"5060c340-9943-4103-efa5-b5ac3b959847"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.8246\n","Checking accuracy on validation set\n","Got 99 / 1000 correct (9.90)\n","\n","Iteration 100, loss = 1.8629\n","Checking accuracy on validation set\n","Got 347 / 1000 correct (34.70)\n","\n","Iteration 200, loss = 1.8717\n","Checking accuracy on validation set\n","Got 421 / 1000 correct (42.10)\n","\n","Iteration 300, loss = 1.5427\n","Checking accuracy on validation set\n","Got 446 / 1000 correct (44.60)\n","\n","Iteration 400, loss = 1.6517\n","Checking accuracy on validation set\n","Got 461 / 1000 correct (46.10)\n","\n","Iteration 500, loss = 1.3903\n","Checking accuracy on validation set\n","Got 480 / 1000 correct (48.00)\n","\n","Iteration 600, loss = 1.7687\n","Checking accuracy on validation set\n","Got 475 / 1000 correct (47.50)\n","\n","Iteration 700, loss = 1.3211\n","Checking accuracy on validation set\n","Got 493 / 1000 correct (49.30)\n","\n","Iteration 0, loss = 1.3906\n","Checking accuracy on validation set\n","Got 488 / 1000 correct (48.80)\n","\n","Iteration 100, loss = 1.4405\n","Checking accuracy on validation set\n","Got 502 / 1000 correct (50.20)\n","\n","Iteration 200, loss = 1.3856\n","Checking accuracy on validation set\n","Got 490 / 1000 correct (49.00)\n","\n","Iteration 300, loss = 1.2646\n","Checking accuracy on validation set\n","Got 498 / 1000 correct (49.80)\n","\n","Iteration 400, loss = 1.4873\n","Checking accuracy on validation set\n","Got 497 / 1000 correct (49.70)\n","\n","Iteration 500, loss = 1.2333\n","Checking accuracy on validation set\n","Got 505 / 1000 correct (50.50)\n","\n","Iteration 600, loss = 1.3669\n","Checking accuracy on validation set\n","Got 518 / 1000 correct (51.80)\n","\n","Iteration 700, loss = 1.5149\n","Checking accuracy on validation set\n","Got 512 / 1000 correct (51.20)\n","\n"]}],"source":["learning_rate = 3e-3\n","channel_1 = 32\n","channel_2 = 16\n","\n","model = None\n","optimizer = None\n","################################################################################\n","# TODO: Instantiate your ThreeLayerConvNet model and a corresponding optimizer #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","model = ThreeLayerConvNet(in_channel = 3, channel_1 = 32, channel_2 = 16, num_classes = 10)\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","train_part34(model, optimizer)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"lsFqIP43pR2D"},"source":["# Part IV. PyTorch Sequential API\n","\n","Part III에서는 임의의 학습 가능한 레이어와 그 연결성을 정의할 수 있는 PyTorch 모듈 API를 소개했습니다.\n","\n","Feed forward layers과 같은 간단한 모델의 경우, `nn.Module` 서브클래스를 생성하고, `__init__`에서 클래스 속성에 레이어를 할당하고, `forward()`에서 각 레이어를 하나씩 호출하는 3단계를 거쳐야 합니다. 더 편리한 방법이 있을까요?\n","\n","다행히도 PyTorch에서는 위의 단계를 하나로 합친 `nn.Sequential`이라는 컨테이너 모듈을 제공합니다. feed forward stacks보다 더 복잡한 topology를 지정할 수 없기 때문에 `nn.Module`만큼 유연하지는 않지만, 많은 사용 사례에 충분합니다.\n","\n","### Sequential API: 2계층 네트워크\n","`nn.Sequential`을 사용하여 2계층 fully connected 네트워크 예제를 다시 작성하고 위에서 정의한 training loop를 사용하여 트레이닝하는 방법을 살펴봅시다.\n","\n","여기서도 하이퍼파라미터를 조정할 필요는 없지만, 한 번의 훈련 후에는 40% 이상의 정확도를 달성해야 합니다."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"hTN-_2OmpR2D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690038941198,"user_tz":-540,"elapsed":22254,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"1f1536b4-3413-4ca0-d3b2-45bb62880588"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.3326\n","Checking accuracy on validation set\n","Got 124 / 1000 correct (12.40)\n","\n","Iteration 100, loss = 1.8909\n","Checking accuracy on validation set\n","Got 390 / 1000 correct (39.00)\n","\n","Iteration 200, loss = 1.7270\n","Checking accuracy on validation set\n","Got 394 / 1000 correct (39.40)\n","\n","Iteration 300, loss = 1.6427\n","Checking accuracy on validation set\n","Got 433 / 1000 correct (43.30)\n","\n","Iteration 400, loss = 2.0764\n","Checking accuracy on validation set\n","Got 427 / 1000 correct (42.70)\n","\n","Iteration 500, loss = 1.9092\n","Checking accuracy on validation set\n","Got 426 / 1000 correct (42.60)\n","\n","Iteration 600, loss = 1.7882\n","Checking accuracy on validation set\n","Got 433 / 1000 correct (43.30)\n","\n","Iteration 700, loss = 1.4243\n","Checking accuracy on validation set\n","Got 430 / 1000 correct (43.00)\n","\n"]}],"source":["# We need to wrap `flatten` function in a module in order to stack it\n","# in nn.Sequential\n","class Flatten(nn.Module):\n","    def forward(self, x):\n","        return flatten(x)\n","\n","hidden_layer_size = 4000\n","learning_rate = 1e-2\n","\n","model = nn.Sequential(\n","    Flatten(),\n","    nn.Linear(3 * 32 * 32, hidden_layer_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_layer_size, 10),\n",")\n","\n","# you can use Nesterov momentum in optim.SGD\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n","                     momentum=0.9, nesterov=True)\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"Ppx-dXtZpR2D"},"source":["### Sequential API: Three-Layer ConvNet\n","여기서는 `nn.Sequential`을 사용하여 Part III에서 사용한 것과 동일한 아키텍처로 3계층 ConvNet을 정의하고 훈련해야 합니다:\n","\n","1. 32개의 5x5 필터가 있는 Convolution 레이어(바이어스 포함), zero-padding은 2입니다.\n","2. ReLU\n","3. 16개의 3x3 필터가 있는 Convolution 레이어(바이어스 포함), zero-padding 1\n","4. ReLU\n","5. 10개의 클래스에 대한 점수를 계산하기 위한  fully-connected layer(바이어스 포함)\n","\n","기본 PyTorch 가중치 초기화를 사용할 수 있습니다.\n","\n","Nesterov momentum 0.9의 확률적 경사 하강을 사용하여 모델을 최적화해야 합니다.\n","\n","다시 말하지만, 하이퍼파라미터를 조정할 필요는 없지만 한 번의 훈련 후에는 55% 이상의 정확도를 볼 수 있어야 합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CP6-UsQtzMeI","executionInfo":{"status":"aborted","timestamp":1689914896539,"user_tz":-540,"elapsed":6,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"outputs":[],"source":["channel_1 = 32\n","channel_2 = 16\n","learning_rate = 1e-2\n","\n","model = None\n","optimizer = None\n","\n","################################################################################\n","# TODO: Rewrite the 2-layer ConvNet with bias from Part III with the           #\n","# Sequential API.                                                              #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","model = nn.Sequential(\n","    nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 5, stride=1, padding=2, bias=True, padding_mode='zeros'),\n","    nn.ReLU(),\n","    nn.Conv2d(in_channels = 32, out_channels = 16, kernel_size = 3, stride=1, padding=1, bias=True, padding_mode='zeros'),\n","    nn.ReLU(),\n","    Flatten(),\n","    nn.Linear(16 * 32 * 32, 10)\n",")\n","\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n","                     momentum=0.9, nesterov=True)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"8AhsbVrNoPt7"},"source":["# Let's do this! - Reimplement AlexNet\n","이제 PyTorch의 기본적인 사용법을 모두 배워 봤습니다. 지금까지 배웠던 내용을 바탕으로 Deep Into Deep 수업 중에 다루었던 모델 중 하나인 [AlexNet](https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)을 재구현해 보도록 하겠습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"DdF9qsXnLi_W"},"source":["## AlexNet Architecture\n","AlexNet의 전체적인 구조는 다음과 같습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gl7KqYljPjbO","executionInfo":{"status":"aborted","timestamp":1689914896540,"user_tz":-540,"elapsed":7,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","\n","images = './notebook_images/AlexNet_Architecture.png'\n","image = cv2.imread(images)\n","cv2_imshow(image)"]},{"cell_type":"markdown","metadata":{"id":"kESoCsqDQuLX"},"source":["## 구현 세부사항\n","이 그림을 바탕으로 AlexNet을 재구현 해 봅시다. 그러기 위해서 몇 가지 알고 넘어가야할 부분이 있습니다.\n","\n","AlexNet의 Input Data는 원래 3x224x224입니다. 하지만 우리는 지금 3x32x32인 CIFAR-10 Dataset에 대해서 실험을 하고 있습니다. 그렇기 때문에 Input Data의 dimension을 맞춰주는 작업이 필요합니다.\n","\n","PyTorch에는 이를 위한 Upsample 클래스가 존재합니다.\n","\n","```\n","nn.Upsample(size=(224,224))\n","```\n","\n","> **주의** : 이는 실험의 편의성을 위해 사용한 방식입니다. 실제로 논문을 재구현 할 때에는 실험이 진행된 Data와 동일한 dimension의 Data를 사용하여야 합니다.\n","\n","+ 추가로, Deep Learning 분야에서 많이 화제가 되었던 이야기 중 하나가 Input dimension이 맞지 않는다는 것이었습니다. 논문에서 첫번째 Convolution Layer에서 filter size가 11이고, stride가 4라는 것만 언급 되어 있습니다. 그 때 output volume을 계산해 보면 정수가 아닙니다. 많은 주장이 있었지만 저자가 Padding 3를 빼먹었다고 생각해, 본 구현에서도 Padding 3을 줬습니다.\n","\n","또한, AlexNet은 GPU 두 개에서 모델을 돌리기 위해 구성되었습니다. 2012년 AlexNet이 구현될 때와 달리 지금은 GPU 성능이 많이 발전하여, 하나의 GPU에서도 충분히 이를 실행시킬 수 있습니다. 하나의 GPU에서 실행되도록 모델을 수정해서 실험해 봅시다.\n","\n","그림에서 볼 수 있듯이 윗쪽과 아래쪽 CNN Layer가 있습니다. 이 Layer들을 하나로 합한다면, feature 수가 늘어난다고 생각하면 됩니다. 예를 들어, 첫 번째 CNN Layer는 48개의 filter가 두 개 있는데, 이를 96개의 filter가 있다고 생각하면 됩니다.\n","\n","Fully-Connected Layer 또한 2048 + 2048 = 4096개의 feature를 가진다고 생각하면 됩니다.\n","\n","**재구현은 Module API를 사용해도 좋고, Sequential API를 사용해도 좋습니다. 권투를 빕니다!**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2l01XXCQQP2G"},"source":["## AlexNet Architecture Summary\n","다음은 논문에 나온 AlexNet의 구조를 요약한 것입니다. 구현에 참고해 주세요.\n","### features\n","|Layer|# of filters|Filter Size|Stride|Padding|Size of feature map|Activation|\n","|:-----|:-----------|:----|:-----------|:------|:----------|:--|\n","|Input Image|-|-|-|-|3x32x32|-|\n","|Upsample|-|-|-|-|3x224x224|-|\n","|Convolution 1|96|11x11|4|3|55x55x96|ReLU|\n","|Max Pooling 1|-|3x3|2|-|27x27x96|-|\n","|Convolution 2|256|5x5|2|-|27x27x256|ReLU|\n","|Max Pooling 2|-|3x3|2|-|13x13x256|-|\n","|Convolution 3|384|3x3|1|1|13x13x384|ReLU|\n","|Convolution 4|384|3x3|1|1|13x13x384|ReLU|\n","|Convolution 5|256|3x3|1|1|13x13x256|ReLU|\n","|Max Pooling 3|-|3x3|2|-|6x6x256|-|\n","\n","### classifier\n","|Layer|in_feature|out_feature|dropout rate|Activation|\n","|:----|:---------|:----------|:-----------|:---------|\n","|Flatten|-|-|-|-|\n","|Dropout 1|-|-|0.5|-|\n","|Fully-Connected 1|9216|4096|-|ReLU|\n","|Dropout 2|-|-|0.5|-|\n","|Fully-Connected 2|4096|4096|-|ReLU|\n","|Fully-Connected 3|4096|10|-|-|\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sequential_accuracy","executionInfo":{"status":"aborted","timestamp":1689914896540,"user_tz":-540,"elapsed":6,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"outputs":[],"source":["learning_rate = 1e-4\n","\n","model = None\n","optimizer = None\n","\n","################################################################################\n","# TODO: Reimplement AlexNet                                                    #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","class AlexNet(nn.Module):\n","  def __init__(self, num_classes):\n","    super(AlexNet,self).__init__()\n","    self.upsample = nn.Upsample(size = (227,227))\n","    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 96, kernel_size = 11, stride= 4, padding = 0, bias=True, padding_mode='zeros')\n","    self.maxpool1 = nn.MaxPool2d(kernel_size = 3, stride= 2, padding=0)\n","    self.conv2 = nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size = 5, stride= 1, padding = 2, bias=True, padding_mode='zeros')\n","    self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride= 2, padding=0)\n","    self.conv3 = nn.Conv2d(in_channels = 256, out_channels = 384, kernel_size = 3, stride= 1, padding = 1, bias=True, padding_mode='zeros')\n","    self.conv4 = nn.Conv2d(in_channels = 384, out_channels = 384, kernel_size = 3, stride= 1, padding = 1, bias=True, padding_mode='zeros')\n","    self.conv5 = nn.Conv2d(in_channels = 384, out_channels = 256, kernel_size = 3, stride= 1, padding = 1, bias=True, padding_mode='zeros')\n","    self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride= 2, padding=0)\n","\n","    self.dropout1 = nn.Dropout(p=0.5, inplace=False)\n","    self.fc1 = nn.Linear(9216, 4096)\n","    self.dropout2 = nn.Dropout(p=0.5, inplace=False)\n","    self.fc2 = nn.Linear(4096,4096)\n","    self.fc3 = nn.Linear(4096, num_classes)\n","\n","  def forward(self,x):\n","    scores = None\n","\n","    upsampled_x = self.upsample(x)\n","    A_1 = self.conv1(upsampled_x)\n","    Z_1 = F.relu(A_1)\n","    maxpool_Z_1 = self.maxpool1(Z_1)\n","\n","    A_2 = self.conv2(maxpool_Z_1)\n","    Z_2 = F.relu(A_2)\n","    maxpool_Z_2 = self.maxpool2(Z_2)\n","\n","    A_3 = self.conv3(maxpool_Z_2)\n","    Z_3 = F.relu(A_3)\n","    A_4 = self.conv4(Z_3)\n","    Z_4 = F.relu(A_4)\n","    A_5 = self.conv5(Z_4)\n","    Z_5 = F.relu(A_5)\n","    maxpool_Z_5 = self.maxpool3(Z_5)\n","\n","    flatten_feature = flatten(maxpool_Z_5)\n","    dropout1_flatten_feature = self.dropout1(flatten_feature)\n","    A_6 = self.fc1(dropout1_flatten_feature)\n","    Z_6 = F.relu(A_6)\n","    dropout2_Z_6 = self.dropout2(Z_6)\n","    A_7 = self.fc2(dropout2_Z_6)\n","    Z_7 = F.relu(A_7)\n","    A_8 = self.fc3(Z_7)\n","\n","    scores = A_8\n","\n","    return scores\n","\n","model = AlexNet(num_classes = 10)\n","optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n","#optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n","#                    momentum=0.9, nesterov=True)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","train_part34(model, optimizer, epochs=10)"]},{"cell_type":"markdown","metadata":{"id":"yTQNIdymfthW"},"source":["## Describe what you did\n","\n","재구현에 성공했나요? 실패했다면 어떤 점이 어려웠나요? 다른 모델과 비교했을 때 더 좋은 성능이 나왔나요? 혹은 ILSVRC'12와 비슷한 성능인가요? 만약 기대하던 성능이 안 나왔다면 어떤 문제가 있었을까요? 자유롭게 생각을 적어주세요."]},{"cell_type":"markdown","metadata":{"id":"V4ueerblf7FI"},"source":["**Answer:**\n","\n","성능이 전혀 나오질 않았는데 이는 32 X 32 X 3 data를 강제로 upsampling 했기 때문이라고 생각한다.\n","\n","추가적으로 AlexNet의 구조에는 LRN 구조도 들어가 있는데 본 구조에는 LRN을 넣기 않은 것도 이유일 수 있지 않을까..\n","\n","- 아니다. 마지막 Layer에 RELU를 넣어서 성능이 아예 안나온 것이었다. 똑바로 보자!!!!"]},{"cell_type":"markdown","metadata":{"id":"Iq-i0xoUpR2E"},"source":["# Part V. CIFAR-10 open-ended challenge\n","\n","이 section에서는 CIFAR-10에서 원하는 ConvNet 아키텍처를 실험해 볼 수 있습니다.\n","\n","이제 여러분이 할 일은 아키텍처, 하이퍼파라미터, loss 함수, Optimizer를 실험하여 10개 epoch 이내에 CIFAR-10 **Validation** 세트에서 **70% 이상** 정확도를 달성하는 모델을 훈련하는 것입니다. 위에서 확인_정확도 및 훈련 함수를 사용할 수 있습니다. `nn.Module` 또는 `nn.Sequential` API를 사용할 수 있습니다.\n","\n","이 노트북의 마지막에 여러분이 수행한 작업을 설명하세요.\n","\n","다음은 각 구성 요소에 대한 공식 API 문서입니다. 한 가지 참고 사항: \"spatial batch norm\" 클래스에서 호출하는 것을 PyTorch에서는 \"BatchNorm2D\"라고 부릅니다.\n","\n","* Layers in torch.nn package: http://pytorch.org/docs/stable/nn.html\n","* Activations: http://pytorch.org/docs/stable/nn.html#non-linear-activations\n","* Loss functions: http://pytorch.org/docs/stable/nn.html#loss-functions\n","* Optimizers: http://pytorch.org/docs/stable/optim.html\n","\n","\n","### 시도해 볼만한 일:\n","- **Filter size**: 위에서는 5x5를 사용했는데, 더 작은 필터가 더 효율적일까요?\n","- **Filters 수**: 위에서는 32개의 필터를 사용했습니다. 필터 수가 많거나 적을수록 더 효율적일까요?\n","- **Pooling vs Strided Convolution**: max pooling을 사용하나요, 아니면 Strided Convolution만 사용하나요?\n","- **Batch normalization**: Convolutional Layer 뒤에 spatial batch normalization을, affine 레이어 뒤에 vanilla batch normalization을 추가해 보세요. 네트워크가 더 빠르게 훈련되나요?\n","- **네트워크 아키텍처**: 위의 네트워크에는 두 개의 학습 가능한 파라미터 레이어가 있습니다. 심층 네트워크를 사용하면 더 잘할 수 있나요? 시도해 볼 만한 좋은 아키텍처는 다음과 같습니다:\n","    - [conv-relu-pool]xN -> [affine]xM -> [softmax 또는 SVM]\n","    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax 또는 SVM]\n","    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax 또는 SVM]\n","- **Global Average Pooling**: 평평하게 한 다음 여러 개의 Affine 레이어를 갖는 대신 이미지가 작아질 때까지 Convolution을 수행한 다음(7x7 정도) Average Pooling 연산을 수행하여 1x1 이미지 사진(1, 1 , Filter#)을 얻은 다음 (Filter#) 벡터로 재형성합니다. 이 방식은 [Google's Inception Network](https://arxiv.org/abs/1512.00567)에서 사용됩니다(아키텍처는 표 1 참조).\n","- **Regularization**: l2 가중치 regulariztion를 추가하거나 Dropout을 사용할 수 있습니다.\n","\n","### Tips for training\n","시도하는 각 네트워크 아키텍처에 대해 학습 속도와 기타 하이퍼파라미터를 조정해야 합니다. 이 작업을 수행할 때 명심해야 할 몇 가지 중요한 사항이 있습니다:\n","\n","- 매개변수가 잘 작동하는 경우 수백 번의 반복을 통해 개선 효과를 볼 수 있어야 합니다.\n","- 하이퍼파라미터 튜닝을 위한 거칠고 세밀한 접근 방식을 기억하세요. 몇 번의 학습 반복만으로 광범위한 하이퍼파라미터를 테스트하여 제대로 작동하는 파라미터 조합을 찾는 것부터 시작하세요.\n","- 효과가 있는 것으로 보이는 몇 가지 파라미터 세트를 찾으면 해당 파라미터를 중심으로 더 세밀하게 검색하세요. 더 많은 epoch에 대해 훈련해야 할 수도 있습니다.\n","- 하이퍼파라미터 검색에는 유효성 검사 집합을 사용하고, 유효성 검사 집합에서 선택한 최상의 파라미터로 아키텍처를 평가하기 위해 테스트 집합을 저장해야 합니다.\n","\n","### Going above and beyond\n","모험심이 강하다면 성능을 향상시키기 위해 구현할 수 있는 다른 기능도 많이 있습니다. 이러한 기능을 반드시 구현해야 하는 것은 아니지만, 시간이 된다면 그 재미를 놓치지 마세요!\n","\n","- 대체 optimizers: Adam, Adagrad, RMSprop 등을 사용해 볼 수 있습니다.\n","- Leaky ReLU, parametric ReLU, ELU 또는 MaxOut과 같은 대체 Activation 함수.\n","- Model ensembles\n","- Data augmentation\n","- 새로운 아키텍처\n","  - [ResNets](https://arxiv.org/abs/1512.03385) 이전 레이어의 입력이 출력에 추가됩니다.\n","  - [DenseNets](https://arxiv.org/abs/1608.06993) 이전 레이어에 대한 입력이 서로 연결되는 곳입니다.\n","  - [이 블로그에서 자세한 개요를 확인할 수 있습니다.](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n","\n","### Have fun and happy training!"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"uWsuRLTjfoRa","executionInfo":{"status":"ok","timestamp":1689916613642,"user_tz":-540,"elapsed":1524,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"outputs":[],"source":["def train_part5(model, optimizer, epochs=1):\n","    \"\"\"\n","    Train a model on CIFAR-10 using the PyTorch Module API.\n","\n","    Inputs:\n","    - model: A PyTorch Module giving the model to train.\n","    - optimizer: An Optimizer object we will use to train the model\n","    - epochs: (Optional) A Python integer giving the number of epochs to train for\n","\n","    Returns: Nothing, but prints model accuracies during training.\n","    \"\"\"\n","    avg_losses = []\n","    model = model.to(device=device)  # move the model parameters to CPU/GPU\n","    for e in range(epochs):\n","        avg_loss = 0.0\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores = model(x)\n","            loss = F.cross_entropy(scores, y)\n","\n","            # Zero out all of the gradients for the variables which the optimizer\n","            # will update.\n","            optimizer.zero_grad()\n","\n","            # This is the backwards pass: compute the gradient of the loss with\n","            # respect to each  parameter of the model.\n","            loss.backward()\n","\n","            # Actually update the parameters of the model using the gradients\n","            # computed by the backwards pass.\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy_part34(loader_val, model)\n","                print()\n","\n","            avg_loss += loss.item()\n","        avg_losses.append(avg_loss / len(loader_train))\n","    return avg_losses"]},{"cell_type":"markdown","source":["auxiliary loss 사용 x"],"metadata":{"id":"UEk22c6r3fpt"}},{"cell_type":"code","execution_count":49,"metadata":{"id":"open_ended_accuracy","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1689918654622,"user_tz":-540,"elapsed":1994753,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"0273b123-962b-4163-e1ca-257c569cbec3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.3620\n","Checking accuracy on validation set\n","Got 105 / 1000 correct (10.50)\n","\n","Iteration 100, loss = 1.8140\n","Checking accuracy on validation set\n","Got 284 / 1000 correct (28.40)\n","\n","Iteration 200, loss = 2.1421\n","Checking accuracy on validation set\n","Got 336 / 1000 correct (33.60)\n","\n","Iteration 300, loss = 1.7402\n","Checking accuracy on validation set\n","Got 368 / 1000 correct (36.80)\n","\n","Iteration 400, loss = 1.8479\n","Checking accuracy on validation set\n","Got 430 / 1000 correct (43.00)\n","\n","Iteration 500, loss = 1.3086\n","Checking accuracy on validation set\n","Got 457 / 1000 correct (45.70)\n","\n","Iteration 600, loss = 1.4314\n","Checking accuracy on validation set\n","Got 520 / 1000 correct (52.00)\n","\n","Iteration 700, loss = 1.4886\n","Checking accuracy on validation set\n","Got 468 / 1000 correct (46.80)\n","\n","Iteration 0, loss = 1.2705\n","Checking accuracy on validation set\n","Got 540 / 1000 correct (54.00)\n","\n","Iteration 100, loss = 1.0071\n","Checking accuracy on validation set\n","Got 494 / 1000 correct (49.40)\n","\n","Iteration 200, loss = 1.3555\n","Checking accuracy on validation set\n","Got 583 / 1000 correct (58.30)\n","\n","Iteration 300, loss = 1.1130\n","Checking accuracy on validation set\n","Got 597 / 1000 correct (59.70)\n","\n","Iteration 400, loss = 1.2252\n","Checking accuracy on validation set\n","Got 587 / 1000 correct (58.70)\n","\n","Iteration 500, loss = 1.0151\n","Checking accuracy on validation set\n","Got 564 / 1000 correct (56.40)\n","\n","Iteration 600, loss = 1.0697\n","Checking accuracy on validation set\n","Got 623 / 1000 correct (62.30)\n","\n","Iteration 700, loss = 1.0004\n","Checking accuracy on validation set\n","Got 609 / 1000 correct (60.90)\n","\n","Iteration 0, loss = 0.8641\n","Checking accuracy on validation set\n","Got 669 / 1000 correct (66.90)\n","\n","Iteration 100, loss = 0.8398\n","Checking accuracy on validation set\n","Got 611 / 1000 correct (61.10)\n","\n","Iteration 200, loss = 0.9429\n","Checking accuracy on validation set\n","Got 613 / 1000 correct (61.30)\n","\n","Iteration 300, loss = 0.7814\n","Checking accuracy on validation set\n","Got 678 / 1000 correct (67.80)\n","\n","Iteration 400, loss = 0.7884\n","Checking accuracy on validation set\n","Got 655 / 1000 correct (65.50)\n","\n","Iteration 500, loss = 1.0652\n","Checking accuracy on validation set\n","Got 688 / 1000 correct (68.80)\n","\n","Iteration 600, loss = 0.8295\n","Checking accuracy on validation set\n","Got 714 / 1000 correct (71.40)\n","\n","Iteration 700, loss = 0.5542\n","Checking accuracy on validation set\n","Got 685 / 1000 correct (68.50)\n","\n","Iteration 0, loss = 1.0469\n","Checking accuracy on validation set\n","Got 670 / 1000 correct (67.00)\n","\n","Iteration 100, loss = 0.6959\n","Checking accuracy on validation set\n","Got 690 / 1000 correct (69.00)\n","\n","Iteration 200, loss = 0.6102\n","Checking accuracy on validation set\n","Got 693 / 1000 correct (69.30)\n","\n","Iteration 300, loss = 0.6960\n","Checking accuracy on validation set\n","Got 738 / 1000 correct (73.80)\n","\n","Iteration 400, loss = 0.8257\n","Checking accuracy on validation set\n","Got 737 / 1000 correct (73.70)\n","\n","Iteration 500, loss = 0.7858\n","Checking accuracy on validation set\n","Got 738 / 1000 correct (73.80)\n","\n","Iteration 600, loss = 0.5755\n","Checking accuracy on validation set\n","Got 744 / 1000 correct (74.40)\n","\n","Iteration 700, loss = 0.6899\n","Checking accuracy on validation set\n","Got 719 / 1000 correct (71.90)\n","\n","Iteration 0, loss = 0.5731\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 100, loss = 0.5756\n","Checking accuracy on validation set\n","Got 764 / 1000 correct (76.40)\n","\n","Iteration 200, loss = 0.7609\n","Checking accuracy on validation set\n","Got 704 / 1000 correct (70.40)\n","\n","Iteration 300, loss = 0.5654\n","Checking accuracy on validation set\n","Got 750 / 1000 correct (75.00)\n","\n","Iteration 400, loss = 0.6332\n","Checking accuracy on validation set\n","Got 759 / 1000 correct (75.90)\n","\n","Iteration 500, loss = 0.4052\n","Checking accuracy on validation set\n","Got 761 / 1000 correct (76.10)\n","\n","Iteration 600, loss = 0.9023\n","Checking accuracy on validation set\n","Got 757 / 1000 correct (75.70)\n","\n","Iteration 700, loss = 0.8680\n","Checking accuracy on validation set\n","Got 802 / 1000 correct (80.20)\n","\n","Iteration 0, loss = 0.6351\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 100, loss = 0.4850\n","Checking accuracy on validation set\n","Got 753 / 1000 correct (75.30)\n","\n","Iteration 200, loss = 0.3492\n","Checking accuracy on validation set\n","Got 779 / 1000 correct (77.90)\n","\n","Iteration 300, loss = 0.5605\n","Checking accuracy on validation set\n","Got 803 / 1000 correct (80.30)\n","\n","Iteration 400, loss = 0.5103\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Iteration 500, loss = 0.3832\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 600, loss = 0.4836\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 700, loss = 0.7519\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 0, loss = 0.4158\n","Checking accuracy on validation set\n","Got 809 / 1000 correct (80.90)\n","\n","Iteration 100, loss = 0.3713\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 200, loss = 0.5052\n","Checking accuracy on validation set\n","Got 822 / 1000 correct (82.20)\n","\n","Iteration 300, loss = 0.6827\n","Checking accuracy on validation set\n","Got 808 / 1000 correct (80.80)\n","\n","Iteration 400, loss = 0.4426\n","Checking accuracy on validation set\n","Got 817 / 1000 correct (81.70)\n","\n","Iteration 500, loss = 0.8007\n","Checking accuracy on validation set\n","Got 828 / 1000 correct (82.80)\n","\n","Iteration 600, loss = 0.4695\n","Checking accuracy on validation set\n","Got 804 / 1000 correct (80.40)\n","\n","Iteration 700, loss = 0.3731\n","Checking accuracy on validation set\n","Got 818 / 1000 correct (81.80)\n","\n","Iteration 0, loss = 0.4148\n","Checking accuracy on validation set\n","Got 823 / 1000 correct (82.30)\n","\n","Iteration 100, loss = 0.3909\n","Checking accuracy on validation set\n","Got 813 / 1000 correct (81.30)\n","\n","Iteration 200, loss = 0.4122\n","Checking accuracy on validation set\n","Got 826 / 1000 correct (82.60)\n","\n","Iteration 300, loss = 0.5040\n","Checking accuracy on validation set\n","Got 824 / 1000 correct (82.40)\n","\n","Iteration 400, loss = 0.5492\n","Checking accuracy on validation set\n","Got 826 / 1000 correct (82.60)\n","\n","Iteration 500, loss = 0.4504\n","Checking accuracy on validation set\n","Got 842 / 1000 correct (84.20)\n","\n","Iteration 600, loss = 0.2906\n","Checking accuracy on validation set\n","Got 821 / 1000 correct (82.10)\n","\n","Iteration 700, loss = 0.4841\n","Checking accuracy on validation set\n","Got 830 / 1000 correct (83.00)\n","\n","Iteration 0, loss = 0.2100\n","Checking accuracy on validation set\n","Got 829 / 1000 correct (82.90)\n","\n","Iteration 100, loss = 0.6203\n","Checking accuracy on validation set\n","Got 847 / 1000 correct (84.70)\n","\n","Iteration 200, loss = 0.2806\n","Checking accuracy on validation set\n","Got 782 / 1000 correct (78.20)\n","\n","Iteration 300, loss = 0.5731\n","Checking accuracy on validation set\n","Got 824 / 1000 correct (82.40)\n","\n","Iteration 400, loss = 0.4860\n","Checking accuracy on validation set\n","Got 806 / 1000 correct (80.60)\n","\n","Iteration 500, loss = 0.2865\n","Checking accuracy on validation set\n","Got 843 / 1000 correct (84.30)\n","\n","Iteration 600, loss = 0.4438\n","Checking accuracy on validation set\n","Got 820 / 1000 correct (82.00)\n","\n","Iteration 700, loss = 0.3516\n","Checking accuracy on validation set\n","Got 807 / 1000 correct (80.70)\n","\n","Iteration 0, loss = 0.3051\n","Checking accuracy on validation set\n","Got 844 / 1000 correct (84.40)\n","\n","Iteration 100, loss = 0.3601\n","Checking accuracy on validation set\n","Got 837 / 1000 correct (83.70)\n","\n","Iteration 200, loss = 0.3269\n","Checking accuracy on validation set\n","Got 820 / 1000 correct (82.00)\n","\n","Iteration 300, loss = 0.3205\n","Checking accuracy on validation set\n","Got 840 / 1000 correct (84.00)\n","\n","Iteration 400, loss = 0.3029\n","Checking accuracy on validation set\n","Got 828 / 1000 correct (82.80)\n","\n","Iteration 500, loss = 0.2629\n","Checking accuracy on validation set\n","Got 856 / 1000 correct (85.60)\n","\n","Iteration 600, loss = 0.3548\n","Checking accuracy on validation set\n","Got 840 / 1000 correct (84.00)\n","\n","Iteration 700, loss = 0.5695\n","Checking accuracy on validation set\n","Got 823 / 1000 correct (82.30)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["################################################################################\n","# TODO:                                                                        #\n","# Experiment with any architectures, optimizers, and hyperparameters.          #\n","# Achieve AT LEAST 70% accuracy on the *validation set* within 10 epochs.      #\n","#                                                                              #\n","# Note that you can use the check_accuracy function to evaluate on either      #\n","# the test set or the validation set, by passing either loader_test or         #\n","# loader_val as the second argument to check_accuracy. You should not touch    #\n","# the test set until you have finished your architecture and  hyperparameter   #\n","# tuning, and only run the test set once at the end to report a final value.   #\n","################################################################################\n","model = None\n","optimizer = None\n","experiment_name = \"googlenet_without_aux_adam_lr0.0001\"  # e.g., \"model1_sgd_lr0.1\", \"model2_adam_lr0.001\"\n","# Change the above experiment_name to store the avg_losses while perserving\n","# the previous avg_losses. Using the same value for experiment_name results in\n","# overwriting the previous one.\n","\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","class inceptionv1(nn.Module):\n","  def __init__(self,auxiliary = True, init_weight = True):\n","    super(inceptionv1,self).__init__()\n","\n","    assert auxiliary == True or auxiliary == False\n","    self.auxiliary = True\n","\n","    self.upsample = nn.Upsample(size = (224,224))\n","\n","    self.conv1 = ConvBlock(3, 64, kernel_size=7, stride=2, padding=3)\n","    self.maxpool1 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.conv2 = ConvBlock(64, 192, kernel_size=3, stride=1, padding=1)\n","    self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.inception3a = InceptionBlock(192,64,96,128,16,32,32)\n","    self.inception3b = InceptionBlock(256,128,128,192,32,96,64)\n","    self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.inception4a = InceptionBlock(480,192,96,208,16,48,64)\n","    self.inception4b = InceptionBlock(512,160,112,224,24,64,64)\n","    self.inception4c = InceptionBlock(512,128,128,256,24,64,64)\n","    self.inception4d = InceptionBlock(512,112,114,288,32,64,64)\n","    self.inception4e = InceptionBlock(528,256,160,320,32,128,128)\n","    self.maxpool4 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","    self.inception5a = InceptionBlock(832,256,160,320,32,128,128)\n","    self.inception5b = InceptionBlock(832,384,192,384,48,128,128)\n","    self.avgpool5 = nn.AvgPool2d(kernel_size = 7, stride=1)\n","    self.drop = nn.Dropout(p=0.4, inplace=False)\n","    self.fc = nn.Linear(1024,10)\n","\n","    if self.auxiliary:\n","      self.aux1 = Auxiliaray_classifier(512,10)\n","      self.aux2 = Auxiliaray_classifier(528,10)\n","    else:\n","      self.aux1 = None\n","      self.aux2 = None\n","\n","    if init_weight:\n","      self._initialize_weights()\n","\n","  def forward(self, x):\n","    x = self.upsample(x)\n","\n","    x = self.conv1(x)\n","    x = self.maxpool1(x)\n","    x = self.conv2(x)\n","    x = self.maxpool2(x)\n","    x = self.inception3a(x)\n","    x = self.inception3b(x)\n","    x = self.maxpool3(x)\n","\n","    x = self.inception4a(x)\n","\n","    if self.auxiliary and self.training:\n","      aux1 = self.aux1(x)\n","\n","    x = self.inception4b(x)\n","    x = self.inception4c(x)\n","    x = self.inception4d(x)\n","\n","    if self.auxiliary and self.training:\n","      aux2 = self.aux2(x)\n","\n","    x = self.inception4e(x)\n","    x = self.maxpool4(x)\n","    x = self.inception5a(x)\n","    x = self.inception5b(x)\n","    x = self.avgpool5(x)\n","\n","    x = x.view(x.shape[0], -1)\n","\n","    x = self.drop(x)\n","    x = self.fc(x)\n","\n","    if self.auxiliary and self.training:\n","      #return x, aux1, aux2\n","      return x\n","    else:\n","      return x\n","\n","  def _initialize_weights(self):\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","        if m.bias is not None:\n","          nn.init.constant_(m.bias, 0)\n","      elif isinstance(m, nn.BatchNorm2d):\n","        nn.init.constant_(m.weight,1)\n","        nn.init.constant_(m.bias,0)\n","      elif isinstance(m, nn.Linear):\n","        nn.init.normal_(m.weight,0,0.01)\n","        nn.init.constant_(m.bias,0)\n","\n","\n","class ConvBlock(nn.Module):\n","  def __init__(self,in_channels, out_channels, **kwarg):\n","    super(ConvBlock,self).__init__()\n","\n","    self.convlayer = nn.Sequential(\n","        nn.Conv2d(in_channels,out_channels, **kwarg),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","    )\n","\n","  def forward(self,x):\n","    return self.convlayer(x)\n","\n","\n","class InceptionBlock(nn.Module):\n","  def __init__(self,in_channels,out_channels_1x1,reduce_channels_3x3,out_channels_3x3,reduce_channels_5x5,out_channels_5x5,poolproj_channels):\n","    super(InceptionBlock,self).__init__()\n","\n","    self.branch1 = ConvBlock(in_channels,out_channels_1x1,kernel_size = 1)\n","    self.branch2 = nn.Sequential(\n","        ConvBlock(in_channels,reduce_channels_3x3,kernel_size = 1),\n","        ConvBlock(reduce_channels_3x3,out_channels_3x3,kernel_size = 3,padding = 1)\n","    )\n","    self.branch3 = nn.Sequential(\n","        ConvBlock(in_channels,reduce_channels_5x5,kernel_size = 1),\n","        ConvBlock(reduce_channels_5x5,out_channels_5x5,kernel_size = 5, padding = 2)\n","    )\n","    self.branch4 = nn.Sequential(\n","        nn.MaxPool2d(kernel_size = 3, stride=1, padding=1),\n","        ConvBlock(in_channels,poolproj_channels,kernel_size = 1)\n","    )\n","\n","  def forward(self,x):\n","    x = torch.cat([self.branch1(x),self.branch2(x),self.branch3(x),self.branch4(x)],1)\n","    return x\n","\n","class Auxiliaray_classifier(nn.Module):\n","  def __init__(self,in_channels,num_classes):\n","    super(Auxiliaray_classifier,self).__init__()\n","\n","    self.avgpool = nn.AvgPool2d(kernel_size = 5, stride=3, padding=0)\n","    self.conv = ConvBlock(in_channels,128,kernel_size = 1)\n","    self.fc = nn.Sequential(\n","        nn.Linear(2048,1024),\n","        nn.ReLU(),\n","        nn.Dropout(),\n","        nn.Linear(1024,num_classes)\n","    )\n","\n","  def forward(self,x):\n","    x = self.avgpool(x)\n","    x = self.conv(x)\n","    x = x.view(x.shape[0],-1)\n","    x = self.fc(x)\n","\n","    return x\n","\n","\n","model = inceptionv1(auxiliary = False, init_weight = True)\n","optimizer = optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","\n","# You should get at least 70% accuracy\n","avg_losses = train_part5(model, optimizer, epochs=10)\n","avg_losses = np.array(avg_losses)\n","np.save(\"%s.npy\" % experiment_name, avg_losses)\n","\n","plt.plot(avg_losses)\n","plt.title(\"Training Loss (%s)\" % experiment_name)\n","plt.show()"]},{"cell_type":"markdown","source":["auxiliary loss 사용해서 모델링"],"metadata":{"id":"eT2NnTAr3a5z"}},{"cell_type":"code","source":["def train_part5(model, optimizer, epochs=1):\n","    \"\"\"\n","    Train a model on CIFAR-10 using the PyTorch Module API.\n","\n","    Inputs:\n","    - model: A PyTorch Module giving the model to train.\n","    - optimizer: An Optimizer object we will use to train the model\n","    - epochs: (Optional) A Python integer giving the number of epochs to train for\n","\n","    Returns: Nothing, but prints model accuracies during training.\n","    \"\"\"\n","    avg_losses = []\n","    model = model.to(device=device)  # move the model parameters to CPU/GPU\n","    for e in range(epochs):\n","        avg_loss = 0.0\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores_out,scores_aux1,scores_aux2 = model(x)\n","            output_loss = F.cross_entropy(scores_out, y)\n","            aux_1_loss = F.cross_entropy(scores_aux1, y)\n","            aux_2_loss = F.cross_entropy(scores_aux2, y)\n","\n","            loss = output_loss + 0.3 * (aux_1_loss + aux_2_loss)\n","            # Zero out all of the gradients for the variables which the optimizer\n","            # will update.\n","            optimizer.zero_grad()\n","\n","            # This is the backwards pass: compute the gradient of the loss with\n","            # respect to each  parameter of the model.\n","            loss.backward()\n","\n","            # Actually update the parameters of the model using the gradients\n","            # computed by the backwards pass.\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy_part34(loader_val, model)\n","                print()\n","\n","            avg_loss += loss.item()\n","        avg_losses.append(avg_loss / len(loader_train))\n","\n","    torch.save(model,'googlenet_with_aux_adam_lr0.0001.pth')\n","    return avg_losses"],"metadata":{"id":"5xVOh0dF3in9","executionInfo":{"status":"ok","timestamp":1690039230516,"user_tz":-540,"elapsed":382,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["################################################################################\n","# TODO:                                                                        #\n","# Experiment with any architectures, optimizers, and hyperparameters.          #\n","# Achieve AT LEAST 70% accuracy on the *validation set* within 10 epochs.      #\n","#                                                                              #\n","# Note that you can use the check_accuracy function to evaluate on either      #\n","# the test set or the validation set, by passing either loader_test or         #\n","# loader_val as the second argument to check_accuracy. You should not touch    #\n","# the test set until you have finished your architecture and  hyperparameter   #\n","# tuning, and only run the test set once at the end to report a final value.   #\n","################################################################################\n","model = None\n","optimizer = None\n","experiment_name = \"googlenet_with_aux_adam_lr0.0001\"  # e.g., \"model1_sgd_lr0.1\", \"model2_adam_lr0.001\"\n","# Change the above experiment_name to store the avg_losses while perserving\n","# the previous avg_losses. Using the same value for experiment_name results in\n","# overwriting the previous one.\n","\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","class inceptionv1(nn.Module):\n","  def __init__(self,auxiliary = True, init_weight = True):\n","    super(inceptionv1,self).__init__()\n","\n","    assert auxiliary == True or auxiliary == False\n","    self.auxiliary = True\n","\n","    self.upsample = nn.Upsample(size = (224,224))\n","\n","    self.conv1 = ConvBlock(3, 64, kernel_size=7, stride=2, padding=3)\n","    self.maxpool1 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.conv2 = ConvBlock(64, 192, kernel_size=3, stride=1, padding=1)\n","    self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.inception3a = InceptionBlock(192,64,96,128,16,32,32)\n","    self.inception3b = InceptionBlock(256,128,128,192,32,96,64)\n","    self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n","    self.inception4a = InceptionBlock(480,192,96,208,16,48,64)\n","    self.inception4b = InceptionBlock(512,160,112,224,24,64,64)\n","    self.inception4c = InceptionBlock(512,128,128,256,24,64,64)\n","    self.inception4d = InceptionBlock(512,112,114,288,32,64,64)\n","    self.inception4e = InceptionBlock(528,256,160,320,32,128,128)\n","    self.maxpool4 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","    self.inception5a = InceptionBlock(832,256,160,320,32,128,128)\n","    self.inception5b = InceptionBlock(832,384,192,384,48,128,128)\n","    self.avgpool5 = nn.AvgPool2d(kernel_size = 7, stride=1)\n","    self.drop = nn.Dropout(p=0.4, inplace=False)\n","    self.fc = nn.Linear(1024,10)\n","\n","    if self.auxiliary:\n","      self.aux1 = Auxiliaray_classifier(512,10)\n","      self.aux2 = Auxiliaray_classifier(528,10)\n","    else:\n","      self.aux1 = None\n","      self.aux2 = None\n","\n","    if init_weight:\n","      self._initialize_weights()\n","\n","  def forward(self, x):\n","    x = self.upsample(x)\n","\n","    x = self.conv1(x)\n","    x = self.maxpool1(x)\n","    x = self.conv2(x)\n","    x = self.maxpool2(x)\n","    x = self.inception3a(x)\n","    x = self.inception3b(x)\n","    x = self.maxpool3(x)\n","\n","    x = self.inception4a(x)\n","\n","    if self.auxiliary and self.training:\n","      aux1 = self.aux1(x)\n","\n","    x = self.inception4b(x)\n","    x = self.inception4c(x)\n","    x = self.inception4d(x)\n","\n","    if self.auxiliary and self.training:\n","      aux2 = self.aux2(x)\n","\n","    x = self.inception4e(x)\n","    x = self.maxpool4(x)\n","    x = self.inception5a(x)\n","    x = self.inception5b(x)\n","    x = self.avgpool5(x)\n","\n","    x = x.view(x.shape[0], -1)\n","\n","    x = self.drop(x)\n","    x = self.fc(x)\n","\n","    if self.auxiliary and self.training:\n","      return x, aux1, aux2\n","    else:\n","      return x\n","\n","  def _initialize_weights(self):\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","        if m.bias is not None:\n","          nn.init.constant_(m.bias, 0)\n","      elif isinstance(m, nn.BatchNorm2d):\n","        nn.init.constant_(m.weight,1)\n","        nn.init.constant_(m.bias,0)\n","      elif isinstance(m, nn.Linear):\n","        nn.init.normal_(m.weight,0,0.01)\n","        nn.init.constant_(m.bias,0)\n","\n","\n","class ConvBlock(nn.Module):\n","  def __init__(self,in_channels, out_channels, **kwarg):\n","    super(ConvBlock,self).__init__()\n","\n","    self.convlayer = nn.Sequential(\n","        nn.Conv2d(in_channels,out_channels, **kwarg),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","    )\n","\n","  def forward(self,x):\n","    return self.convlayer(x)\n","\n","\n","class InceptionBlock(nn.Module):\n","  def __init__(self,in_channels,out_channels_1x1,reduce_channels_3x3,out_channels_3x3,reduce_channels_5x5,out_channels_5x5,poolproj_channels):\n","    super(InceptionBlock,self).__init__()\n","\n","    self.branch1 = ConvBlock(in_channels,out_channels_1x1,kernel_size = 1)\n","    self.branch2 = nn.Sequential(\n","        ConvBlock(in_channels,reduce_channels_3x3,kernel_size = 1),\n","        ConvBlock(reduce_channels_3x3,out_channels_3x3,kernel_size = 3,padding = 1)\n","    )\n","    self.branch3 = nn.Sequential(\n","        ConvBlock(in_channels,reduce_channels_5x5,kernel_size = 1),\n","        ConvBlock(reduce_channels_5x5,out_channels_5x5,kernel_size = 5, padding = 2)\n","    )\n","    self.branch4 = nn.Sequential(\n","        nn.MaxPool2d(kernel_size = 3, stride=1, padding=1),\n","        ConvBlock(in_channels,poolproj_channels,kernel_size = 1)\n","    )\n","\n","  def forward(self,x):\n","    x = torch.cat([self.branch1(x),self.branch2(x),self.branch3(x),self.branch4(x)],1)\n","    return x\n","\n","class Auxiliaray_classifier(nn.Module):\n","  def __init__(self,in_channels,num_classes):\n","    super(Auxiliaray_classifier,self).__init__()\n","\n","    self.avgpool = nn.AvgPool2d(kernel_size = 5, stride=3, padding=0)\n","    self.conv = ConvBlock(in_channels,128,kernel_size = 1)\n","    self.fc = nn.Sequential(\n","        nn.Linear(2048,1024),\n","        nn.ReLU(),\n","        nn.Dropout(),\n","        nn.Linear(1024,num_classes)\n","    )\n","\n","  def forward(self,x):\n","    x = self.avgpool(x)\n","    x = self.conv(x)\n","    x = x.view(x.shape[0],-1)\n","    x = self.fc(x)\n","\n","    return x\n","\n","learning_rate = 0.0001\n","model = inceptionv1(auxiliary = True, init_weight = True)\n","optimizer = optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","\n","# You should get at least 70% accuracy\n","avg_losses = train_part5(model, optimizer, epochs=10)\n","avg_losses = np.array(avg_losses)\n","np.save(\"%s.npy\" % experiment_name, avg_losses)\n","\n","plt.plot(avg_losses)\n","plt.title(\"Training Loss (%s)\" % experiment_name)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tpMsEjGO3Z5s","executionInfo":{"status":"ok","timestamp":1690041234066,"user_tz":-540,"elapsed":2003168,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"cfe356c5-5485-4e71-b5d6-8971fca70dcd"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 3.6781\n","Checking accuracy on validation set\n","Got 88 / 1000 correct (8.80)\n","\n","Iteration 100, loss = 2.7357\n","Checking accuracy on validation set\n","Got 384 / 1000 correct (38.40)\n","\n","Iteration 200, loss = 2.3034\n","Checking accuracy on validation set\n","Got 440 / 1000 correct (44.00)\n","\n","Iteration 300, loss = 1.8122\n","Checking accuracy on validation set\n","Got 512 / 1000 correct (51.20)\n","\n","Iteration 400, loss = 2.0486\n","Checking accuracy on validation set\n","Got 499 / 1000 correct (49.90)\n","\n","Iteration 500, loss = 1.9209\n","Checking accuracy on validation set\n","Got 583 / 1000 correct (58.30)\n","\n","Iteration 600, loss = 1.8618\n","Checking accuracy on validation set\n","Got 585 / 1000 correct (58.50)\n","\n","Iteration 700, loss = 1.6195\n","Checking accuracy on validation set\n","Got 627 / 1000 correct (62.70)\n","\n","Iteration 0, loss = 1.3374\n","Checking accuracy on validation set\n","Got 611 / 1000 correct (61.10)\n","\n","Iteration 100, loss = 1.7645\n","Checking accuracy on validation set\n","Got 581 / 1000 correct (58.10)\n","\n","Iteration 200, loss = 1.3540\n","Checking accuracy on validation set\n","Got 637 / 1000 correct (63.70)\n","\n","Iteration 300, loss = 1.2494\n","Checking accuracy on validation set\n","Got 649 / 1000 correct (64.90)\n","\n","Iteration 400, loss = 1.3251\n","Checking accuracy on validation set\n","Got 674 / 1000 correct (67.40)\n","\n","Iteration 500, loss = 1.3828\n","Checking accuracy on validation set\n","Got 680 / 1000 correct (68.00)\n","\n","Iteration 600, loss = 1.4756\n","Checking accuracy on validation set\n","Got 688 / 1000 correct (68.80)\n","\n","Iteration 700, loss = 1.3428\n","Checking accuracy on validation set\n","Got 740 / 1000 correct (74.00)\n","\n","Iteration 0, loss = 1.4516\n","Checking accuracy on validation set\n","Got 715 / 1000 correct (71.50)\n","\n","Iteration 100, loss = 1.4546\n","Checking accuracy on validation set\n","Got 747 / 1000 correct (74.70)\n","\n","Iteration 200, loss = 1.2314\n","Checking accuracy on validation set\n","Got 722 / 1000 correct (72.20)\n","\n","Iteration 300, loss = 1.1164\n","Checking accuracy on validation set\n","Got 744 / 1000 correct (74.40)\n","\n","Iteration 400, loss = 0.9620\n","Checking accuracy on validation set\n","Got 691 / 1000 correct (69.10)\n","\n","Iteration 500, loss = 0.9995\n","Checking accuracy on validation set\n","Got 770 / 1000 correct (77.00)\n","\n","Iteration 600, loss = 0.9131\n","Checking accuracy on validation set\n","Got 734 / 1000 correct (73.40)\n","\n","Iteration 700, loss = 1.2456\n","Checking accuracy on validation set\n","Got 730 / 1000 correct (73.00)\n","\n","Iteration 0, loss = 0.9791\n","Checking accuracy on validation set\n","Got 759 / 1000 correct (75.90)\n","\n","Iteration 100, loss = 0.8265\n","Checking accuracy on validation set\n","Got 778 / 1000 correct (77.80)\n","\n","Iteration 200, loss = 0.8619\n","Checking accuracy on validation set\n","Got 741 / 1000 correct (74.10)\n","\n","Iteration 300, loss = 0.9809\n","Checking accuracy on validation set\n","Got 764 / 1000 correct (76.40)\n","\n","Iteration 400, loss = 0.7284\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 500, loss = 0.9295\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Iteration 600, loss = 0.7301\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 700, loss = 0.5359\n","Checking accuracy on validation set\n","Got 790 / 1000 correct (79.00)\n","\n","Iteration 0, loss = 0.6430\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 100, loss = 0.5242\n","Checking accuracy on validation set\n","Got 809 / 1000 correct (80.90)\n","\n","Iteration 200, loss = 0.7327\n","Checking accuracy on validation set\n","Got 816 / 1000 correct (81.60)\n","\n","Iteration 300, loss = 0.9247\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 400, loss = 0.6324\n","Checking accuracy on validation set\n","Got 796 / 1000 correct (79.60)\n","\n","Iteration 500, loss = 0.8848\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 600, loss = 0.6821\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Iteration 700, loss = 0.4903\n","Checking accuracy on validation set\n","Got 808 / 1000 correct (80.80)\n","\n","Iteration 0, loss = 0.7126\n","Checking accuracy on validation set\n","Got 813 / 1000 correct (81.30)\n","\n","Iteration 100, loss = 0.5873\n","Checking accuracy on validation set\n","Got 812 / 1000 correct (81.20)\n","\n","Iteration 200, loss = 0.6664\n","Checking accuracy on validation set\n","Got 827 / 1000 correct (82.70)\n","\n","Iteration 300, loss = 0.4336\n","Checking accuracy on validation set\n","Got 806 / 1000 correct (80.60)\n","\n","Iteration 400, loss = 0.3868\n","Checking accuracy on validation set\n","Got 815 / 1000 correct (81.50)\n","\n","Iteration 500, loss = 0.6424\n","Checking accuracy on validation set\n","Got 825 / 1000 correct (82.50)\n","\n","Iteration 600, loss = 0.5601\n","Checking accuracy on validation set\n","Got 798 / 1000 correct (79.80)\n","\n","Iteration 700, loss = 0.7070\n","Checking accuracy on validation set\n","Got 820 / 1000 correct (82.00)\n","\n","Iteration 0, loss = 0.5315\n","Checking accuracy on validation set\n","Got 833 / 1000 correct (83.30)\n","\n","Iteration 100, loss = 0.2619\n","Checking accuracy on validation set\n","Got 830 / 1000 correct (83.00)\n","\n","Iteration 200, loss = 0.3571\n","Checking accuracy on validation set\n","Got 825 / 1000 correct (82.50)\n","\n","Iteration 300, loss = 0.2919\n","Checking accuracy on validation set\n","Got 801 / 1000 correct (80.10)\n","\n","Iteration 400, loss = 0.6144\n","Checking accuracy on validation set\n","Got 819 / 1000 correct (81.90)\n","\n","Iteration 500, loss = 0.5190\n","Checking accuracy on validation set\n","Got 816 / 1000 correct (81.60)\n","\n","Iteration 600, loss = 0.4516\n","Checking accuracy on validation set\n","Got 802 / 1000 correct (80.20)\n","\n","Iteration 700, loss = 0.7036\n","Checking accuracy on validation set\n","Got 798 / 1000 correct (79.80)\n","\n","Iteration 0, loss = 0.3780\n","Checking accuracy on validation set\n","Got 815 / 1000 correct (81.50)\n","\n","Iteration 100, loss = 0.2927\n","Checking accuracy on validation set\n","Got 840 / 1000 correct (84.00)\n","\n","Iteration 200, loss = 0.2309\n","Checking accuracy on validation set\n","Got 810 / 1000 correct (81.00)\n","\n","Iteration 300, loss = 0.1963\n","Checking accuracy on validation set\n","Got 815 / 1000 correct (81.50)\n","\n","Iteration 400, loss = 0.4155\n","Checking accuracy on validation set\n","Got 803 / 1000 correct (80.30)\n","\n","Iteration 500, loss = 0.3241\n","Checking accuracy on validation set\n","Got 808 / 1000 correct (80.80)\n","\n","Iteration 600, loss = 0.3870\n","Checking accuracy on validation set\n","Got 808 / 1000 correct (80.80)\n","\n","Iteration 700, loss = 0.5970\n","Checking accuracy on validation set\n","Got 842 / 1000 correct (84.20)\n","\n","Iteration 0, loss = 0.2407\n","Checking accuracy on validation set\n","Got 842 / 1000 correct (84.20)\n","\n","Iteration 100, loss = 0.2003\n","Checking accuracy on validation set\n","Got 825 / 1000 correct (82.50)\n","\n","Iteration 200, loss = 0.1507\n","Checking accuracy on validation set\n","Got 837 / 1000 correct (83.70)\n","\n","Iteration 300, loss = 0.2092\n","Checking accuracy on validation set\n","Got 841 / 1000 correct (84.10)\n","\n","Iteration 400, loss = 0.3711\n","Checking accuracy on validation set\n","Got 837 / 1000 correct (83.70)\n","\n","Iteration 500, loss = 0.5353\n","Checking accuracy on validation set\n","Got 823 / 1000 correct (82.30)\n","\n","Iteration 600, loss = 0.2610\n","Checking accuracy on validation set\n","Got 824 / 1000 correct (82.40)\n","\n","Iteration 700, loss = 0.5331\n","Checking accuracy on validation set\n","Got 816 / 1000 correct (81.60)\n","\n","Iteration 0, loss = 0.1982\n","Checking accuracy on validation set\n","Got 800 / 1000 correct (80.00)\n","\n","Iteration 100, loss = 0.2014\n","Checking accuracy on validation set\n","Got 840 / 1000 correct (84.00)\n","\n","Iteration 200, loss = 0.2630\n","Checking accuracy on validation set\n","Got 830 / 1000 correct (83.00)\n","\n","Iteration 300, loss = 0.1625\n","Checking accuracy on validation set\n","Got 826 / 1000 correct (82.60)\n","\n","Iteration 400, loss = 0.2584\n","Checking accuracy on validation set\n","Got 813 / 1000 correct (81.30)\n","\n","Iteration 500, loss = 0.2388\n","Checking accuracy on validation set\n","Got 809 / 1000 correct (80.90)\n","\n","Iteration 600, loss = 0.4845\n","Checking accuracy on validation set\n","Got 830 / 1000 correct (83.00)\n","\n","Iteration 700, loss = 0.1758\n","Checking accuracy on validation set\n","Got 816 / 1000 correct (81.60)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"5samHtMggn_8"},"source":["이전에 실행한 `experiment_name` 여러 개를 리스트 내에 나열해 보세요. 각 실험의 손실 함수 추이를 비교할 수 있습니다."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bdyq9pfCgqaz","colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"status":"ok","timestamp":1690038755805,"user_tz":-540,"elapsed":1130,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"23a17c7b-c5bd-4630-fa13-e96d684fb699"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["experiment_names = [\"googlenet_with_aux_adam_lr0.0001\", \"googlenet_without_aux_adam_lr0.0001\"]\n","\n","for experiment_name in experiment_names:\n","    avg_losses = np.load(\"%s.npy\" % experiment_name)\n","    plt.plot(avg_losses, label=experiment_name)\n","plt.title(\"Training Loss Comparison\")\n","plt.legend(loc=\"upper right\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Wn0hm7nvpR2E"},"source":["## Describe what you did\n","\n","아래 칸에 자신이 수행한 작업, 구현한 추가 기능 및/또는 네트워크를 훈련하고 평가하는 과정에서 만든 그래프에 대한 설명을 작성해야 합니다."]},{"cell_type":"markdown","metadata":{"id":"85-8eL1mpR2E"},"source":["**Answer:**\n","\n","논문 리뷰를 했었던 googlenet에 대한 코드 구현을 해봤다.\n","\n","CNN에서 다양한 사이즈의 Kernel을 concat한 inception module을 사용했고 중간 중간 auxiliary classifier를 이용해 vanish gradient를 방지했다.\n","\n","auxiliary가 있는 경우와 없는 경우 모두 loss가 잘 하락하고 있음을 확인할 수 있으며 처음 initialize가 랜덤하게 진행되어 loss의 차이가 나올 것으로 예상된다. (혹은 auxiliary classifier가 의미가 없는 것일 수도 ..)"]},{"cell_type":"markdown","metadata":{"id":"RM-B3G5ypR2F"},"source":["## Test set -- run this only once\n","\n","이제 만족스러운 결과를 얻었으므로 테스트 세트에서 최종 모델을 테스트합니다(best_model에 저장해야 함). 이것이 유효성 검사 세트 정확도와 어떻게 비교되는지 생각해 보세요."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"7KGIAvAZpR2F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690041475014,"user_tz":-540,"elapsed":11857,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"ee77a5ef-6716-4fd1-8411-6e666932f50d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Checking accuracy on test set\n","Got 8205 / 10000 correct (82.05)\n"]}],"source":["best_model = torch.load('googlenet_with_aux_adam_lr0.0001.pth')\n","check_accuracy_part34(loader_test, best_model)"]},{"cell_type":"markdown","metadata":{"id":"48ZsEUyiocf-"},"source":["# Additional Part. Pretrained model 불러오기\n","\n","Part V에서 만족스러운 결과를 얻으셨나요? PyTorch의 Model을 정의하는 능력은 매우 강력하지만, 때로는 다른 사람들이 만들어 둔 Model을 통해 빠르게 실험을 하고 싶을 때도 있습니다. 그럴 때를 위해 torchvision를 통해 pre-trained된 Model을 받을 수 있습니다.\n","\n","다음을 참고하세요: [torchvision document](https://pytorch.org/vision/stable/models.html#classification)\n","\n","Model의 구조가 궁금한 경우 print()를 통해 쉽게 확인해 볼 수 있습니다."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"aLXA4juyol1y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690041715538,"user_tz":-540,"elapsed":2849,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"ebff8c2a-c5b2-4d48-d9ba-bee44a041e5f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 236MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",")\n"]}],"source":["from torchvision import models\n","\n","# Download resnet50 pretrained\n","resnet_pretrained = models.resnet50(pretrained=True)\n","print(resnet_pretrained)"]},{"cell_type":"markdown","metadata":{"id":"HyK1w2VotW_C"},"source":["## Pretrained model 수정하기\n","print()를 통해 확인할 수 있듯이, 다운 받은 ResNet Model의 마지막 Layer는 out_features=1000으로 설정되어 있습니다. 하지만 우리의 task에서는 Output이 10개 임으로, model 구조를 조금 수정해야 합니다."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"B726VCVjpcwK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690041791942,"user_tz":-540,"elapsed":390,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"01c38b51-b2be-4949-936a-bfbe08df549b"},"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",")\n"]}],"source":["num_ftrs = resnet_pretrained.fc.in_features\n","num_classes = 10\n","\n","# Model이 가진 'fc'라는 이름을 가진 Layer에 직접 접근해 수정해 줄 수 있습니다.\n","resnet_pretrained.fc = nn.Linear(num_ftrs, num_classes)\n","print(resnet_pretrained)"]},{"cell_type":"markdown","metadata":{"id":"-oUEPMcPsiBJ"},"source":["## Fine tuning model 성능 평가 하기\n","이제 Fine tuning 한 Model의 성능을 평가해 봅시다."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"wUaV2rF7LAX5","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1690043001489,"user_tz":-540,"elapsed":1188745,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"616769b6-82d0-4b10-ae05-0f3edbf3d1ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.3938\n","Checking accuracy on validation set\n","Got 113 / 1000 correct (11.30)\n","\n","Iteration 100, loss = 2.5607\n","Checking accuracy on validation set\n","Got 306 / 1000 correct (30.60)\n","\n","Iteration 200, loss = 2.3100\n","Checking accuracy on validation set\n","Got 225 / 1000 correct (22.50)\n","\n","Iteration 300, loss = 2.0018\n","Checking accuracy on validation set\n","Got 310 / 1000 correct (31.00)\n","\n","Iteration 400, loss = 2.0368\n","Checking accuracy on validation set\n","Got 229 / 1000 correct (22.90)\n","\n","Iteration 500, loss = 1.6766\n","Checking accuracy on validation set\n","Got 322 / 1000 correct (32.20)\n","\n","Iteration 600, loss = 1.6393\n","Checking accuracy on validation set\n","Got 358 / 1000 correct (35.80)\n","\n","Iteration 700, loss = 1.4873\n","Checking accuracy on validation set\n","Got 404 / 1000 correct (40.40)\n","\n","Iteration 0, loss = 1.4721\n","Checking accuracy on validation set\n","Got 450 / 1000 correct (45.00)\n","\n","Iteration 100, loss = 1.4698\n","Checking accuracy on validation set\n","Got 469 / 1000 correct (46.90)\n","\n","Iteration 200, loss = 1.7465\n","Checking accuracy on validation set\n","Got 383 / 1000 correct (38.30)\n","\n","Iteration 300, loss = 1.3743\n","Checking accuracy on validation set\n","Got 463 / 1000 correct (46.30)\n","\n","Iteration 400, loss = 1.6631\n","Checking accuracy on validation set\n","Got 494 / 1000 correct (49.40)\n","\n","Iteration 500, loss = 1.3592\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n","Iteration 600, loss = 1.4866\n","Checking accuracy on validation set\n","Got 522 / 1000 correct (52.20)\n","\n","Iteration 700, loss = 1.3589\n","Checking accuracy on validation set\n","Got 469 / 1000 correct (46.90)\n","\n","Iteration 0, loss = 1.2942\n","Checking accuracy on validation set\n","Got 518 / 1000 correct (51.80)\n","\n","Iteration 100, loss = 1.4343\n","Checking accuracy on validation set\n","Got 518 / 1000 correct (51.80)\n","\n","Iteration 200, loss = 1.2912\n","Checking accuracy on validation set\n","Got 558 / 1000 correct (55.80)\n","\n","Iteration 300, loss = 1.2661\n","Checking accuracy on validation set\n","Got 549 / 1000 correct (54.90)\n","\n","Iteration 400, loss = 1.2987\n","Checking accuracy on validation set\n","Got 557 / 1000 correct (55.70)\n","\n","Iteration 500, loss = 1.1017\n","Checking accuracy on validation set\n","Got 569 / 1000 correct (56.90)\n","\n","Iteration 600, loss = 1.1369\n","Checking accuracy on validation set\n","Got 559 / 1000 correct (55.90)\n","\n","Iteration 700, loss = 1.1943\n","Checking accuracy on validation set\n","Got 553 / 1000 correct (55.30)\n","\n","Iteration 0, loss = 1.1544\n","Checking accuracy on validation set\n","Got 587 / 1000 correct (58.70)\n","\n","Iteration 100, loss = 1.1558\n","Checking accuracy on validation set\n","Got 559 / 1000 correct (55.90)\n","\n","Iteration 200, loss = 1.1397\n","Checking accuracy on validation set\n","Got 586 / 1000 correct (58.60)\n","\n","Iteration 300, loss = 1.1315\n","Checking accuracy on validation set\n","Got 606 / 1000 correct (60.60)\n","\n","Iteration 400, loss = 0.9025\n","Checking accuracy on validation set\n","Got 586 / 1000 correct (58.60)\n","\n","Iteration 500, loss = 1.2181\n","Checking accuracy on validation set\n","Got 583 / 1000 correct (58.30)\n","\n","Iteration 600, loss = 0.9976\n","Checking accuracy on validation set\n","Got 620 / 1000 correct (62.00)\n","\n","Iteration 700, loss = 1.0050\n","Checking accuracy on validation set\n","Got 640 / 1000 correct (64.00)\n","\n","Iteration 0, loss = 0.8207\n","Checking accuracy on validation set\n","Got 646 / 1000 correct (64.60)\n","\n","Iteration 100, loss = 0.8183\n","Checking accuracy on validation set\n","Got 589 / 1000 correct (58.90)\n","\n","Iteration 200, loss = 0.8118\n","Checking accuracy on validation set\n","Got 641 / 1000 correct (64.10)\n","\n","Iteration 300, loss = 0.9840\n","Checking accuracy on validation set\n","Got 641 / 1000 correct (64.10)\n","\n","Iteration 400, loss = 0.7990\n","Checking accuracy on validation set\n","Got 651 / 1000 correct (65.10)\n","\n","Iteration 500, loss = 0.8434\n","Checking accuracy on validation set\n","Got 650 / 1000 correct (65.00)\n","\n","Iteration 600, loss = 0.7820\n","Checking accuracy on validation set\n","Got 659 / 1000 correct (65.90)\n","\n","Iteration 700, loss = 1.0531\n","Checking accuracy on validation set\n","Got 682 / 1000 correct (68.20)\n","\n","Iteration 0, loss = 0.9970\n","Checking accuracy on validation set\n","Got 634 / 1000 correct (63.40)\n","\n","Iteration 100, loss = 0.9365\n","Checking accuracy on validation set\n","Got 634 / 1000 correct (63.40)\n","\n","Iteration 200, loss = 1.0408\n","Checking accuracy on validation set\n","Got 647 / 1000 correct (64.70)\n","\n","Iteration 300, loss = 0.9205\n","Checking accuracy on validation set\n","Got 681 / 1000 correct (68.10)\n","\n","Iteration 400, loss = 0.8107\n","Checking accuracy on validation set\n","Got 688 / 1000 correct (68.80)\n","\n","Iteration 500, loss = 0.8399\n","Checking accuracy on validation set\n","Got 675 / 1000 correct (67.50)\n","\n","Iteration 600, loss = 0.8556\n","Checking accuracy on validation set\n","Got 673 / 1000 correct (67.30)\n","\n","Iteration 700, loss = 0.9142\n","Checking accuracy on validation set\n","Got 623 / 1000 correct (62.30)\n","\n","Iteration 0, loss = 0.7364\n","Checking accuracy on validation set\n","Got 663 / 1000 correct (66.30)\n","\n","Iteration 100, loss = 0.7778\n","Checking accuracy on validation set\n","Got 670 / 1000 correct (67.00)\n","\n","Iteration 200, loss = 0.7090\n","Checking accuracy on validation set\n","Got 687 / 1000 correct (68.70)\n","\n","Iteration 300, loss = 0.7107\n","Checking accuracy on validation set\n","Got 664 / 1000 correct (66.40)\n","\n","Iteration 400, loss = 0.8918\n","Checking accuracy on validation set\n","Got 685 / 1000 correct (68.50)\n","\n","Iteration 500, loss = 0.9349\n","Checking accuracy on validation set\n","Got 716 / 1000 correct (71.60)\n","\n","Iteration 600, loss = 0.8852\n","Checking accuracy on validation set\n","Got 693 / 1000 correct (69.30)\n","\n","Iteration 700, loss = 0.7479\n","Checking accuracy on validation set\n","Got 662 / 1000 correct (66.20)\n","\n","Iteration 0, loss = 0.5168\n","Checking accuracy on validation set\n","Got 699 / 1000 correct (69.90)\n","\n","Iteration 100, loss = 0.5956\n","Checking accuracy on validation set\n","Got 712 / 1000 correct (71.20)\n","\n","Iteration 200, loss = 0.6997\n","Checking accuracy on validation set\n","Got 668 / 1000 correct (66.80)\n","\n","Iteration 300, loss = 0.6663\n","Checking accuracy on validation set\n","Got 711 / 1000 correct (71.10)\n","\n","Iteration 400, loss = 0.9659\n","Checking accuracy on validation set\n","Got 673 / 1000 correct (67.30)\n","\n","Iteration 500, loss = 0.8356\n","Checking accuracy on validation set\n","Got 707 / 1000 correct (70.70)\n","\n","Iteration 600, loss = 0.9447\n","Checking accuracy on validation set\n","Got 710 / 1000 correct (71.00)\n","\n","Iteration 700, loss = 0.7911\n","Checking accuracy on validation set\n","Got 709 / 1000 correct (70.90)\n","\n","Iteration 0, loss = 0.7039\n","Checking accuracy on validation set\n","Got 703 / 1000 correct (70.30)\n","\n","Iteration 100, loss = 0.7813\n","Checking accuracy on validation set\n","Got 673 / 1000 correct (67.30)\n","\n","Iteration 200, loss = 0.7570\n","Checking accuracy on validation set\n","Got 682 / 1000 correct (68.20)\n","\n","Iteration 300, loss = 0.7553\n","Checking accuracy on validation set\n","Got 724 / 1000 correct (72.40)\n","\n","Iteration 400, loss = 0.7364\n","Checking accuracy on validation set\n","Got 708 / 1000 correct (70.80)\n","\n","Iteration 500, loss = 0.8598\n","Checking accuracy on validation set\n","Got 733 / 1000 correct (73.30)\n","\n","Iteration 600, loss = 0.7339\n","Checking accuracy on validation set\n","Got 748 / 1000 correct (74.80)\n","\n","Iteration 700, loss = 0.5838\n","Checking accuracy on validation set\n","Got 705 / 1000 correct (70.50)\n","\n","Iteration 0, loss = 0.5214\n","Checking accuracy on validation set\n","Got 725 / 1000 correct (72.50)\n","\n","Iteration 100, loss = 0.6007\n","Checking accuracy on validation set\n","Got 736 / 1000 correct (73.60)\n","\n","Iteration 200, loss = 0.4618\n","Checking accuracy on validation set\n","Got 719 / 1000 correct (71.90)\n","\n","Iteration 300, loss = 0.6588\n","Checking accuracy on validation set\n","Got 704 / 1000 correct (70.40)\n","\n","Iteration 400, loss = 0.6582\n","Checking accuracy on validation set\n","Got 728 / 1000 correct (72.80)\n","\n","Iteration 500, loss = 0.5928\n","Checking accuracy on validation set\n","Got 742 / 1000 correct (74.20)\n","\n","Iteration 600, loss = 0.5964\n","Checking accuracy on validation set\n","Got 731 / 1000 correct (73.10)\n","\n","Iteration 700, loss = 0.5809\n","Checking accuracy on validation set\n","Got 738 / 1000 correct (73.80)\n","\n","Iteration 0, loss = 0.5534\n","Checking accuracy on validation set\n","Got 710 / 1000 correct (71.00)\n","\n","Iteration 100, loss = 0.4518\n","Checking accuracy on validation set\n","Got 706 / 1000 correct (70.60)\n","\n","Iteration 200, loss = 0.5539\n","Checking accuracy on validation set\n","Got 730 / 1000 correct (73.00)\n","\n","Iteration 300, loss = 0.7499\n","Checking accuracy on validation set\n","Got 745 / 1000 correct (74.50)\n","\n","Iteration 400, loss = 0.4672\n","Checking accuracy on validation set\n","Got 740 / 1000 correct (74.00)\n","\n","Iteration 500, loss = 0.6456\n","Checking accuracy on validation set\n","Got 738 / 1000 correct (73.80)\n","\n","Iteration 600, loss = 0.4007\n","Checking accuracy on validation set\n","Got 736 / 1000 correct (73.60)\n","\n","Iteration 700, loss = 0.5362\n","Checking accuracy on validation set\n","Got 757 / 1000 correct (75.70)\n","\n","Iteration 0, loss = 0.4643\n","Checking accuracy on validation set\n","Got 740 / 1000 correct (74.00)\n","\n","Iteration 100, loss = 0.5383\n","Checking accuracy on validation set\n","Got 752 / 1000 correct (75.20)\n","\n","Iteration 200, loss = 0.7117\n","Checking accuracy on validation set\n","Got 717 / 1000 correct (71.70)\n","\n","Iteration 300, loss = 0.7984\n","Checking accuracy on validation set\n","Got 733 / 1000 correct (73.30)\n","\n","Iteration 400, loss = 0.5858\n","Checking accuracy on validation set\n","Got 742 / 1000 correct (74.20)\n","\n","Iteration 500, loss = 0.6086\n","Checking accuracy on validation set\n","Got 742 / 1000 correct (74.20)\n","\n","Iteration 600, loss = 0.3926\n","Checking accuracy on validation set\n","Got 783 / 1000 correct (78.30)\n","\n","Iteration 700, loss = 0.4146\n","Checking accuracy on validation set\n","Got 748 / 1000 correct (74.80)\n","\n","Iteration 0, loss = 0.6490\n","Checking accuracy on validation set\n","Got 748 / 1000 correct (74.80)\n","\n","Iteration 100, loss = 0.6859\n","Checking accuracy on validation set\n","Got 747 / 1000 correct (74.70)\n","\n","Iteration 200, loss = 0.2467\n","Checking accuracy on validation set\n","Got 735 / 1000 correct (73.50)\n","\n","Iteration 300, loss = 0.4952\n","Checking accuracy on validation set\n","Got 755 / 1000 correct (75.50)\n","\n","Iteration 400, loss = 0.5649\n","Checking accuracy on validation set\n","Got 734 / 1000 correct (73.40)\n","\n","Iteration 500, loss = 0.3932\n","Checking accuracy on validation set\n","Got 762 / 1000 correct (76.20)\n","\n","Iteration 600, loss = 0.5893\n","Checking accuracy on validation set\n","Got 627 / 1000 correct (62.70)\n","\n","Iteration 700, loss = 0.6825\n","Checking accuracy on validation set\n","Got 750 / 1000 correct (75.00)\n","\n","Iteration 0, loss = 0.4569\n","Checking accuracy on validation set\n","Got 744 / 1000 correct (74.40)\n","\n","Iteration 100, loss = 0.3845\n","Checking accuracy on validation set\n","Got 758 / 1000 correct (75.80)\n","\n","Iteration 200, loss = 0.7488\n","Checking accuracy on validation set\n","Got 761 / 1000 correct (76.10)\n","\n","Iteration 300, loss = 0.5961\n","Checking accuracy on validation set\n","Got 769 / 1000 correct (76.90)\n","\n","Iteration 400, loss = 0.3508\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 500, loss = 0.5410\n","Checking accuracy on validation set\n","Got 764 / 1000 correct (76.40)\n","\n","Iteration 600, loss = 0.4211\n","Checking accuracy on validation set\n","Got 778 / 1000 correct (77.80)\n","\n","Iteration 700, loss = 0.5404\n","Checking accuracy on validation set\n","Got 758 / 1000 correct (75.80)\n","\n","Iteration 0, loss = 0.4601\n","Checking accuracy on validation set\n","Got 774 / 1000 correct (77.40)\n","\n","Iteration 100, loss = 0.2360\n","Checking accuracy on validation set\n","Got 786 / 1000 correct (78.60)\n","\n","Iteration 200, loss = 0.4654\n","Checking accuracy on validation set\n","Got 769 / 1000 correct (76.90)\n","\n","Iteration 300, loss = 0.5221\n","Checking accuracy on validation set\n","Got 749 / 1000 correct (74.90)\n","\n","Iteration 400, loss = 0.4198\n","Checking accuracy on validation set\n","Got 769 / 1000 correct (76.90)\n","\n","Iteration 500, loss = 0.5667\n","Checking accuracy on validation set\n","Got 761 / 1000 correct (76.10)\n","\n","Iteration 600, loss = 0.5560\n","Checking accuracy on validation set\n","Got 758 / 1000 correct (75.80)\n","\n","Iteration 700, loss = 0.3805\n","Checking accuracy on validation set\n","Got 763 / 1000 correct (76.30)\n","\n","Iteration 0, loss = 0.3856\n","Checking accuracy on validation set\n","Got 756 / 1000 correct (75.60)\n","\n","Iteration 100, loss = 0.4761\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 200, loss = 0.4640\n","Checking accuracy on validation set\n","Got 785 / 1000 correct (78.50)\n","\n","Iteration 300, loss = 0.1868\n","Checking accuracy on validation set\n","Got 766 / 1000 correct (76.60)\n","\n","Iteration 400, loss = 0.3234\n","Checking accuracy on validation set\n","Got 771 / 1000 correct (77.10)\n","\n","Iteration 500, loss = 0.6242\n","Checking accuracy on validation set\n","Got 766 / 1000 correct (76.60)\n","\n","Iteration 600, loss = 0.4993\n","Checking accuracy on validation set\n","Got 765 / 1000 correct (76.50)\n","\n","Iteration 700, loss = 0.5530\n","Checking accuracy on validation set\n","Got 772 / 1000 correct (77.20)\n","\n","Iteration 0, loss = 0.2097\n","Checking accuracy on validation set\n","Got 785 / 1000 correct (78.50)\n","\n","Iteration 100, loss = 0.3339\n","Checking accuracy on validation set\n","Got 758 / 1000 correct (75.80)\n","\n","Iteration 200, loss = 0.4037\n","Checking accuracy on validation set\n","Got 777 / 1000 correct (77.70)\n","\n","Iteration 300, loss = 0.2840\n","Checking accuracy on validation set\n","Got 749 / 1000 correct (74.90)\n","\n","Iteration 400, loss = 0.3411\n","Checking accuracy on validation set\n","Got 756 / 1000 correct (75.60)\n","\n","Iteration 500, loss = 0.1638\n","Checking accuracy on validation set\n","Got 759 / 1000 correct (75.90)\n","\n","Iteration 600, loss = 0.2947\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 700, loss = 0.3819\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 0, loss = 0.2651\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 100, loss = 0.1925\n","Checking accuracy on validation set\n","Got 763 / 1000 correct (76.30)\n","\n","Iteration 200, loss = 0.1701\n","Checking accuracy on validation set\n","Got 765 / 1000 correct (76.50)\n","\n","Iteration 300, loss = 0.3185\n","Checking accuracy on validation set\n","Got 763 / 1000 correct (76.30)\n","\n","Iteration 400, loss = 0.2945\n","Checking accuracy on validation set\n","Got 782 / 1000 correct (78.20)\n","\n","Iteration 500, loss = 0.3252\n","Checking accuracy on validation set\n","Got 793 / 1000 correct (79.30)\n","\n","Iteration 600, loss = 0.4535\n","Checking accuracy on validation set\n","Got 762 / 1000 correct (76.20)\n","\n","Iteration 700, loss = 0.3498\n","Checking accuracy on validation set\n","Got 781 / 1000 correct (78.10)\n","\n","Iteration 0, loss = 0.1903\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 100, loss = 0.4296\n","Checking accuracy on validation set\n","Got 693 / 1000 correct (69.30)\n","\n","Iteration 200, loss = 0.2885\n","Checking accuracy on validation set\n","Got 745 / 1000 correct (74.50)\n","\n","Iteration 300, loss = 0.3542\n","Checking accuracy on validation set\n","Got 757 / 1000 correct (75.70)\n","\n","Iteration 400, loss = 0.4230\n","Checking accuracy on validation set\n","Got 778 / 1000 correct (77.80)\n","\n","Iteration 500, loss = 0.2851\n","Checking accuracy on validation set\n","Got 786 / 1000 correct (78.60)\n","\n","Iteration 600, loss = 0.4190\n","Checking accuracy on validation set\n","Got 770 / 1000 correct (77.00)\n","\n","Iteration 700, loss = 0.2536\n","Checking accuracy on validation set\n","Iteration 0, loss = 0.3691\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 100, loss = 0.2027\n","Checking accuracy on validation set\n","Got 777 / 1000 correct (77.70)\n","\n","Iteration 200, loss = 0.1192\n","Checking accuracy on validation set\n","Got 792 / 1000 correct (79.20)\n","\n","Iteration 300, loss = 0.2856\n","Checking accuracy on validation set\n","Got 796 / 1000 correct (79.60)\n","\n","Iteration 400, loss = 0.4514\n","Checking accuracy on validation set\n","Got 751 / 1000 correct (75.10)\n","\n","Iteration 500, loss = 0.3002\n","Checking accuracy on validation set\n","Got 761 / 1000 correct (76.10)\n","\n","Iteration 600, loss = 0.2610\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 700, loss = 0.1836\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 0, loss = 0.2374\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 100, loss = 0.2316\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Iteration 200, loss = 0.2020\n","Checking accuracy on validation set\n","Got 774 / 1000 correct (77.40)\n","\n","Iteration 300, loss = 0.4165\n","Checking accuracy on validation set\n","Got 768 / 1000 correct (76.80)\n","\n","Iteration 400, loss = 0.1104\n","Checking accuracy on validation set\n","Got 761 / 1000 correct (76.10)\n","\n","Iteration 500, loss = 0.2114\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 600, loss = 0.2763\n","Checking accuracy on validation set\n","Got 771 / 1000 correct (77.10)\n","\n","Iteration 700, loss = 0.1388\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Iteration 0, loss = 0.1384\n","Checking accuracy on validation set\n","Got 762 / 1000 correct (76.20)\n","\n","Iteration 100, loss = 0.3289\n","Checking accuracy on validation set\n","Got 769 / 1000 correct (76.90)\n","\n","Iteration 200, loss = 0.2976\n","Checking accuracy on validation set\n","Got 764 / 1000 correct (76.40)\n","\n","Iteration 300, loss = 0.2765\n","Checking accuracy on validation set\n","Got 737 / 1000 correct (73.70)\n","\n","Iteration 400, loss = 0.1715\n","Checking accuracy on validation set\n","Got 764 / 1000 correct (76.40)\n","\n","Iteration 500, loss = 0.2583\n","Checking accuracy on validation set\n","Got 792 / 1000 correct (79.20)\n","\n","Iteration 600, loss = 0.2268\n","Checking accuracy on validation set\n","Got 759 / 1000 correct (75.90)\n","\n","Iteration 700, loss = 0.2624\n","Checking accuracy on validation set\n","Got 785 / 1000 correct (78.50)\n","\n","Iteration 0, loss = 0.0651\n","Checking accuracy on validation set\n","Got 793 / 1000 correct (79.30)\n","\n","Iteration 100, loss = 0.1979\n","Checking accuracy on validation set\n","Got 768 / 1000 correct (76.80)\n","\n","Iteration 200, loss = 0.1318\n","Checking accuracy on validation set\n","Got 774 / 1000 correct (77.40)\n","\n","Iteration 300, loss = 0.0432\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 400, loss = 0.1387\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 500, loss = 0.1784\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Iteration 600, loss = 0.2836\n","Checking accuracy on validation set\n","Got 779 / 1000 correct (77.90)\n","\n","Iteration 700, loss = 0.1791\n","Checking accuracy on validation set\n","Got 783 / 1000 correct (78.30)\n","\n","Iteration 0, loss = 0.2053\n","Checking accuracy on validation set\n","Got 794 / 1000 correct (79.40)\n","\n","Iteration 100, loss = 0.4386\n","Checking accuracy on validation set\n","Got 801 / 1000 correct (80.10)\n","\n","Iteration 200, loss = 0.1054\n","Checking accuracy on validation set\n","Got 778 / 1000 correct (77.80)\n","\n","Iteration 300, loss = 0.1573\n","Checking accuracy on validation set\n","Got 768 / 1000 correct (76.80)\n","\n","Iteration 400, loss = 0.0954\n","Checking accuracy on validation set\n","Got 765 / 1000 correct (76.50)\n","\n","Iteration 500, loss = 0.1508\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 600, loss = 0.2464\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 700, loss = 0.3199\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Iteration 0, loss = 0.2102\n","Checking accuracy on validation set\n","Got 794 / 1000 correct (79.40)\n","\n","Iteration 100, loss = 0.2326\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Iteration 200, loss = 0.1697\n","Checking accuracy on validation set\n","Got 782 / 1000 correct (78.20)\n","\n","Iteration 300, loss = 0.2386\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 400, loss = 0.2108\n","Checking accuracy on validation set\n","Got 769 / 1000 correct (76.90)\n","\n","Iteration 500, loss = 0.1098\n","Checking accuracy on validation set\n","Got 781 / 1000 correct (78.10)\n","\n","Iteration 600, loss = 0.1909\n","Checking accuracy on validation set\n","Got 774 / 1000 correct (77.40)\n","\n","Iteration 700, loss = 0.2852\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 0, loss = 0.1160\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 100, loss = 0.1840\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 200, loss = 0.3629\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 300, loss = 0.0684\n","Checking accuracy on validation set\n","Got 796 / 1000 correct (79.60)\n","\n","Iteration 400, loss = 0.1411\n","Checking accuracy on validation set\n","Got 803 / 1000 correct (80.30)\n","\n","Iteration 500, loss = 0.1530\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 600, loss = 0.3064\n","Checking accuracy on validation set\n","Got 752 / 1000 correct (75.20)\n","\n","Iteration 700, loss = 0.5814\n","Checking accuracy on validation set\n","Got 630 / 1000 correct (63.00)\n","\n","Iteration 0, loss = 0.1292\n","Checking accuracy on validation set\n","Got 748 / 1000 correct (74.80)\n","\n","Iteration 100, loss = 0.1121\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 200, loss = 0.1393\n","Checking accuracy on validation set\n","Got 779 / 1000 correct (77.90)\n","\n","Iteration 300, loss = 0.1978\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 400, loss = 0.1851\n","Checking accuracy on validation set\n","Got 780 / 1000 correct (78.00)\n","\n","Iteration 500, loss = 0.2315\n","Checking accuracy on validation set\n","Got 777 / 1000 correct (77.70)\n","\n","Iteration 600, loss = 0.1845\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 700, loss = 0.2151\n","Checking accuracy on validation set\n","Got 779 / 1000 correct (77.90)\n","\n","Iteration 0, loss = 0.0752\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 100, loss = 0.1516\n","Checking accuracy on validation set\n","Got 770 / 1000 correct (77.00)\n","\n","Iteration 200, loss = 0.0597\n","Checking accuracy on validation set\n","Got 793 / 1000 correct (79.30)\n","\n","Iteration 300, loss = 0.1851\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 400, loss = 0.2546\n","Checking accuracy on validation set\n","Got 794 / 1000 correct (79.40)\n","\n","Iteration 500, loss = 0.2163\n","Checking accuracy on validation set\n","Got 809 / 1000 correct (80.90)\n","\n","Iteration 600, loss = 0.1195\n","Checking accuracy on validation set\n","Got 786 / 1000 correct (78.60)\n","\n","Iteration 700, loss = 0.1795\n","Checking accuracy on validation set\n","Got 781 / 1000 correct (78.10)\n","\n","Iteration 0, loss = 0.0209\n","Checking accuracy on validation set\n","Got 783 / 1000 correct (78.30)\n","\n","Iteration 100, loss = 0.2938\n","Checking accuracy on validation set\n","Got 776 / 1000 correct (77.60)\n","\n","Iteration 200, loss = 0.0530\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 300, loss = 0.1635\n","Checking accuracy on validation set\n","Got 786 / 1000 correct (78.60)\n","\n","Iteration 400, loss = 0.2413\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 500, loss = 0.1380\n","Checking accuracy on validation set\n","Got 772 / 1000 correct (77.20)\n","\n","Iteration 600, loss = 0.0941\n","Checking accuracy on validation set\n","Got 785 / 1000 correct (78.50)\n","\n","Iteration 700, loss = 0.1403\n","Checking accuracy on validation set\n","Got 796 / 1000 correct (79.60)\n","\n","Iteration 0, loss = 0.0412\n","Checking accuracy on validation set\n","Got 765 / 1000 correct (76.50)\n","\n","Iteration 100, loss = 0.0411\n","Checking accuracy on validation set\n","Got 781 / 1000 correct (78.10)\n","\n","Iteration 200, loss = 0.1287\n","Checking accuracy on validation set\n","Got 791 / 1000 correct (79.10)\n","\n","Iteration 300, loss = 0.0730\n","Checking accuracy on validation set\n","Got 772 / 1000 correct (77.20)\n","\n","Iteration 400, loss = 0.1225\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 500, loss = 0.0295\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 600, loss = 0.0911\n","Checking accuracy on validation set\n","Got 792 / 1000 correct (79.20)\n","\n","Iteration 700, loss = 0.0723\n","Checking accuracy on validation set\n","Got 775 / 1000 correct (77.50)\n","\n","Iteration 0, loss = 0.0722\n","Checking accuracy on validation set\n","Got 783 / 1000 correct (78.30)\n","\n","Iteration 100, loss = 0.1365\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 200, loss = 0.1278\n","Checking accuracy on validation set\n","Got 767 / 1000 correct (76.70)\n","\n","Iteration 300, loss = 0.0839\n","Checking accuracy on validation set\n","Got 787 / 1000 correct (78.70)\n","\n","Iteration 400, loss = 0.1414\n","Checking accuracy on validation set\n","Got 784 / 1000 correct (78.40)\n","\n","Iteration 500, loss = 0.1473\n","Checking accuracy on validation set\n","Got 795 / 1000 correct (79.50)\n","\n","Iteration 600, loss = 0.1601\n","Checking accuracy on validation set\n","Got 789 / 1000 correct (78.90)\n","\n","Iteration 700, loss = 0.2109\n","Checking accuracy on validation set\n","Got 797 / 1000 correct (79.70)\n","\n","Iteration 0, loss = 0.0358\n","Checking accuracy on validation set\n","Got 813 / 1000 correct (81.30)\n","\n","Iteration 100, loss = 0.0441\n","Checking accuracy on validation set\n","Got 782 / 1000 correct (78.20)\n","\n","Iteration 200, loss = 0.0882\n","Checking accuracy on validation set\n","Got 778 / 1000 correct (77.80)\n","\n","Iteration 300, loss = 0.1313\n","Checking accuracy on validation set\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-8db71db0dcac>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_pretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_pretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-efe653b99eac>\u001b[0m in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration %d, loss = %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mcheck_accuracy_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-6bb93280a1d6>\u001b[0m in \u001b[0;36mcheck_accuracy_part34\u001b[0;34m(loader, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["optimizer = optim.Adam(resnet_pretrained.parameters(), lr = 0.01)\n","train_part34(resnet_pretrained, optimizer, epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_l7diPcCqO_4","executionInfo":{"status":"aborted","timestamp":1690043001490,"user_tz":-540,"elapsed":10,"user":{"displayName":"이진규","userId":"14200365865951724458"}}},"outputs":[],"source":["check_accuracy_part34(loader_test, resnet_pretrained)"]},{"cell_type":"markdown","metadata":{"id":"wvtjmX24uhMg"},"source":["만족스러운 결과를 얻으셨나요?\n","\n","직접 만든 Model과 비교해 봤을 때 어떤 model이 더 성능이 좋았고 왜 그런 결과가 나왔을까요?\n","\n","만약 학습이 잘 되지 않았다면 어떻게 해결할 수 있을까요?\n","\n","> [torchvision document](https://pytorch.org/vision/stable/index.html)에 있는 다양한 Model들을 시도해 보면서 비교해 보도록 합시다."]},{"cell_type":"code","source":["efficientnet_b0_pretrained = models.efficientnet_b0(pretrained=True)\n","print(efficientnet_b0_pretrained)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bR25XtT8WKLk","executionInfo":{"status":"ok","timestamp":1690043006767,"user_tz":-540,"elapsed":941,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"3d8d87a7-8436-4e5d-9959-9f21d0f8c22f"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-3dd342df.pth\n","100%|██████████| 20.5M/20.5M [00:00<00:00, 61.3MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["EfficientNet(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (2): Conv2dNormActivation(\n","            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n","      )\n","    )\n","    (2): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n","      )\n","    )\n","    (3): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n","      )\n","    )\n","    (4): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n","      )\n","    )\n","    (8): Conv2dNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=1)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=True)\n","    (1): Linear(in_features=1280, out_features=1000, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","execution_count":42,"metadata":{"id":"pOnK6v92vIwR","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1690043253576,"user_tz":-540,"elapsed":125146,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"3848bbe2-e291-4631-b811-1cda3238b160"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.2862\n","Checking accuracy on validation set\n","Got 151 / 1000 correct (15.10)\n","\n","Iteration 100, loss = 2.7052\n","Checking accuracy on validation set\n","Got 99 / 1000 correct (9.90)\n","\n","Iteration 200, loss = 3.0521\n","Checking accuracy on validation set\n","Got 75 / 1000 correct (7.50)\n","\n","Iteration 300, loss = 2.3734\n","Checking accuracy on validation set\n","Got 137 / 1000 correct (13.70)\n","\n","Iteration 400, loss = 2.4278\n","Checking accuracy on validation set\n","Got 88 / 1000 correct (8.80)\n","\n","Iteration 500, loss = 2.3963\n","Checking accuracy on validation set\n","Got 143 / 1000 correct (14.30)\n","\n","Iteration 600, loss = 2.2738\n","Checking accuracy on validation set\n","Got 130 / 1000 correct (13.00)\n","\n","Iteration 700, loss = 2.3661\n","Checking accuracy on validation set\n","Got 138 / 1000 correct (13.80)\n","\n","Iteration 0, loss = 2.3521\n","Checking accuracy on validation set\n","Got 114 / 1000 correct (11.40)\n","\n","Iteration 100, loss = 2.3535\n","Checking accuracy on validation set\n","Got 129 / 1000 correct (12.90)\n","\n","Iteration 200, loss = 2.3652\n","Checking accuracy on validation set\n","Got 131 / 1000 correct (13.10)\n","\n","Iteration 300, loss = 2.3694\n","Checking accuracy on validation set\n","Got 111 / 1000 correct (11.10)\n","\n","Iteration 400, loss = 2.3235\n","Checking accuracy on validation set\n","Got 113 / 1000 correct (11.30)\n","\n","Iteration 500, loss = 2.6111\n","Checking accuracy on validation set\n","Got 132 / 1000 correct (13.20)\n","\n","Iteration 600, loss = 2.2735\n","Checking accuracy on validation set\n","Got 127 / 1000 correct (12.70)\n","\n","Iteration 700, loss = 2.3837\n","Checking accuracy on validation set\n","Got 164 / 1000 correct (16.40)\n","\n","Iteration 0, loss = 2.2023\n","Checking accuracy on validation set\n","Got 146 / 1000 correct (14.60)\n","\n","Iteration 100, loss = 2.1828\n","Checking accuracy on validation set\n","Got 129 / 1000 correct (12.90)\n","\n","Iteration 200, loss = 2.2122\n","Checking accuracy on validation set\n","Got 149 / 1000 correct (14.90)\n","\n","Iteration 300, loss = 2.4081\n","Checking accuracy on validation set\n","Got 134 / 1000 correct (13.40)\n","\n","Iteration 400, loss = 2.3240\n","Checking accuracy on validation set\n","Got 131 / 1000 correct (13.10)\n","\n","Iteration 500, loss = 2.4406\n","Checking accuracy on validation set\n","Got 148 / 1000 correct (14.80)\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-dc78d43ce801>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefficientnet_b0_pretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-efe653b99eac>\u001b[0m in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move the model parameters to CPU/GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# put model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["################################################################################\n","# TODO:                                                                        #\n","# Download any pretrained model from torchvision, then finetuning them         #\n","################################################################################\n","model = None\n","optimizer = None\n","\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","num_ftrs = efficientnet_b0_pretrained.classifier[1].in_features\n","num_classes = 10\n","\n","efficientnet_b0_pretrained.classifier[1] = nn.Linear(num_ftrs, num_classes)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","model = efficientnet_b0_pretrained\n","optimizer = optim.Adam(efficientnet_b0_pretrained.parameters(), lr = 0.01)\n","\n","train_part34(model, optimizer, epochs=3)"]},{"cell_type":"code","source":["efficientnet_b0_pretrained"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jz8iv7bfbKlB","executionInfo":{"status":"ok","timestamp":1690043256614,"user_tz":-540,"elapsed":393,"user":{"displayName":"이진규","userId":"14200365865951724458"}},"outputId":"d1b9a3f0-1cb4-44ef-c539-076567c9f5ba"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EfficientNet(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (2): Conv2dNormActivation(\n","            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n","      )\n","    )\n","    (2): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n","      )\n","    )\n","    (3): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n","      )\n","    )\n","    (4): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n","      )\n","    )\n","    (8): Conv2dNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=1)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=True)\n","    (1): Linear(in_features=1280, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"7qtKTBHduRa5"},"source":["**Answer:**\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}